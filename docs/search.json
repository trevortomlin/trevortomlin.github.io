[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Trevor's Website",
    "section": "",
    "text": "Introduction to CKKS\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nVandermonde Matrices\n\n\n\n\n\n\n\nmathematics\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nCyclotomic Polynomials\n\n\n\n\n\n\n\nmathematics\n\n\n\n\n\n\n\n\n\n\n\nAug 4, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nMerkle Trees\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJul 25, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nFast Fourier Transform\n\n\n\n\n\n\n\nmathematics\n\n\nalgorithms\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nVerifiable Delay Functions\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nYao’s Garbled Circuits\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 28, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nOblivious Transfer\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nShamir’s Secret Sharing\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nZero Knowledge Proofs\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nPaper accepted into KDD 2023 Undergraduate Consortium\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nLearning With Errors\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 16, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nGroups, Rings, and Fields\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 15, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to Modular Arithmetic\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nShortest Vector Problem and Closest Vector Problem\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nInteger Factorization Problem\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nDiscrete Logarithm Problem\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nSimple SHA-3\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nFederated Learning From Scratch\n\n\n\n\n\n\n\nmachine learning\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I’m Trevor. I am a motivated and passionate student with a strong interest in computer science and technology. I am currently pursuing a degree in Computer Science at the University of Washington Tacoma. I enjoy exploring new technologies and topics in all branches of computer science including machine learning and cryptography. Recently I have been researching privacy preserving machine learning techniques such as federated learning, differential privacy, and homomorphic encryption. I am excited to continue learning and growing in my field, and I am eager to contribute my skills and knowledge to innovative and impactful projects."
  },
  {
    "objectID": "posts/federatedlearning/index.html",
    "href": "posts/federatedlearning/index.html",
    "title": "Federated Learning From Scratch",
    "section": "",
    "text": "Federated learning is a technique for machine learning that uses decentralized clients to train on local data and send information back to a server without revealing the local data. Federated learning helps models be trained with greater privacy and has many natural applications."
  },
  {
    "objectID": "posts/federatedlearning/index.html#how-does-federated-learning-work",
    "href": "posts/federatedlearning/index.html#how-does-federated-learning-work",
    "title": "Federated Learning From Scratch",
    "section": "How does Federated Learning Work?",
    "text": "How does Federated Learning Work?\n\nAn initial model is established on the server and the weights are sent out to all clients\nEach client trains the model on its own local data and sends the weights or gradients back to the server\nAggregate the weights of each client\nUpdate the server’s model with the aggregated weights and send the new weights to each client\nRepeat steps 2-5 for some number of iterations"
  },
  {
    "objectID": "posts/federatedlearning/index.html#how-do-we-aggregate-the-weights",
    "href": "posts/federatedlearning/index.html#how-do-we-aggregate-the-weights",
    "title": "Federated Learning From Scratch",
    "section": "How do we aggregate the weights?",
    "text": "How do we aggregate the weights?\nThe following two algorithms come from the paper Communication-Efficient Learning of Deep Networks from Decentralized Data by H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas from Google in 2016.\n\nFedSGD\nA simple way to update the server’s model is to update the parameters for every gradient that gets sent from a client. This method is called FedSGD and is defined as follows:\n\\[g_k = \\nabla F_k(w_t)\\] \\[ w_{t+1} \\leftarrow w_t - \\eta \\sum_{k=1}^{K}\\frac{n_k}{n}g_k\\]\nFor each client k, we do one single step of gradient descent and then average the weights together.\n\n\nFedAVG\nFedAVG is a modification of FedSGD that trains each client for multiple epochs and then averages the weights together. This method uses less communication than FedSGD and is one of the most commonly used algorithms. It is defined in the aformentioned paper as follows:\n\n\n\nExample with code\nWe first generate a simple dataset that can be used to classify two classes.We then train a centralized model using sklearn and plot the decision boundary. Next, we train a federated model using FedAVG and plot the decision boundary. Finally, we compare the accuracy of the two models.\n\n# Generate Dataset using sklearn\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nX, y = make_classification(\n    n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=1, random_state=7\n)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Plot the data\nplt.scatter(X[:, 0], X[:, 1], marker=\"o\", c=y, s=25, edgecolor=\"k\")\nplt.show()\n\n\n\n\nFigure 1: A synthetic dataset generated using sklearn\n\n\n\n\n\nimport numpy as np\nfrom sklearn.linear_model import SGDClassifier\n\n# Train sklearn SGDClassifier model\nmodel = SGDClassifier(loss=\"log_loss\")\nmodel.fit(X_train, y_train)\n\n# Plot the decision boundary\nx1 = np.linspace(X_test.min()-3, X_test.max()+3, 100)\nx2 = np.linspace(y_test.min()-3, y_test.max()+3, 100)\nxx1, xx2 = np.meshgrid(x1, x2)\nX_grid = np.c_[xx1.ravel(), xx2.ravel()]\nprobs = model.predict_proba(X_grid)[:, 1].reshape(xx1.shape)\n\nplt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors=\"black\")\nplt.scatter(X_test[:, 0], X_test[:, 1], marker=\"o\", c=y_test, s=25, edgecolor=\"k\")\nplt.show()\n\n# Print the accuracy\naccuracy = model.score(X_test, y_test) * 100.0\nprint(f\"Accuracy: {accuracy:.2f}%\")\n\n\n\n\nFigure 2: Decision boundary after training a centralized model\n\n\n\n\nAccuracy: 85.00%\n\n\n\nimport numpy as np\nfrom sklearn.linear_model import SGDClassifier\n\nn_clients = 3\nn_epochs = 3\nn_rounds = 1\n\nclient_models = [SGDClassifier(loss=\"log_loss\") for _ in range(n_clients)]\nserver_model = SGDClassifier(loss=\"log_loss\")\n\n# Split data into clients\nX_clients = np.array_split(X_train, n_clients)\ny_clients = np.array_split(y_train, n_clients)\n\n# Initialize server coefficients to 0\nserver_model.coef_ = np.zeros((1, 2))\nserver_model.intercept_ = np.zeros(1)\nserver_model.classes_ = np.array([0, 1])\n\nfor _ in range(n_rounds):\n\n    # Set client models to be the same as the server model\n    for client_model in client_models:\n        client_model.coef_ = server_model.coef_\n        client_model.intercept_ = server_model.intercept_\n\n    # Train each client model on its own data\n    for client_model, X, y in zip(client_models, X_clients, y_clients):\n\n        # Split data into batches\n        X_batches = np.array_split(X, n_epochs)\n        y_batches = np.array_split(y, n_epochs)\n\n        for _ in range(n_epochs):\n            for X_batch, y_batch in zip(X_batches, y_batches):\n                client_model.partial_fit(X_batch, y_batch, classes=[0, 1])\n\n    # Aggregate the client models using FedAVG using the number of samples as the weights\n    n_samples = [len(X) for X in X_clients]\n    weights = [n / sum(n_samples) for n in n_samples]\n\n    server_model.coef_ = np.average(\n        [client_model.coef_ for client_model in client_models], axis=0, weights=weights\n    )\n    server_model.intercept_ = np.average(\n        [client_model.intercept_ for client_model in client_models], axis=0, weights=weights\n    )\n\n# Plot the decision boundary\nx1 = np.linspace(X_test.min()-3, X_test.max()+3, 100)\nx2 = np.linspace(y_test.min()-3, y_test.max()+3, 100)\nxx1, xx2 = np.meshgrid(x1, x2)\nX_grid = np.c_[xx1.ravel(), xx2.ravel()]\nprobs = model.predict_proba(X_grid)[:, 1].reshape(xx1.shape)\n\nplt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors=\"black\")\nplt.scatter(X_test[:, 0], X_test[:, 1], marker=\"o\", c=y_test, s=25, edgecolor=\"k\")\nplt.show()\n\n# Print the accuracy\naccuracy = server_model.score(X_test, y_test) * 100.0\nprint(f\"Accuracy: {accuracy:.2f}%\")\n\n\n\n\nFigure 3: Decision boundary after training a federated model\n\n\n\n\nAccuracy: 85.00%\n\n\nNow we can see that the federated model has a similar accuracy to the centralized model. If we look at the weights of the server model, we can see that they are similar to the weights of the centralized model.\n\nprint(f\"Centralized Model Weights: w={model.coef_[0]}, b={model.intercept_[0]}\")\nprint(f\"Federated Model Weights: w={server_model.coef_[0]}, b={server_model.intercept_[0]}\")\n\nCentralized Model Weights: w=[-6.13807248 21.28558495], b=5.731260349455407\nFederated Model Weights: w=[-5.8260368  24.13905334], b=6.432089614040729"
  },
  {
    "objectID": "posts/federatedlearning/index.html#a-high-level-look",
    "href": "posts/federatedlearning/index.html#a-high-level-look",
    "title": "Federated Learning From Scratch",
    "section": "A High-Level Look",
    "text": "A High-Level Look"
  },
  {
    "objectID": "posts/federatedlearning/index.html#further-reading",
    "href": "posts/federatedlearning/index.html#further-reading",
    "title": "Federated Learning From Scratch",
    "section": "Further Reading",
    "text": "Further Reading\nOther algorithms for federated learning include:\n1. FedDyn\n2. Sub-FedAvg\n3. FedAvgM\n4. FedAdam\n\nFrameworks for federated learning include:\n1. TensorFlow Federated\n2. Flower"
  },
  {
    "objectID": "posts/federatedlearning/index.html#issues-with-federated-learning",
    "href": "posts/federatedlearning/index.html#issues-with-federated-learning",
    "title": "Federated Learning From Scratch",
    "section": "Issues with Federated Learning",
    "text": "Issues with Federated Learning\nFederated Learning is a promising approach to training machine learning models on decentralized data. There are situations where Federated Learning is naturally the best solution given how the data is split up. However, there are still many issues that need to be considered before using it.  While Federated Learning helps increase privacy, it does not guarantee privacy. There are many attacks that use either malicious models or gradients to extract information about the data. To have privacy Federated Learning must be combined with something such as differential privacy or fully homomorphic encryption.  Another issue is that clients typically have different amounts of data and with different usage patterns that might not be representative of the entire dataset. This is defined as Unbalanced data and Non-IID data in the Federated Learning literature.  Finally, Federated Learning has to deal with the issue of limited communication and a large number of clients. Some clients have limited bandwidth and are offline for long periods of time. This means that the server model has to be able to handle clients that are not always available."
  },
  {
    "objectID": "posts/keccak/index.html",
    "href": "posts/keccak/index.html",
    "title": "Simple SHA-3",
    "section": "",
    "text": "Cryptographic algorithms such as Keccak play a crucial role in securing sensitive information, but they can often seem daunting and complex to understand. The National Institute of Standards and Technology (NIST) standard for Keccak, in particular, has become a widely used cryptographic algorithm due to its high security and efficiency. However, the technical jargon and complex mathematical concepts surrounding Keccak can be intimidating for those unfamiliar with the field of cryptography. In this blog post, I aim to provide a comprehensive yet accessible guide to the NIST standard for Keccak, breaking down the technical terms and explaining them in an easier to understand way."
  },
  {
    "objectID": "posts/keccak/index.html#what-is-the-nist-standard-for-keccak",
    "href": "posts/keccak/index.html#what-is-the-nist-standard-for-keccak",
    "title": "Simple SHA-3",
    "section": "What is the NIST standard for Keccak?",
    "text": "What is the NIST standard for Keccak?\nThe NIST standard for Keccak is a set of specifications for the Keccak cryptographic algorithm developed by Guido Bertoni, Joan Daemen, Michaël Peeters, and Gilles Van Assche. The NIST standard, officially known as FIPS 202, was published in 2015 as a part of a competition that NIST organized. Keccak is a family of hash functions, with different versions that provide varying levels of security and performance. The NIST standard specifies the requirements for the use of Keccak in a variety of applications, including digital signatures, key derivation, and password hashing."
  },
  {
    "objectID": "posts/keccak/index.html#understanding-keccaks-hash-function",
    "href": "posts/keccak/index.html#understanding-keccaks-hash-function",
    "title": "Simple SHA-3",
    "section": "Understanding Keccak’s Hash Function",
    "text": "Understanding Keccak’s Hash Function\nThe state of the hash function is represented as a 5x5 matrix of 64-bit words. The state is initialized to all zeros. The input is then XORed with the state. The state is then passed through the Keccak-p permutation function. This process is repeated until all of the input has been processed. The output is the state of the hash function.\nTo convert from a bit string to the state array we use the following function:\nprivate static long[][] stringToStateArray(String s) {\n    long[][] A = new long[5][5];\n    int i = 0;\n\n    for (int y = 0; y &lt; 5; y++) {\n        for (int x = 0; x &lt; 5; x++) {\n            String blockString = s.substring(i * 64, (i + 1) * 64);\n            A[x][y] = Long.reverse(Long.parseUnsignedLong(blockString, 2));\n            i++;\n            // 9 is the number of longs to store 576 (rate) / 64 (size of long) = 9 longs\n            if (i&gt;=8) {\n                return A;\n            }\n        }\n    }\n\n    return A;\n}\nMore information about this can be found in section 3.1.2 of FIPS 202.\nThe 5-step mappings in the Keccak cryptographic algorithm are the core components that transform input data into a fixed-length hash output.\nSome of the step mappings require this function, which rotates the bits of a 64-bit integer to the left by a specified number of bits:\nprivate static long rotateLeft(long x, int n) {\n    return (x &lt;&lt; n) | (x &gt;&gt;&gt; (64 - n));\n}\n\nTheta: In this step, the input data is transformed by applying a linear function to each row of the state matrix. This step helps to increase the security of the algorithm by increasing the diffusion of the input data.\n\n\n\n\nFigure 3 From FIPS 202\n\n\npublic static long[][] theta(long[][] A) {\n    long[] C = new long[5];\n    for (int x = 0; x &lt; 5; x++) {\n        C[x] = A[x][0] ^ A[x][1] ^ A[x][2] ^ A[x][3] ^ A[x][4];\n    }\n\n    long[] D = new long[5];\n    for (int x = 0; x &lt; 5; x++) {\n        D[x] = (C[(x+4)%5]) ^ rotateLeft(C[(x+1)%5], 1);\n    }\n\n    for (int x = 0; x &lt; 5; x++) {\n        for (int y = 0; y &lt; 5; y++) {\n            A[x][y] ^= D[x];\n        }\n    }\n    return A;\n}\n\nRho: The state matrix is rotated by a certain number of positions in this step. The amount of rotation is determined by a pre-defined pattern, which varies depending on the version of Keccak being used.\n\n\n\n\nFigure 4 From FIPS 202\n\n\n\nPi: In this step, the columns and rows of the state matrix are rearranged according to a pre-defined permutation. This helps to further increase the diffusion of the input data.\n\n\n\n\nFigure 5 From FIPS 202\n\n\n\nChi: The state matrix is transformed by applying a non-linear function to each row. This helps to introduce non-linearity into the algorithm and make it more resistant to attacks.\n\nIn practice, the Pi and Rho steps are combined into a single step mapping. The combined step mapping is defined as:\npublic static long[][] pi_rho(long[][] A) {\n\n    final int[][] offsets = new int[][] {\n        {0, 1, 62, 28, 27},\n        {36, 44, 6, 55, 20},\n        {3, 10, 43, 25, 39},\n        {41, 45, 15, 21, 8},\n        {18, 2, 61, 56, 14}\n    };\n\n    long[][] B = new long[5][5];\n    for (int y = 0; y &lt; 5; y++) {\n        for (int x = 0; x &lt; 5; x++) {\n            int newX = 2 * x + 3 * y;\n            newX %= 5;\n            int newY = y;\n\n            long rotatedValue = rotateLeft(A[x][y], offsets[y][x]);\n\n            B[newY][newX] = rotatedValue;\n        }\n    }\n\n    return B;\n\n}\n\n\n\nFigure 6 From FIPS 202\n\n\npublic static long[][] chi(long[][] A) {\n    long[][] C = new long[5][5];\n    for (int i = 0; i &lt; 5; i++) {\n        for (int j = 0; j &lt; 5; j++) {\n            C[i][j] = A[i][j] ^ ((~A[(i+1)%5][j]) & A[(i+2)%5][j]);\n        }\n    }\n    return C;\n}\n\nIota: The final step involves XORing a pre-defined round constant with a specific location in the state matrix. This helps to add additional randomness to the output and increase the security of the algorithm.\n\npublic static long[][] iota(long[][] A, int round) {\n    long RC = rc[round];\n    A[0][0] ^= RC;\n    return A;\n}\nIn this case the round constants are retrieved from a lookup table, however the round constants can also be calculated using Algorithm 5 from the NIST standard. Below is the lookup table for the round constants:\nprivate static final long[] rc = {\n    0x0000000000000001L,\n    0x0000000000008082L,\n    0x800000000000808AL,\n    0x8000000080008000L,\n    0x000000000000808BL,\n    0x0000000080000001L,\n    0x8000000080008081L,\n    0x8000000000008009L,\n    0x000000000000008AL,\n    0x0000000000000088L,\n    0x0000000080008009L,\n    0x000000008000000AL,\n    0x000000008000808BL,\n    0x800000000000008BL,\n    0x8000000000008089L,\n    0x8000000000008003L,\n    0x8000000000008002L,\n    0x8000000000000080L,\n    0x000000000000800AL,\n    0x800000008000000AL,\n    0x8000000080008081L,\n    0x8000000000008080L,\n    0x0000000080000001L,\n    0x8000000080008008L\n};\nBy repeating these 5-step mappings multiple times, the input data is progressively transformed into a fixed-length hash output. The number of rounds performed depends on the version of Keccak being used and the desired level of security. The output produced by Keccak is considered to be highly secure and is resistant to various attacks such as collision, preimage, and second preimage attacks.\nA single round is defined as:\npublic static long[][] keccakRound(long[][] A, int round) {\n    A = theta(A);\n    A = pi_rho(A);\n    A = chi(A);\n    A = iota(A, round);\n    return A;\n}\nAnd gets repeated for the number of rounds:\npublic static long[][] keccakf(long[][] A, int n) {\n    for (int i = 0; i &lt; n; i++) {\n        A = keccakRound(A, i);\n    }\n    return A;\n}\nTo put this all together, here is psuedo code for the Keccak algorithm:\nfunction keccak-f(A)\n    for i from 0 to 24\n        A = θ(A)\n        A = π(A)\n        A = ρ(A)\n        A = χ(A)\n        A = ι(A, i)\n    return A\n\nfunction SHA-3(M)\n    P = M || 0x06 || 0x00 || … || 0x80 so that len(P) * constant == rate\n    n = len(P)/rate\n    c = list of blocks with a length of rate bits\n\n    Initialize all state values to 0\n\n    for i from 0 to n-1\n        S = S xor c[i]\n        S = keccak_round(S)\n\n    Z = empty string\n    for i from 0 to n-1\n        Z = Z || S[i*b..(i+1)*b-1]\n    return Z"
  },
  {
    "objectID": "posts/keccak/index.html#applications-of-keccak",
    "href": "posts/keccak/index.html#applications-of-keccak",
    "title": "Simple SHA-3",
    "section": "Applications of Keccak",
    "text": "Applications of Keccak\nKeccak has several applications in the field of cryptography due to its high security and efficiency. Some of the common applications of Keccak include:\n\nHash Functions: Keccak is commonly used as a hash function to securely store and transmit sensitive data. Its resistance to various attacks makes it suitable for applications such as password storage, digital signatures, and message authentication.\nEncryption: Keccak can be used for encryption, especially in applications where data needs to be transmitted securely over a network. The algorithm’s high security makes it a reliable choice for encryption.\nKey Derivation: Keccak can be used to derive keys for cryptographic protocols such as TLS (Transport Layer Security) and SSL (Secure Sockets Layer). It is also used to generate keys for secure communication between different systems.\nBlockchain: Keccak is used as a hashing function in many blockchain systems such as Ethereum and CryptoNote. The algorithm provides high security, which is necessary for protecting the integrity of the blockchain.\nRandom Number Generation: Keccak is used in random number generators for secure applications such as gambling, lottery, and cryptography."
  },
  {
    "objectID": "posts/keccak/index.html#conclusion",
    "href": "posts/keccak/index.html#conclusion",
    "title": "Simple SHA-3",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, Keccak is a powerful cryptographic algorithm that has become a popular choice for secure applications such as password storage, digital signatures, and blockchain. Its high security and efficiency make it a reliable choice for various cryptographic operations, including hashing, encryption, key derivation, and random number generation. The 5-step mappings of Keccak, also known as the Keccak-p permutation, provide a robust framework for transforming input data into a fixed-length hash output. While Keccak may seem complex and intimidating to those unfamiliar with cryptography, this blog post has provided a comprehensive yet accessible guide to the NIST standard for Keccak. By breaking down the technical terms and explaining them in an easy-to-understand way, we hope to have demystified Keccak and made it accessible to anyone interested in cryptography."
  },
  {
    "objectID": "posts/keccak/index.html#parameter-specifications",
    "href": "posts/keccak/index.html#parameter-specifications",
    "title": "Simple SHA-3",
    "section": "Parameter Specifications",
    "text": "Parameter Specifications\nKeccak is described in the format Keccak-p[b,n] where b is the rate + capacity and n is the number of rounds. Additionally, the parameter \\(w\\) is defined as \\(\\frac{b}{25}\\) and \\(l\\) is \\(log_2(w)\\). Keccak-f[b] is a subset of Keccak-p[b,n] where \\(n\\) is fixed to \\(12 + 2l\\).\n\nFIPS 202 Table 1: KECCAK-p permutation widths and related quantities\n\n\nb\n25\n50\n100\n200\n400\n800\n1600\n\n\n\n\nw\n1\n2\n4\n8\n16\n32\n64\n\n\nl\n0\n1\n2\n3\n4\n5\n6\n\n\n\n\nFIPS 202 Table 3: Input block sizes for HMAC\n\n\nHash Function\nSHA3-224\nSHA3-256\nSHA3-384\nSHA3-512\n\n\n\n\nBlock Size (bytes)\n144\n136\n104\n72\n\n\n\n\nKeccak Team Table 3: the parameters of the standard FIPS 202 and SP 800-185 instances\n\n\n\n\n\n\n\n\n\nName\nr\nc\nOutput length (bits)\nSecurity level (bits)\n\n\n\n\nSHA3-224\n1152\n448\n224\n112\n\n\nSHA3-256\n1088\n512\n256\n128\n\n\nSHA3-384\n832\n768\n384\n192\n\n\nSHA3-512\n576\n1024\n512\n256\n\n\n\nIn this blog we are using Keccak-f[1600] which is the SHA-3 standard. This means that the rate is 576, the capacity is 1024, and the output length is 512. \\(w\\) is 64 and \\(l\\) is 6."
  },
  {
    "objectID": "posts/keccak/index.html#padding",
    "href": "posts/keccak/index.html#padding",
    "title": "Simple SHA-3",
    "section": "Padding",
    "text": "Padding\nKeccak pads the end of the input with the byte 0x06 followed by as many 0x00 bytes as necessary to make the input a multiple of the rate of the hash function. The last byte of the last block is set to 0x80."
  },
  {
    "objectID": "posts/keccak/index.html#input",
    "href": "posts/keccak/index.html#input",
    "title": "Simple SHA-3",
    "section": "Input",
    "text": "Input\nKeccak recieves a strings of bits stored in little-endian format. Keccak pads the end of the input with the byte 0x06 followed by as many 0x00 bytes as necessary to make the input a multiple of the rate of the hash function. The last byte of the last block is set to 0x80."
  },
  {
    "objectID": "posts/keccak/index.html#understanding-sha-3s-hash-function",
    "href": "posts/keccak/index.html#understanding-sha-3s-hash-function",
    "title": "Simple SHA-3",
    "section": "Understanding SHA-3’s Hash Function",
    "text": "Understanding SHA-3’s Hash Function\nThe state of the hash function is represented as a 5x5 matrix of 64-bit words. The state is initialized to all zeros. The input is then XORed with the state. The state is then passed through the Keccak-p permutation function. This process is repeated until all of the input has been processed. The output is the state of the hash function.\nTo convert from a bit string to the state array we use the following function:\nprivate static long[][] stringToStateArray(String s) {\n    long[][] A = new long[5][5];\n    int i = 0;\n\n    for (int y = 0; y &lt; 5; y++) {\n        for (int x = 0; x &lt; 5; x++) {\n            String blockString = s.substring(i * 64, (i + 1) * 64);\n            A[x][y] = Long.reverse(Long.parseUnsignedLong(blockString, 2));\n            i++;\n            // 9 is the number of longs to store 576 (rate) / 64 (size of long) = 9 longs\n            if (i&gt;=8) {\n                return A;\n            }\n        }\n    }\n\n    return A;\n}\nMore information about this can be found in section 3.1.2 of FIPS 202.\nThe 5-step mappings in the Keccak cryptographic algorithm are the core components that transform input data into a fixed-length hash output.\nSome of the step mappings require this function, which rotates the bits of a 64-bit integer to the left by a specified number of bits:\nprivate static long rotateLeft(long x, int n) {\n    return (x &lt;&lt; n) | (x &gt;&gt;&gt; (64 - n));\n}\n\nTheta: In this step, the input data is transformed by applying a linear function to each row of the state matrix. This step helps to increase the security of the algorithm by increasing the diffusion of the input data.\n\n\n\n\nFigure 3 From FIPS 202\n\n\npublic static long[][] theta(long[][] A) {\n    long[] C = new long[5];\n    for (int x = 0; x &lt; 5; x++) {\n        C[x] = A[x][0] ^ A[x][1] ^ A[x][2] ^ A[x][3] ^ A[x][4];\n    }\n\n    long[] D = new long[5];\n    for (int x = 0; x &lt; 5; x++) {\n        D[x] = (C[(x+4)%5]) ^ rotateLeft(C[(x+1)%5], 1);\n    }\n\n    for (int x = 0; x &lt; 5; x++) {\n        for (int y = 0; y &lt; 5; y++) {\n            A[x][y] ^= D[x];\n        }\n    }\n    return A;\n}\n\nRho: The state matrix is rotated by a certain number of positions in this step. The amount of rotation is determined by a pre-defined pattern, which varies depending on the version of Keccak being used.\n\n\n\n\nFigure 4 From FIPS 202\n\n\n\nPi: In this step, the columns and rows of the state matrix are rearranged according to a pre-defined permutation. This helps to further increase the diffusion of the input data.\n\n\n\n\nFigure 5 From FIPS 202\n\n\n\nChi: The state matrix is transformed by applying a non-linear function to each row. This helps to introduce non-linearity into the algorithm and make it more resistant to attacks.\n\nIn practice, the Pi and Rho steps are combined into a single step mapping. The combined step mapping is defined as:\npublic static long[][] pi_rho(long[][] A) {\n\n    final int[][] offsets = new int[][] {\n        {0, 1, 62, 28, 27},\n        {36, 44, 6, 55, 20},\n        {3, 10, 43, 25, 39},\n        {41, 45, 15, 21, 8},\n        {18, 2, 61, 56, 14}\n    };\n\n    long[][] B = new long[5][5];\n    for (int y = 0; y &lt; 5; y++) {\n        for (int x = 0; x &lt; 5; x++) {\n            int newX = 2 * x + 3 * y;\n            newX %= 5;\n            int newY = y;\n\n            long rotatedValue = rotateLeft(A[x][y], offsets[y][x]);\n\n            B[newY][newX] = rotatedValue;\n        }\n    }\n\n    return B;\n\n}\n\n\n\nFigure 6 From FIPS 202\n\n\npublic static long[][] chi(long[][] A) {\n    long[][] C = new long[5][5];\n    for (int i = 0; i &lt; 5; i++) {\n        for (int j = 0; j &lt; 5; j++) {\n            C[i][j] = A[i][j] ^ ((~A[(i+1)%5][j]) & A[(i+2)%5][j]);\n        }\n    }\n    return C;\n}\n\nIota: The final step involves XORing a pre-defined round constant with a specific location in the state matrix. This helps to add additional randomness to the output and increase the security of the algorithm.\n\npublic static long[][] iota(long[][] A, int round) {\n    long RC = rc[round];\n    A[0][0] ^= RC;\n    return A;\n}\nIn this case the round constants are retrieved from a lookup table, however the round constants can also be calculated using Algorithm 5 from the NIST standard. Below is the lookup table for the round constants:\nprivate static final long[] rc = {\n    0x0000000000000001L,\n    0x0000000000008082L,\n    0x800000000000808AL,\n    0x8000000080008000L,\n    0x000000000000808BL,\n    0x0000000080000001L,\n    0x8000000080008081L,\n    0x8000000000008009L,\n    0x000000000000008AL,\n    0x0000000000000088L,\n    0x0000000080008009L,\n    0x000000008000000AL,\n    0x000000008000808BL,\n    0x800000000000008BL,\n    0x8000000000008089L,\n    0x8000000000008003L,\n    0x8000000000008002L,\n    0x8000000000000080L,\n    0x000000000000800AL,\n    0x800000008000000AL,\n    0x8000000080008081L,\n    0x8000000000008080L,\n    0x0000000080000001L,\n    0x8000000080008008L\n};\nBy repeating these 5-step mappings multiple times, the input data is progressively transformed into a fixed-length hash output. The number of rounds performed depends on the version of Keccak being used and the desired level of security. The output produced by Keccak is considered to be highly secure and is resistant to various attacks such as collision, preimage, and second preimage attacks.\nA single round is defined as:\npublic static long[][] keccakRound(long[][] A, int round) {\n    A = theta(A);\n    A = pi_rho(A);\n    A = chi(A);\n    A = iota(A, round);\n    return A;\n}\nAnd gets repeated for the number of rounds:\npublic static long[][] keccakf(long[][] A, int n) {\n    for (int i = 0; i &lt; n; i++) {\n        A = keccakRound(A, i);\n    }\n    return A;\n}\nTo put this all together, here is psuedo code for the Keccak algorithm:\nfunction keccak-f(A)\n    for i from 0 to 24\n        A = θ(A)\n        A = π(A)\n        A = ρ(A)\n        A = χ(A)\n        A = ι(A, i)\n    return A\n\nfunction SHA-3(M)\n    P = M || 0x06 || 0x00 || … || 0x80 so that len(P) * constant == rate\n    n = len(P)/rate\n    c = list of blocks with a length of rate bits\n\n    Initialize all state values to 0\n\n    for i from 0 to n-1\n        S = S xor c[i]\n        S = keccak_round(S)\n\n    Z = empty string\n    for i from 0 to n-1\n        Z = Z || S[i*b..(i+1)*b-1]\n    return Z"
  },
  {
    "objectID": "posts/keccak/index.html#references",
    "href": "posts/keccak/index.html#references",
    "title": "Simple SHA-3",
    "section": "References",
    "text": "References\n\nKeccak Team - Keccak Specifications Summary\nFIPS 202"
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html",
    "href": "posts/discretelogarithmproblem/index.html",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "The discrete logarithm problem is a fundamental concept in the field of cryptography. It plays a crucial role in many encryption algorithms and serves as the basis for various security protocols. In this blog post, we will explore what the discrete logarithm problem is and why it is significant.\n\n\nBefore delving into the discrete logarithm problem, let’s quickly recap logarithms. A logarithm is an operation that calculates the exponent to which a particular base must be raised to obtain a given number. In simpler terms, it answers the question: “What power do I need to raise this base to get this number?”\nFor example, in the equation \\(2^x = 8\\), the logarithm base 2 of 8 is 3, denoted as \\(log_2(8) = 3\\). It tells us that 2 raised to the power of 3 equals 8.\n\n\n\nNow, let’s move on to the discrete logarithm problem. In cryptography, we often deal with mathematical structures known as finite fields. These fields have a finite number of elements and exhibit certain properties that make them suitable for cryptographic operations.\nThe discrete logarithm problem is defined within a finite field. Given a base element g and a target element h, the problem involves finding an exponent x such that \\(g^x = h.\\) Mathematically, it can be represented as \\(x = log_g(h).\\)\nThe challenge lies in finding the value of x efficiently, especially when the field is very large and calculations become computationally expensive. In other words, the problem is to determine the unknown exponent x based on the known values of g and h.\n\nimport matplotlib.pyplot as plt\n\n# Define the finite field parameters\nprime_modulus = 17  # Modulus value for the finite field\n\n# Generate the base and target elements\n# All integers from 1 to (prime_modulus - 1)\nbase_elements = range(1, prime_modulus)  \n\n# Calculate the target elements using exponentiation\ntarget_elements = [pow(2, x, prime_modulus) for x in base_elements]  \n\nplt.scatter(base_elements, target_elements, color='red', marker='o')\n\nplt.xlabel('Base Elements')\nplt.ylabel('Target Elements')\nplt.title('Discrete Logarithm Problem')\n\nplt.show()\n\n\n\n\nNow, if we consider the plotted graph, with the x-axis representing the base elements and the y-axis representing the target elements, finding the discrete logarithm involves determining the x-coordinate (base element) corresponding to a given y-coordinate (target element).\nThe challenge arises because, in a finite field, as the field size (p) grows larger, the number of possible base and target elements increases exponentially.\n\n\n\nThe discrete logarithm problem forms the foundation of various cryptographic algorithms, particularly those based on public-key cryptography. These algorithms rely on the difficulty of solving the discrete logarithm problem to ensure the security of encrypted data.\nOne such algorithm is Diffie-Hellman key exchange, which allows two parties to establish a shared secret key over an insecure channel.\nOther algorithms, such as DSA (Digital Signature Algorithm) and ElGamal encryption, also depend on the discrete logarithm problem for their security.\n\n\n\nThe emergence of quantum computing has significant implications for cryptographic algorithms, including those based on the discrete logarithm problem. Classical computers employ the index calculus algorithm to solve this problem, but it becomes time-consuming as the field size increases. Quantum computers, however, leverage algorithms like Shor’s algorithm, which can efficiently solve the discrete logarithm problem in polynomial time. This poses a challenge to the security of classical cryptographic schemes when faced with a powerful quantum computer.\nWhile there are no quantum computers large enough to break the discrete logarithm problem at the time of writing, it is important to consider the implications of quantum computing on the security of cryptographic algorithms. This is especially true for those that rely on the discrete logarithm problem, such as Diffie-Hellman key exchange and DSA.\n\n\n\nIn summary, the discrete logarithm problem is a mathematical challenge of finding an unknown exponent within a finite field. Its significance in cryptography cannot be overstated, as it underpins the security of various encryption algorithms and protocols. However, the emergence of quantum computing poses a threat to the security of these algorithms, as quantum computers can efficiently solve the discrete logarithm problem. We should look to develop quantum-resistant cryptographic schemes to ensure the security of our data in the future such as lattice-based cryptography."
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html#understanding-logarithms",
    "href": "posts/discretelogarithmproblem/index.html#understanding-logarithms",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "Before delving into the discrete logarithm problem, let’s quickly recap logarithms. A logarithm is an operation that calculates the exponent to which a particular base must be raised to obtain a given number. In simpler terms, it answers the question: “What power do I need to raise this base to get this number?”\nFor example, in the equation \\(2^x = 8\\), the logarithm base 2 of 8 is 3, denoted as \\(log_2(8) = 3\\). It tells us that 2 raised to the power of 3 equals 8."
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html#the-discrete-logarithm-problem",
    "href": "posts/discretelogarithmproblem/index.html#the-discrete-logarithm-problem",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "Now, let’s move on to the discrete logarithm problem. In cryptography, we often deal with mathematical structures known as finite fields. These fields have a finite number of elements and exhibit certain properties that make them suitable for cryptographic operations.\nThe discrete logarithm problem is defined within a finite field. Given a base element g and a target element h, the problem involves finding an exponent x such that \\(g^x = h.\\) Mathematically, it can be represented as \\(x = log_g(h).\\)\nThe challenge lies in finding the value of x efficiently, especially when the field is very large and calculations become computationally expensive. In other words, the problem is to determine the unknown exponent x based on the known values of g and h.\n\nimport matplotlib.pyplot as plt\n\n# Define the finite field parameters\nprime_modulus = 17  # Modulus value for the finite field\n\n# Generate the base and target elements\n# All integers from 1 to (prime_modulus - 1)\nbase_elements = range(1, prime_modulus)  \n\n# Calculate the target elements using exponentiation\ntarget_elements = [pow(2, x, prime_modulus) for x in base_elements]  \n\nplt.scatter(base_elements, target_elements, color='red', marker='o')\n\nplt.xlabel('Base Elements')\nplt.ylabel('Target Elements')\nplt.title('Discrete Logarithm Problem')\n\nplt.show()\n\n\n\n\nNow, if we consider the plotted graph, with the x-axis representing the base elements and the y-axis representing the target elements, finding the discrete logarithm involves determining the x-coordinate (base element) corresponding to a given y-coordinate (target element).\nThe challenge arises because, in a finite field, as the field size (p) grows larger, the number of possible base and target elements increases exponentially."
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html#significance-in-cryptography",
    "href": "posts/discretelogarithmproblem/index.html#significance-in-cryptography",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "The discrete logarithm problem forms the foundation of various cryptographic algorithms, particularly those based on public-key cryptography. These algorithms rely on the difficulty of solving the discrete logarithm problem to ensure the security of encrypted data.\nOne such algorithm is Diffie-Hellman key exchange, which allows two parties to establish a shared secret key over an insecure channel.\nOther algorithms, such as DSA (Digital Signature Algorithm) and ElGamal encryption, also depend on the discrete logarithm problem for their security."
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html#conclusion",
    "href": "posts/discretelogarithmproblem/index.html#conclusion",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "In summary, the discrete logarithm problem is a mathematical challenge of finding an unknown exponent within a finite field. Its significance in cryptography cannot be overstated, as it underpins the security of various encryption algorithms and protocols. However, the emergence of quantum computing poses a threat to the security of these algorithms, as quantum computers can efficiently solve the discrete logarithm problem. We should look to develop quantum-resistant cryptographic schemes to ensure the security of our data in the future such as lattice-based cryptography."
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html#quantum-security",
    "href": "posts/discretelogarithmproblem/index.html#quantum-security",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "The emergence of quantum computing has significant implications for cryptographic algorithms, including those based on the discrete logarithm problem. Classical computers employ the index calculus algorithm to solve this problem, but it becomes time-consuming as the field size increases. Quantum computers, however, leverage algorithms like Shor’s algorithm, which can efficiently solve the discrete logarithm problem in polynomial time. This poses a challenge to the security of classical cryptographic schemes when faced with a powerful quantum computer.\nWhile there are no quantum computers large enough to break the discrete logarithm problem at the time of writing, it is important to consider the implications of quantum computing on the security of cryptographic algorithms. This is especially true for those that rely on the discrete logarithm problem, such as Diffie-Hellman key exchange and DSA."
  },
  {
    "objectID": "posts/integerfactorization/index.html",
    "href": "posts/integerfactorization/index.html",
    "title": "Integer Factorization Problem",
    "section": "",
    "text": "The integer factorization problem is a fundamental challenge in cryptography, with significant implications for the widely used RSA encryption scheme. Understanding this problem and its computational complexity provides insights into the security of RSA and the potential impact of quantum computing advancements.\nIn essence, the integer factorization problem involves breaking down a composite integer into its prime factors. While this task may seem simple for small numbers, it becomes exponentially more difficult as the size of the number increases. This property forms the basis of RSA encryption, where the security relies on the difficulty of factoring the product of two large prime numbers.\nClassical computers employ various algorithms, such as the General Number Field Sieve (GNFS) or the Quadratic Sieve (QS), to factorize composite integers. The time complexity of these algorithms grows significantly with the size of the number, making it increasingly time-consuming to factorize larger integers.\nLet’s see an example of how we can factorize the product of two small prime numbers using a Python code snippet:\n\ndef factorize_product(p, q):\n    n = p * q\n    factors = []\n    i = 2\n\n    while i * i &lt;= n:\n        if n % i:\n            i += 1\n        else:\n            n //= i\n            factors.append(i)\n\n    if n &gt; 1:\n        factors.append(n)\n\n    return factors\n\np = 7\nq = 11\nproduct = p * q\nprime_factors = factorize_product(p, q)\nprint(f\"The prime factors of {product} are: {prime_factors}\")\n\nThe prime factors of 77 are: [7, 11]\n\n\nIn the example, we factorize the product of two primes 7 and 11, which is 77. The code will output the prime factors: [7, 11], indicating that 77 can be factored into the primes 7 and 11.\nIn the code snippet above, we demonstrated the factorization of a product of two small prime numbers. However, it’s important to note that the security of RSA encryption relies on the difficulty of factoring much larger composite numbers. Typical RSA primes used in modern cryptographic systems can have lengths of 2048 bits to make a security level of 4096 bits. Factoring such large numbers using classical computers is an incredibly demanding computational task that is not reasonable to compute.\nTo put this into perspective, consider that breaking a 4096-bit RSA key by factoring the modulus is estimated to require trillions of years on current classical computing technology. This emphasizes the level of security provided by RSA encryption when implemented with sufficiently large prime numbers.\nIt’s worth noting that while this code snippet demonstrates factoring a product of small prime numbers, for larger composite numbers, more efficient factoring algorithms are required. Nonetheless, the underlying principle remains the same: factoring the product of two large prime numbers is extremely challenging, forming the basis of the security behind RSA encryption.\nThe existence of a powerful quantum computer with the capability to execute Shor’s algorithm poses a significant threat to the security of RSA and other cryptographic systems that rely on the hardness of integer factorization. With a quantum computer, the time required to factorize large composite numbers would be reduced from exponential to polynomial, rendering RSA vulnerable to attacks.\nTo address these concerns, researchers are actively exploring post-quantum cryptography. The goal is to develop new encryption schemes that can resist attacks from both classical and quantum computers. These schemes rely on alternative mathematical problems that have no known efficient algorithms for quantum computers, providing a potential avenue for future secure communication."
  },
  {
    "objectID": "posts/integerfactorization/index.html#the-integer-factorization-problem-and-its-impact-on-rsa",
    "href": "posts/integerfactorization/index.html#the-integer-factorization-problem-and-its-impact-on-rsa",
    "title": "Integer Factorization Problem",
    "section": "",
    "text": "The integer factorization problem is a fundamental challenge in cryptography, with significant implications for the widely used RSA encryption scheme. Understanding this problem and its computational complexity provides insights into the security of RSA and the potential impact of quantum computing advancements.\nIn essence, the integer factorization problem involves breaking down a composite integer into its prime factors. While this task may seem simple for small numbers, it becomes exponentially more difficult as the size of the number increases. This property forms the basis of RSA encryption, where the security relies on the difficulty of factoring the product of two large prime numbers.\nClassical computers employ various algorithms, such as the General Number Field Sieve (GNFS) or the Quadratic Sieve (QS), to factorize composite integers. The time complexity of these algorithms grows significantly with the size of the number, making it increasingly time-consuming to factorize larger integers.\nLet’s see an example of how we can factorize the product of two small prime numbers using a Python code snippet:\n\ndef factorize_product(p, q):\n    n = p * q\n    factors = []\n    i = 2\n\n    while i * i &lt;= n:\n        if n % i:\n            i += 1\n        else:\n            n //= i\n            factors.append(i)\n\n    if n &gt; 1:\n        factors.append(n)\n\n    return factors\n\np = 7\nq = 11\nproduct = p * q\nprime_factors = factorize_product(p, q)\nprint(f\"The prime factors of {product} are: {prime_factors}\")\n\nThe prime factors of 77 are: [7, 11]\n\n\nIn the example, we factorize the product of two primes 7 and 11, which is 77. The code will output the prime factors: [7, 11], indicating that 77 can be factored into the primes 7 and 11.\nIn the code snippet above, we demonstrated the factorization of a product of two small prime numbers. However, it’s important to note that the security of RSA encryption relies on the difficulty of factoring much larger composite numbers. Typical RSA primes used in modern cryptographic systems can have lengths of 2048 bits to make a security level of 4096 bits. Factoring such large numbers using classical computers is an incredibly demanding computational task that is not reasonable to compute.\nTo put this into perspective, consider that breaking a 4096-bit RSA key by factoring the modulus is estimated to require trillions of years on current classical computing technology. This emphasizes the level of security provided by RSA encryption when implemented with sufficiently large prime numbers.\nIt’s worth noting that while this code snippet demonstrates factoring a product of small prime numbers, for larger composite numbers, more efficient factoring algorithms are required. Nonetheless, the underlying principle remains the same: factoring the product of two large prime numbers is extremely challenging, forming the basis of the security behind RSA encryption.\nThe existence of a powerful quantum computer with the capability to execute Shor’s algorithm poses a significant threat to the security of RSA and other cryptographic systems that rely on the hardness of integer factorization. With a quantum computer, the time required to factorize large composite numbers would be reduced from exponential to polynomial, rendering RSA vulnerable to attacks.\nTo address these concerns, researchers are actively exploring post-quantum cryptography. The goal is to develop new encryption schemes that can resist attacks from both classical and quantum computers. These schemes rely on alternative mathematical problems that have no known efficient algorithms for quantum computers, providing a potential avenue for future secure communication."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html",
    "href": "posts/shortestvectorproblem/index.html",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "Lattice-based cryptography has emerged as a powerful tool in modern cryptography, offering security guarantees and resilience against attacks from both classical and quantum computers. At the heart of lattice-based cryptography lies the Shortest Vector Problem (SVP) and a related problem the Closest Vector Problem, a fundamental computational problem with wide-ranging implications. In this blog post, we will delve into them both, their impact on cryptographic systems, and their practical applications.\n\n\n\nGiven a set of basis vectors which make up a lattice, the goal of the Shortest Vector Problem is to find the shortest non-zero vector in the lattice. The shortest vector is the vector with the smallest Euclidean norm. The Shortest Vector Problem is a hard problem to solve, and it is believed that there is no efficient algorithm to solve it. The Shortest Vector Problem is a NP-hard problem, meaning that it is at least as hard as any other problem in the class of NP problems.\n\n\n\nThe Closest Vector Problem is a related problem to the Shortest Vector Problem. Given a lattice and a target vector, the goal of the Closest Vector Problem is to find the closest vector in the lattice to the target vector. The Closest Vector Problem is also a hard problem to solve, and it is believed that there is no efficient algorithm to solve it. The Closest Vector Problem is also a NP-hard problem.\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Good Basis\nbasis_1_pair1 = np.array([2, 0])\nbasis_2_pair1 = np.array([0, 2])\n\n# Bad Basis\nbasis_1_pair2 = np.array([2, -6])\nbasis_2_pair2 = np.array([2, -8])\n\ngrid_size = 10\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_pair1 = np.array([(x, y) for x in x_values for y in y_values])\n\nlattice_transformed_pair1 = lattice_pair1[:, 0][:, None] * basis_1_pair1 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair1\n\nlattice_transformed_pair2 = lattice_pair1[:, 0][:, None] * basis_1_pair2 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair2\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_transformed_pair1[:, 0], lattice_transformed_pair1[:, 1], color='blue', label='Lattice')\nax.arrow(0, 0, basis_1_pair1[0], basis_1_pair1[1], color='red', width=0.1, label='Good Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair1[0], basis_2_pair1[1], color='red', width=0.1, length_includes_head=True)\n\nax.arrow(0, 0, basis_1_pair2[0], basis_1_pair2[1], color='green', width=0.1, label='Bad Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair2[0], basis_2_pair2[1], color='green', width=0.1, length_includes_head=True)\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn example of two different basis pairs. The red basis pair is a good basis pair, while the green basis pair is a bad basis pair.\n\n\n\n\nTo illustrate the concept of good and bad basis vectors, let’s consider an example. We can visualize a lattice and its basis vectors using two pairs. The first pair consists of basis vectors that are nearly perpendicular, while the second pair comprises basis vectors that are nearly parallel. By examining the resulting lattices, we can observe the impact of the choice of basis vectors on the lattice structure and its security properties.\nBob gives Alice the bad basis. Alice picks a point on the lattice (2, 2) that represents her message. She then adds a small error to the point and sends that point to Bob. Bob then uses the good basis to decode the message.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Basis vectors\nbasis_1 = np.array([2, 0])\nbasis_2 = np.array([0, 2])\n\ngrid_size = 3\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_points = np.array([(x, y) for x in x_values for y in y_values])\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_points[:, 0], lattice_points[:, 1], color='blue', label='Lattice')\n\npoint_1 = np.array([2, 2])  # Point on lattice representing message\npoint_2 = np.array([2.3, 2])  # Message with error added\n\nax.arrow(0, 0, point_1[0], point_1[1], color='green', width=0.1, length_includes_head=True)\n\nax.scatter(point_2[0], point_2[1], color='orange')\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn example of the encoded message and error added to point\n\n\n\n\nThis is very similar to how the Goldreich–Goldwasser–Halevi (GGH) lattice-based cryptosystem works.\n\n\n\nIn practice, lattice-based cryptosystems operate in high-dimensional spaces, which greatly enhances their security. The dimensionality of the lattice significantly increases the computational complexity of finding the shortest vector without access to the private key. As the dimensions increase, the search space for potential shortest vectors expands exponentially, making exhaustive search and other classical techniques infeasible. Quantum computers, despite their potential advantages, still face formidable challenges in solving the shortest vector problem for high-dimensional lattices. Their limited performance and the exponential growth of the problem’s complexity ensure that lattice-based cryptosystems remain secure against both classical and quantum attacks. Therefore, the use of high-dimensional lattices strengthens the security of lattice-based cryptosystems and solidifies their position as robust post-quantum cryptographic solutions.\n\n\n\nKyber, based on the pq-crystals framework, is a lattice-based post-quantum cryptosystem that offers secure communication through its Key Encapsulation Mechanism (KEM) and digital signature schemes. It provides robust security against attacks from classical and quantum adversaries by leveraging the hardness of lattice problems. Kyber strikes a balance between security and efficiency, allowing users to choose parameters based on their specific requirements. With its promising security properties and competitive performance, Kyber has emerged as a strong contender in the field of post-quantum cryptography.\nLattice-based cryptography finds applications in various domains. One notable application is Fully Homomorphic Encryption (FHE), which enables computations on encrypted data without the need for decryption. FHE has applications in privacy-preserving computations, secure outsourcing of computations, and secure machine learning.\n\n\n\nIn summary, the use of high-dimensional lattices in lattice-based cryptosystems provides a robust defense against attacks. The exponential growth of the search space, coupled with the limitations of classical and quantum computers, ensures that finding the shortest vector without the private key remains a nearly impossible task. This characteristic reinforces the post-quantum security offered by lattice-based cryptography and solidifies its position as a promising and resilient approach in the realm of modern cryptographic systems."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#introduction",
    "href": "posts/shortestvectorproblem/index.html#introduction",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "Lattice-based cryptography has emerged as a powerful tool in modern cryptography, offering security guarantees and resilience against attacks from both classical and quantum computers. At the heart of lattice-based cryptography lies the Shortest Vector Problem (SVP) and a related problem the Closest Vector Problem, a fundamental computational problem with wide-ranging implications. In this blog post, we will delve into them both, their impact on cryptographic systems, and their practical applications."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#example",
    "href": "posts/shortestvectorproblem/index.html#example",
    "title": "Shortest Vector Problem",
    "section": "",
    "text": "Code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Good Basis\nbasis_1_pair1 = np.array([2, 0])\nbasis_2_pair1 = np.array([0, 2])\n\n# Bad Basis\nbasis_1_pair2 = np.array([2, -6])\nbasis_2_pair2 = np.array([2, -8])\n\ngrid_size = 10\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_pair1 = np.array([(x, y) for x in x_values for y in y_values])\n\nlattice_transformed_pair1 = lattice_pair1[:, 0][:, None] * basis_1_pair1 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair1\n\nlattice_transformed_pair2 = lattice_pair1[:, 0][:, None] * basis_1_pair2 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair2\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_transformed_pair1[:, 0], lattice_transformed_pair1[:, 1], color='blue', label='Lattice')\nax.arrow(0, 0, basis_1_pair1[0], basis_1_pair1[1], color='red', width=0.1, label='Good Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair1[0], basis_2_pair1[1], color='red', width=0.1, length_includes_head=True)\n\nax.arrow(0, 0, basis_1_pair2[0], basis_1_pair2[1], color='green', width=0.1, label='Bad Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair2[0], basis_2_pair2[1], color='green', width=0.1, length_includes_head=True)\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn example of two different basis pairs. The red basis pair is a good basis pair, while the green basis pair is a bad basis pair.\n\n\n\n\nTo illustrate the concept of good and bad basis vectors, let’s consider an example. We can visualize a lattice and its basis vectors using two pairs. The first pair consists of basis vectors that are nearly perpendicular, while the second pair comprises basis vectors that are nearly parallel. By examining the resulting lattices, we can observe the impact of the choice of basis vectors on the lattice structure and its security properties.\nBob gives Alice the bad basis. Alice picks a point on the lattice (2, 2) that represents her message. She then adds a small error to the point and sends that point to Bob. Bob then uses the good basis to decode the message.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Basis vectors\nbasis_1 = np.array([2, 0])\nbasis_2 = np.array([0, 2])\n\ngrid_size = 5\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_points = np.array([(x, y) for x in x_values for y in y_values])\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_points[:, 0], lattice_points[:, 1], color='blue')\n\nax.arrow(0, 0, basis_1[0], basis_1[1], color='red', width=0.1, length_includes_head=True)\nax.arrow(0, 0, basis_2[0], basis_2[1], color='red', width=0.1, length_includes_head=True)\n\npoint_1 = np.array([2, 2])  # Point on lattice representing message\npoint_2 = np.array([2.3, 2])  # Message with error added\n\nax.arrow(0, 0, point_1[0], point_1[1], color='green', width=0.1, length_includes_head=True)\n\nax.scatter(point_2[0], point_2[1], color='orange')\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n\n\n\n\n\nAn example of the encoded message and error added to point\n\n\n\n\nThis is very similar to how the Goldreich–Goldwasser–Halevi (GGH) lattice-based cryptosystem works."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#dimensionality-in-practice",
    "href": "posts/shortestvectorproblem/index.html#dimensionality-in-practice",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "In practice, lattice-based cryptosystems operate in high-dimensional spaces, which greatly enhances their security. The dimensionality of the lattice significantly increases the computational complexity of finding the shortest vector without access to the private key. As the dimensions increase, the search space for potential shortest vectors expands exponentially, making exhaustive search and other classical techniques infeasible. Quantum computers, despite their potential advantages, still face formidable challenges in solving the shortest vector problem for high-dimensional lattices. Their limited performance and the exponential growth of the problem’s complexity ensure that lattice-based cryptosystems remain secure against both classical and quantum attacks. Therefore, the use of high-dimensional lattices strengthens the security of lattice-based cryptosystems and solidifies their position as robust post-quantum cryptographic solutions."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#applications",
    "href": "posts/shortestvectorproblem/index.html#applications",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "Kyber, based on the pq-crystals framework, is a lattice-based post-quantum cryptosystem that offers secure communication through its Key Encapsulation Mechanism (KEM) and digital signature schemes. It provides robust security against attacks from classical and quantum adversaries by leveraging the hardness of lattice problems. Kyber strikes a balance between security and efficiency, allowing users to choose parameters based on their specific requirements. With its promising security properties and competitive performance, Kyber has emerged as a strong contender in the field of post-quantum cryptography.\nLattice-based cryptography finds applications in various domains. One notable application is Fully Homomorphic Encryption (FHE), which enables computations on encrypted data without the need for decryption. FHE has applications in privacy-preserving computations, secure outsourcing of computations, and secure machine learning."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#conclusion",
    "href": "posts/shortestvectorproblem/index.html#conclusion",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "In summary, the use of high-dimensional lattices in lattice-based cryptosystems provides a robust defense against attacks. The exponential growth of the search space, coupled with the limitations of classical and quantum computers, ensures that finding the shortest vector without the private key remains a nearly impossible task. This characteristic reinforces the post-quantum security offered by lattice-based cryptography and solidifies its position as a promising and resilient approach in the realm of modern cryptographic systems."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#shortest-vector-problem",
    "href": "posts/shortestvectorproblem/index.html#shortest-vector-problem",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "Given a set of basis vectors which make up a lattice, the goal of the Shortest Vector Problem is to find the shortest non-zero vector in the lattice. The shortest vector is the vector with the smallest Euclidean norm. The Shortest Vector Problem is a hard problem to solve, and it is believed that there is no efficient algorithm to solve it. The Shortest Vector Problem is a NP-hard problem, meaning that it is at least as hard as any other problem in the class of NP problems."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#closest-vector-problem",
    "href": "posts/shortestvectorproblem/index.html#closest-vector-problem",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "The Closest Vector Problem is a related problem to the Shortest Vector Problem. Given a lattice and a target vector, the goal of the Closest Vector Problem is to find the closest vector in the lattice to the target vector. The Closest Vector Problem is also a hard problem to solve, and it is believed that there is no efficient algorithm to solve it. The Closest Vector Problem is also a NP-hard problem."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#example-of-closest-vector-problem",
    "href": "posts/shortestvectorproblem/index.html#example-of-closest-vector-problem",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "Code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Good Basis\nbasis_1_pair1 = np.array([2, 0])\nbasis_2_pair1 = np.array([0, 2])\n\n# Bad Basis\nbasis_1_pair2 = np.array([2, -6])\nbasis_2_pair2 = np.array([2, -8])\n\ngrid_size = 10\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_pair1 = np.array([(x, y) for x in x_values for y in y_values])\n\nlattice_transformed_pair1 = lattice_pair1[:, 0][:, None] * basis_1_pair1 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair1\n\nlattice_transformed_pair2 = lattice_pair1[:, 0][:, None] * basis_1_pair2 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair2\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_transformed_pair1[:, 0], lattice_transformed_pair1[:, 1], color='blue', label='Lattice')\nax.arrow(0, 0, basis_1_pair1[0], basis_1_pair1[1], color='red', width=0.1, label='Good Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair1[0], basis_2_pair1[1], color='red', width=0.1, length_includes_head=True)\n\nax.arrow(0, 0, basis_1_pair2[0], basis_1_pair2[1], color='green', width=0.1, label='Bad Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair2[0], basis_2_pair2[1], color='green', width=0.1, length_includes_head=True)\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn example of two different basis pairs. The red basis pair is a good basis pair, while the green basis pair is a bad basis pair.\n\n\n\n\nTo illustrate the concept of good and bad basis vectors, let’s consider an example. We can visualize a lattice and its basis vectors using two pairs. The first pair consists of basis vectors that are nearly perpendicular, while the second pair comprises basis vectors that are nearly parallel. By examining the resulting lattices, we can observe the impact of the choice of basis vectors on the lattice structure and its security properties.\nBob gives Alice the bad basis. Alice picks a point on the lattice (2, 2) that represents her message. She then adds a small error to the point and sends that point to Bob. Bob then uses the good basis to decode the message.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Basis vectors\nbasis_1 = np.array([2, 0])\nbasis_2 = np.array([0, 2])\n\ngrid_size = 3\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_points = np.array([(x, y) for x in x_values for y in y_values])\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_points[:, 0], lattice_points[:, 1], color='blue', label='Lattice')\n\npoint_1 = np.array([2, 2])  # Point on lattice representing message\npoint_2 = np.array([2.3, 2])  # Message with error added\n\nax.arrow(0, 0, point_1[0], point_1[1], color='green', width=0.1, length_includes_head=True)\n\nax.scatter(point_2[0], point_2[1], color='orange')\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn example of the encoded message and error added to point\n\n\n\n\nThis is very similar to how the Goldreich–Goldwasser–Halevi (GGH) lattice-based cryptosystem works."
  },
  {
    "objectID": "posts/modulararithmetic/index.html",
    "href": "posts/modulararithmetic/index.html",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Modular arithmetic is a fascinating branch of mathematics that deals with integers and their remainders. It has various applications in fields like cryptography, computer science, and number theory. In this blog post, we’ll dive into the basics of modular arithmetic and explore different operations using interactive Manim animations.\n\n\nModular arithmetic involves performing operations on numbers within a fixed range, called a modulus. The modulus acts as a wrapping point, where numbers “wrap around” when they exceed the modulus. This wrapping behavior provides interesting properties and patterns.\n\n\n\nLet’s explore modular addition using an example. Suppose we want to add 4 and 4 modulo 5.\nHere are the steps for the equation \\(4 + 4 = 3 \\mod{5 }\\) using modular arithmetic:\nStep 1: Start with the addition of 4 and 4: \\(4 + 4 = 8\\).\nStep 2: Apply the modulus operation with a modulus of 5. Divide the result (8) by the modulus (5) and find the remainder: \\(8 = 3 \\mod{5}\\).\nStep 3: The final result is 3, indicating that when we add 4 and 4 within the modulus of 5, the remainder is 3.\n\n\n\nSubtraction works similarly in modular arithmetic. Let’s work through the equation \\(4 - 8 \\mod{3}\\) using modular arithmetic:\nStep 1: Start with the subtraction of 8 from 4: \\(4 - 8 = -4\\).\nStep 2: Since the result is negative, we need to add the modulus to make it positive. In this case, the modulus is 3, so we add 3 to -4: \\(-4 + 3 = -1\\).\nStep 3: Take the result modulo 3: \\(-1 = 2 \\mod{3}\\).\nStep 4: The final result is 2, indicating that when we subtract 8 from 4 within the modulus of 3, the remainder is 2.\n\n\n\nLet’s work through the equation \\(3 * 4 \\mod{7}\\) using modular arithmetic:\nStep 1: Start with the multiplication of 3 and 4: \\(3 * 4 = 12\\).\nStep 2: Take the result modulo 7: \\(12 = 5 \\mod{7}\\).\nStep 3: The final result is 5, indicating that when we multiply 3 by 4 within the modulus of 7, the remainder is 5.\nIn modular arithmetic, the result of multiplication is obtained by taking the modulo of the product, ensuring that the final result falls within the defined range determined by the modulus.\n\n\n\nThe modular inverse is another essential operation in modular arithmetic. It involves finding the number that, when multiplied by a given number modulo a specified modulus, yields a result of 1. Let’s compute the modular inverse of 3 modulo 10. Here’s an animation showcasing modular inverse on a number line:\nLet’s go through the steps to find the modular inverse:\nStep 1: Try different values for the inverse starting from 1 and going up. Multiply each value by 3 and take the result modulo 10.\n\n\\(1 * 3 = 3 \\mod{10}\\)\n\\(2 * 3 = 6 \\mod{10}\\)\n\\(3 * 3 = 9 \\mod{10}\\)\n\\(4 * 3 = 2 \\mod{10}\\)\n\\(5 * 3 = 5 \\mod{10}\\)\n\\(6 * 3 = 8 \\mod{10}\\)\n\\(7 * 3 = 1 \\mod{10}\\)\n\nStep 2: We found that when we multiply 7 by 3 and take the result modulo 10, we get 1. Therefore, the modular inverse of 3 mod 10 is 7.\nAfter finding the modular inverse of 3 mod 10 as 7 using a naive method, let’s discuss a more efficient approach to find modular inverses using the extended Euclidean algorithm.\nThe extended Euclidean algorithm is a well-known algorithm for finding the greatest common divisor (GCD) of two numbers and obtaining their Bézout coefficients, which can be used to find the modular inverse.\nIn the case of finding the modular inverse of 3 mod 10, we can apply the extended Euclidean algorithm as follows:\nStep 1: Start with the original numbers 3 and 10.\nStep 2: Apply the extended Euclidean algorithm to find the GCD and Bézout coefficients. The algorithm provides us with the values of x and y, such that:\n\\(GCD(3, 10) = 3 * x + 10 * y\\)\nStep 3: If the GCD is equal to 1, then the modular inverse exists. In this case, it means that there is a number, let’s call it “m”, such that:\n\\(3 * m = 1 \\mod{10}\\)\nStep 4: The value of “m” obtained from the extended Euclidean algorithm is the modular inverse of \\(3 \\mod{10}\\).\nUsing the extended Euclidean algorithm provides a more efficient way to find modular inverses compared to the naive method of trying different values. This algorithm has a time complexity of O(log N), where N is the larger of the two numbers involved.\nIf you want to learn more about the extended Euclidean algorithm and how to implement it, check out this post on Brilliant.\n\n\n\nFinding the square root in modular arithmetic involves finding a number that, when squared, gives a result equivalent to a given value modulo a specified modulus. Let’s go through an example to illustrate the steps involved.\nExample: Find the square root of 5 modulo 11.\nStep 1: Begin with the given value, which is 5.\nStep 2: Try different numbers from 0 to 10 as potential square roots. Square each number and take the result modulo 11.\n\n\\(0^2 = 0 \\mod{11}\\)\n\\(1^2 = 1 \\mod{11}\\)\n\\(2^2 = 4 \\mod{11}\\)\n\\(3^2 = 9 \\mod{11}\\)\n\\(4^2 = 5 \\mod{11}\\)\n\\(5^2 = 3 \\mod{11}\\)\n\\(6^2 = 3 \\mod{11}\\)\n\\(7^2 = 5 \\mod{11}\\)\n\\(8^2 = 9 \\mod{11}\\)\n\\(9^2 = 4 \\mod{11}\\)\n\\(10^2 = 1 \\mod{11}\\)\n\nStep 3: We found that when we square 4 and 7, we obtain a result of 5 modulo 11. Therefore, the square roots of 5 modulo 11 are 4 and 7.\nIt’s important to note that in modular arithmetic, a number can have multiple square roots or no square roots at all, depending on the value and modulus involved.\nTo find square roots in modular arithmetic, a more efficient approach is to use Euler’s criterion along with the properties of quadratic residues. Euler’s criterion states that for an odd prime modulus p and an integer a, if \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is congruent to 1, then a has a square root modulo p.\nHere’s a more efficient method to find square roots modulo a prime modulus:\n\nGiven a value a and a prime modulus p, check if a is a quadratic residue modulo p. This can be done by calculating \\(a^{\\frac{p-1}{2}} \\mod{p}\\).\nIf \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is not congruent to 1, then a has no square root modulo p.\nIf \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is congruent to 1, we can proceed to calculate the square root using the Tonelli-Shanks algorithm or other square root algorithms specifically designed for modular arithmetic. These algorithms involve solving modular equations and finding the appropriate values.\n\nThe Tonelli-Shanks algorithm is a popular algorithm for finding square roots in modular arithmetic, especially for large prime moduli.\nIt’s important to note that finding square roots in modular arithmetic can be complex, especially for non-prime moduli. The methods described above are specific to prime moduli and may not directly apply to composite moduli.\n\n\n\nModular arithmetic provides a unique perspective on numbers and operations within a fixed range. It exhibits interesting patterns and behaviors that have practical applications in various fields. We explored modular addition, subtraction, multiplication, square root, and modular inverses. I hope you enjoyed this introduction to modular arithmetic! In a future post I’ll explore more advanced topics in modular arithmetic, so stay tuned!"
  },
  {
    "objectID": "posts/modulararithmetic/index.html#what-is-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#what-is-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Modular arithmetic involves performing operations on numbers within a fixed range, called a modulus. The modulus acts as a wrapping point, where numbers “wrap around” when they exceed the modulus. This wrapping behavior provides interesting properties and patterns."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#addition-in-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#addition-in-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Let’s explore modular addition using an example. Suppose we want to add 4 and 4 modulo 5.\nHere are the steps for the equation \\(4 + 4 = 3 \\mod{5 }\\) using modular arithmetic:\nStep 1: Start with the addition of 4 and 4: \\(4 + 4 = 8\\).\nStep 2: Apply the modulus operation with a modulus of 5. Divide the result (8) by the modulus (5) and find the remainder: \\(8 = 3 \\mod{5}\\).\nStep 3: The final result is 3, indicating that when we add 4 and 4 within the modulus of 5, the remainder is 3."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#subtraction-in-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#subtraction-in-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Subtraction works similarly in modular arithmetic. Let’s work through the equation \\(4 - 8 \\mod{3}\\) using modular arithmetic:\nStep 1: Start with the subtraction of 8 from 4: \\(4 - 8 = -4\\).\nStep 2: Since the result is negative, we need to add the modulus to make it positive. In this case, the modulus is 3, so we add 3 to -4: \\(-4 + 3 = -1\\).\nStep 3: Take the result modulo 3: \\(-1 = 2 \\mod{3}\\).\nStep 4: The final result is 2, indicating that when we subtract 8 from 4 within the modulus of 3, the remainder is 2."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#multiplication-in-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#multiplication-in-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Let’s work through the equation \\(3 * 4 \\mod{7}\\) using modular arithmetic:\nStep 1: Start with the multiplication of 3 and 4: \\(3 * 4 = 12\\).\nStep 2: Take the result modulo 7: \\(12 = 5 \\mod{7}\\).\nStep 3: The final result is 5, indicating that when we multiply 3 by 4 within the modulus of 7, the remainder is 5.\nIn modular arithmetic, the result of multiplication is obtained by taking the modulo of the product, ensuring that the final result falls within the defined range determined by the modulus."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#square-root-in-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#square-root-in-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Finding the square root in modular arithmetic involves finding a number that, when squared, gives a result equivalent to a given value modulo a specified modulus. Let’s go through an example to illustrate the steps involved.\nExample: Find the square root of 5 modulo 11.\nStep 1: Begin with the given value, which is 5.\nStep 2: Try different numbers from 0 to 10 as potential square roots. Square each number and take the result modulo 11.\n\n\\(0^2 = 0 \\mod{11}\\)\n\\(1^2 = 1 \\mod{11}\\)\n\\(2^2 = 4 \\mod{11}\\)\n\\(3^2 = 9 \\mod{11}\\)\n\\(4^2 = 5 \\mod{11}\\)\n\\(5^2 = 3 \\mod{11}\\)\n\\(6^2 = 3 \\mod{11}\\)\n\\(7^2 = 5 \\mod{11}\\)\n\\(8^2 = 9 \\mod{11}\\)\n\\(9^2 = 4 \\mod{11}\\)\n\\(10^2 = 1 \\mod{11}\\)\n\nStep 3: We found that when we square 4 and 7, we obtain a result of 5 modulo 11. Therefore, the square roots of 5 modulo 11 are 4 and 7.\nIt’s important to note that in modular arithmetic, a number can have multiple square roots or no square roots at all, depending on the value and modulus involved.\nTo find square roots in modular arithmetic, a more efficient approach is to use Euler’s criterion along with the properties of quadratic residues. Euler’s criterion states that for an odd prime modulus p and an integer a, if \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is congruent to 1, then a has a square root modulo p.\nHere’s a more efficient method to find square roots modulo a prime modulus:\n\nGiven a value a and a prime modulus p, check if a is a quadratic residue modulo p. This can be done by calculating \\(a^{\\frac{p-1}{2}} \\mod{p}\\).\nIf \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is not congruent to 1, then a has no square root modulo p.\nIf \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is congruent to 1, we can proceed to calculate the square root using the Tonelli-Shanks algorithm or other square root algorithms specifically designed for modular arithmetic. These algorithms involve solving modular equations and finding the appropriate values.\n\nThe Tonelli-Shanks algorithm is a popular algorithm for finding square roots in modular arithmetic, especially for large prime moduli.\nIt’s important to note that finding square roots in modular arithmetic can be complex, especially for non-prime moduli. The methods described above are specific to prime moduli and may not directly apply to composite moduli."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#modular-inverse-in-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#modular-inverse-in-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "The modular inverse is another essential operation in modular arithmetic. It involves finding the number that, when multiplied by a given number modulo a specified modulus, yields a result of 1. Let’s compute the modular inverse of 3 modulo 10. Here’s an animation showcasing modular inverse on a number line:\nLet’s go through the steps to find the modular inverse:\nStep 1: Try different values for the inverse starting from 1 and going up. Multiply each value by 3 and take the result modulo 10.\n\n\\(1 * 3 = 3 \\mod{10}\\)\n\\(2 * 3 = 6 \\mod{10}\\)\n\\(3 * 3 = 9 \\mod{10}\\)\n\\(4 * 3 = 2 \\mod{10}\\)\n\\(5 * 3 = 5 \\mod{10}\\)\n\\(6 * 3 = 8 \\mod{10}\\)\n\\(7 * 3 = 1 \\mod{10}\\)\n\nStep 2: We found that when we multiply 7 by 3 and take the result modulo 10, we get 1. Therefore, the modular inverse of 3 mod 10 is 7.\nAfter finding the modular inverse of 3 mod 10 as 7 using a naive method, let’s discuss a more efficient approach to find modular inverses using the extended Euclidean algorithm.\nThe extended Euclidean algorithm is a well-known algorithm for finding the greatest common divisor (GCD) of two numbers and obtaining their Bézout coefficients, which can be used to find the modular inverse.\nIn the case of finding the modular inverse of 3 mod 10, we can apply the extended Euclidean algorithm as follows:\nStep 1: Start with the original numbers 3 and 10.\nStep 2: Apply the extended Euclidean algorithm to find the GCD and Bézout coefficients. The algorithm provides us with the values of x and y, such that:\n\\(GCD(3, 10) = 3 * x + 10 * y\\)\nStep 3: If the GCD is equal to 1, then the modular inverse exists. In this case, it means that there is a number, let’s call it “m”, such that:\n\\(3 * m = 1 \\mod{10}\\)\nStep 4: The value of “m” obtained from the extended Euclidean algorithm is the modular inverse of \\(3 \\mod{10}\\).\nUsing the extended Euclidean algorithm provides a more efficient way to find modular inverses compared to the naive method of trying different values. This algorithm has a time complexity of O(log N), where N is the larger of the two numbers involved.\nIf you want to learn more about the extended Euclidean algorithm and how to implement it, check out this post on Brilliant."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#conclusion",
    "href": "posts/modulararithmetic/index.html#conclusion",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Modular arithmetic provides a unique perspective on numbers and operations within a fixed range. It exhibits interesting patterns and behaviors that have practical applications in various fields. We explored modular addition, subtraction, multiplication, square root, and modular inverses. I hope you enjoyed this introduction to modular arithmetic! In a future post I’ll explore more advanced topics in modular arithmetic, so stay tuned!"
  },
  {
    "objectID": "posts/groupsfieldsrings/index.html",
    "href": "posts/groupsfieldsrings/index.html",
    "title": "Groups, Rings, and Fields",
    "section": "",
    "text": "Groups, fields, and rings are fundamental mathematical structures that play a crucial role in various cryptographic algorithms. Let’s explore the definitions of these structures and their applications in cryptography.\n\n\nA group is a mathematical structure that consists of a set G along with a binary operation * defined on G. For G to be a group, the following conditions must hold:\n\nClosure: For any elements a and b in G, the result of the operation a * b is also in G.\nAssociativity: The operation * is associative, meaning that for any- elements a, b, and c in G, the expression (a * b) * c is equal to a * (b * c).\nIdentity element: There exists an identity element e in G such that for any element a in G, the equation a * e = e * a = a holds.\nInverses: For every element a in G, there exists an inverse element a⁻¹ in G such that a * a⁻¹ = a⁻¹ * a = e.\n\nAn Abelian group, also known as a commutative group, is a specific type of group where the operation is commutative. In other words, the order in which elements are combined does not affect the result. This property allows for a more simplified structure and often leads to interesting mathematical properties.\nGroups find extensive use in cryptography, particularly in symmetric key algorithms and elliptic curve cryptography. The properties of groups, such as associativity and inverses, are leveraged to achieve secure cryptographic operations.\n\n\n\nA ring is a mathematical structure that combines the operations of addition (+) and multiplication (×). A ring R consists of a set along with two operations: addition and multiplication. For R to be a ring, the following conditions must hold:\n\nR, under addition, forms an Abelian group.\nR, under multiplication, is closed, associative, and has a multiplicative identity element.\nMultiplication distributes over addition.\n\nRings find applications in various areas of mathematics and cryptography, such as error-correcting codes and digital signatures.\n\n\n\nA field is an algebraic structure that extends the concept of a group by introducing a second binary operation, typically denoted as + and ×. A field F consists of a set along with two operations: addition (+) and multiplication (×). For F to be a field, the following conditions must hold:\n\nF, under addition, forms an Abelian group with an identity element 0 and additive inverses.\nF, excluding the additive identity, under multiplication, forms an Abelian group with an identity element 1 and multiplicative inverses.\nDistributivity: For any elements a, b, and c in F, the equation a × (b + c) = (a × b) + (a × c) holds.\n\nFields are essential in cryptography, particularly in public key algorithms. They provide the mathematical framework for operations like modular arithmetic, which forms the basis for secure encryption and digital signatures.\n\n\n\nGroups, fields, and rings are essential mathematical structures that provide a foundation for many cryptographic algorithms. They enable the design and implementation of cryptographic primitives that offer security properties such as confidentiality, integrity, and authenticity.\nFor example, in public key cryptography, the discrete logarithm problem and elliptic curve discrete logarithm problem are formulated within groups or fields. The hardness of these problems forms the basis of cryptographic schemes like the Diffie-Hellman key exchange, Digital Signature Algorithm (DSA), and Elliptic Curve Cryptography (ECC).\nFields and rings also play a crucial role in error-correcting codes used in data transmission and storage. These codes rely on algebraic structures to encode and decode data, ensuring reliable and accurate transmission.\nIn conclusion, groups, fields, and rings provide mathematical frameworks that underpin cryptography and other areas of mathematics. Understanding these structures and their properties is essential for developing secure cryptographic algorithms and systems. By leveraging the properties of these structures, we can design encryption schemes, digital signatures, and other cryptographic primitives that protect sensitive information in various applications."
  },
  {
    "objectID": "posts/groupsfieldsrings/index.html#groups",
    "href": "posts/groupsfieldsrings/index.html#groups",
    "title": "Groups, Rings, and Fields",
    "section": "",
    "text": "A group is a mathematical structure that consists of a set G along with a binary operation * defined on G. For G to be a group, the following conditions must hold:\n\nClosure: For any elements a and b in G, the result of the operation a * b is also in G.\nAssociativity: The operation * is associative, meaning that for any- elements a, b, and c in G, the expression (a * b) * c is equal to a * (b * c).\nIdentity element: There exists an identity element e in G such that for any element a in G, the equation a * e = e * a = a holds.\nInverses: For every element a in G, there exists an inverse element a⁻¹ in G such that a * a⁻¹ = a⁻¹ * a = e.\n\nAn Abelian group, also known as a commutative group, is a specific type of group where the operation is commutative. In other words, the order in which elements are combined does not affect the result. This property allows for a more simplified structure and often leads to interesting mathematical properties.\nGroups find extensive use in cryptography, particularly in symmetric key algorithms and elliptic curve cryptography. The properties of groups, such as associativity and inverses, are leveraged to achieve secure cryptographic operations."
  },
  {
    "objectID": "posts/groupsfieldsrings/index.html#fields",
    "href": "posts/groupsfieldsrings/index.html#fields",
    "title": "Groups, Rings, and Fields",
    "section": "",
    "text": "A field is an algebraic structure that extends the concept of a group by introducing a second binary operation, typically denoted as + and ×. A field F consists of a set along with two operations: addition (+) and multiplication (×). For F to be a field, the following conditions must hold:\n\nF, under addition, forms an Abelian group with an identity element 0 and additive inverses.\nF, excluding the additive identity, under multiplication, forms an Abelian group with an identity element 1 and multiplicative inverses.\nDistributivity: For any elements a, b, and c in F, the equation a × (b + c) = (a × b) + (a × c) holds.\n\nFields are essential in cryptography, particularly in public key algorithms. They provide the mathematical framework for operations like modular arithmetic, which forms the basis for secure encryption and digital signatures."
  },
  {
    "objectID": "posts/groupsfieldsrings/index.html#rings",
    "href": "posts/groupsfieldsrings/index.html#rings",
    "title": "Groups, Rings, and Fields",
    "section": "",
    "text": "A ring is a mathematical structure that combines the operations of addition (+) and multiplication (×). A ring R consists of a set along with two operations: addition and multiplication. For R to be a ring, the following conditions must hold:\n\nR, under addition, forms an Abelian group.\nR, under multiplication, is closed, associative, and has a multiplicative identity element.\nMultiplication distributes over addition.\n\nRings find applications in various areas of mathematics and cryptography, such as error-correcting codes and digital signatures."
  },
  {
    "objectID": "posts/groupsfieldsrings/index.html#cryptographic-applications",
    "href": "posts/groupsfieldsrings/index.html#cryptographic-applications",
    "title": "Groups, Rings, and Fields",
    "section": "",
    "text": "Groups, fields, and rings are essential mathematical structures that provide a foundation for many cryptographic algorithms. They enable the design and implementation of cryptographic primitives that offer security properties such as confidentiality, integrity, and authenticity.\nFor example, in public key cryptography, the discrete logarithm problem and elliptic curve discrete logarithm problem are formulated within groups or fields. The hardness of these problems forms the basis of cryptographic schemes like the Diffie-Hellman key exchange, Digital Signature Algorithm (DSA), and Elliptic Curve Cryptography (ECC).\nFields and rings also play a crucial role in error-correcting codes used in data transmission and storage. These codes rely on algebraic structures to encode and decode data, ensuring reliable and accurate transmission.\nIn conclusion, groups, fields, and rings provide mathematical frameworks that underpin cryptography and other areas of mathematics. Understanding these structures and their properties is essential for developing secure cryptographic algorithms and systems. By leveraging the properties of these structures, we can design encryption schemes, digital signatures, and other cryptographic primitives that protect sensitive information in various applications."
  },
  {
    "objectID": "posts/lwe/index.html",
    "href": "posts/lwe/index.html",
    "title": "Learning With Errors",
    "section": "",
    "text": "The Learning With Errors (LWE) problem is a mathematical problem that plays a significant role in modern cryptographic schemes. It is based on the concept of finding a solution to a system of linear equations with errors. Let’s explore the LWE problem and its applications in cryptography. Problem Statement\nThis problem is incredibly similar to the shortest vector problem (SVP) and the closest vector problem (CVP). I suggest you read that article first if you haven’t already.\n\n\nThe LWE problem can be formulated as the equation \\(A⋅s+e=b\\mod{p}\\), where:\n\n\\(A\\) is the public key matrix,\n\\(s\\) is the secret vector,\n\\(e\\) is the noise vector,\n\\(b\\) is the resulting ciphertext vector, and\n\\(p\\) is a modulus.\n\nLet’s walk through a concrete example to illustrate how the Learning With Errors (LWE) problem can be used for encryption. We will use small values to demonstrate the process.\nSuppose we have the following parameters:\n\nPublic Key Matrix \\(A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}\\)\nModulus \\(p = 7\\)\nSecret Vector \\(s = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}\\)\nNoise Vector \\(e = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\\)\n\n\n\nCode\nfrom IPython.display import display, Math, Latex\nimport numpy as np\n\n# From KMChris\n# https://gist.github.com/KMChris/8fd878826453c3d55814b3293c7b084c\ndef print_matrix(array):\n    matrix = ''\n    for row in array:\n        try:\n            for number in row:\n                matrix += f'{number}&'\n        except TypeError:\n            matrix += f'{row}&'\n        matrix = matrix[:-1] + r'\\\\'\n    return r'\\begin{bmatrix}'+matrix+r'\\end{bmatrix}'\n\nq = 7\nA=np.array([[1 ,2],[3, 4]])\nsA = np.array([[5],[9]])\neA = np.array([[2],[-1]])\nbA = np.matmul(A,sA)%q\nbA = np.add(bA,eA)%q\n\nmatrix = r\"b = \" + print_matrix(A)\nmatrix += r\" * \" + print_matrix(sA)\nmatrix += r\" + \" + print_matrix(eA)\nmatrix += r\" \\mod{\" + str(q) + r\"}\"\nmatrix += r\" = \" + print_matrix(bA)\n\nmatrix = Math(matrix)\n\ndisplay(matrix)\n\n\n\\(\\displaystyle b = \\begin{bmatrix}1&2\\\\3&4\\\\\\end{bmatrix} * \\begin{bmatrix}5\\\\9\\\\\\end{bmatrix} + \\begin{bmatrix}2\\\\-1\\\\\\end{bmatrix} \\mod{7} = \\begin{bmatrix}4\\\\1\\\\\\end{bmatrix}\\)\nAn example of encryption using LWE\n\n\nTo encrypt the message of length \\(n\\) represented in binary (which has t number of different values), we sample \\(n\\) rows from \\(A\\) and the corresponding values from \\(b\\). We add up all the rows into a single equation and we add \\(\\lfloor\\frac{q}{t}\\rfloor\\) to \\(b\\).\nIn this case we will only use a single row, but the same process still applies.\n\n\\([1 \\quad 2] = 4\\)\n\nIf our message is the bit 1, we add \\(\\lfloor\\frac{q}{2}\\rfloor\\) to \\(b\\):\n\n\\([1 \\quad 2] = 4 + \\lfloor\\frac{q}{2}\\rfloor = 7\\)\n\nIf our message is the big 0, we add \\(0\\) to \\(b\\):\n\n\\([1 \\quad 2] = 4\\)\n\nNext, the person with the secret key multiplies the ciphertext vector \\(b\\) by the secret vector \\(s\\) and takes the result modulo \\(p\\) to obtain the original message. There is a small error, but this is removed by rounding the result to the nearest value representing a bit. In our case it is rounded to either 0 representing 0 or 7 representing 1.\n\n\nCode\nprint(\"A_rows * sA % q = correct\")\nprint(\"b_row - correct = encoded\")\n\n# Encoded 1 bit\nA_row = np.array([1, 2])\nb_row = 7\n\ncorrect = np.matmul(A_row,sA)%q\n\nencoded = b_row - correct\n\nprint(f\"1 bit which should be very close to 7: {encoded}\")\n\n# Encoded 0 bit\nA_row = np.array([1, 2])\nb_row = 4\n\ncorrect = np.matmul(A_row,sA)%q\n\nencoded = b_row - correct\nprint(f\"0 bit which should be very close to 0: {encoded}\")\n\n\nA_rows * sA % q = correct\nb_row - correct = encoded\n1 bit which should be very close to 7: [5]\n0 bit which should be very close to 0: [2]\n\n\n\n\n\nFully Homomorphic Encryption (FHE) is a revolutionary cryptographic scheme that allows computations to be performed directly on encrypted data, without the need for decryption. FHE based on LWE enables secure computation on sensitive data while preserving privacy. It allows for powerful operations like addition and multiplication to be performed on encrypted data, providing a practical solution for secure computation in various applications, such as privacy-preserving data analysis and secure outsourcing of computations.\nKyber is a post-quantum secure key encapsulation mechanism (KEM) based on LWE. It is designed to provide secure key exchange in the presence of powerful quantum computers. Kyber uses the LWE problem to generate cryptographic keys, ensuring that the exchanged keys remain secure even if an adversary has access to quantum computing resources. Kyber is a promising candidate for secure communication in a post-quantum world, offering strong security guarantees and efficient performance.\nBoth TFHE (The Fully Homomorphic Encryption Library) and Kyber highlight the practical applications of the LWE problem in constructing advanced cryptographic algorithms. By leveraging the mathematical hardness of the LWE problem, these algorithms provide secure and efficient solutions for various cryptographic tasks, contributing to the development of post-quantum secure systems.\n\n\n\nThe Learning With Errors (LWE) problem is closely related to other lattice-based problems, including Ring Learning With Errors (RLWE) and General Learning With Errors (GLWE). These problems share similar mathematical structures and serve as the foundation for various cryptographic schemes.\nRLWE extends the LWE problem by introducing an additional algebraic structure called a ring. It involves working with polynomials instead of vectors, which offers certain advantages in cryptographic constructions. RLWE allows for the development of efficient encryption schemes, such as the NTRUEncrypt scheme, which provides post-quantum security.\nGLWE generalizes the LWE problem by considering a more general form of noise distribution. It allows for more flexibility in the noise generation process and offers enhanced security guarantees. GLWE is utilized in cryptographic constructions such as functional encryption and obfuscation, enabling advanced functionalities like fine-grained access control and program obfuscation.\n\n\n\nIn conclusion, the Learning With Errors (LWE) problem is a powerful mathematical framework that has gained significant attention in the field of post-quantum cryptography. Its security is based on the presumed hardness of finding the secret key from the public key, even when given noisy and seemingly random equations. The LWE problem offers a promising approach to building cryptographic schemes that are resilient against attacks from both classical and quantum computers. As researchers continue to explore and develop new algorithms and techniques in this area, the LWE problem holds great potential for providing secure communication and protecting sensitive information in the era of quantum computing."
  },
  {
    "objectID": "posts/lwe/index.html#example-encryption-using-learning-with-errors",
    "href": "posts/lwe/index.html#example-encryption-using-learning-with-errors",
    "title": "Learning With Errors",
    "section": "",
    "text": "The LWE problem can be formulated as the equation \\(A⋅s+e=b\\mod{p}\\), where:\n\n\\(A\\) is the public key matrix,\n\\(s\\) is the secret vector,\n\\(e\\) is the noise vector,\n\\(b\\) is the resulting ciphertext vector, and\n\\(p\\) is a modulus.\n\nLet’s walk through a concrete example to illustrate how the Learning With Errors (LWE) problem can be used for encryption. We will use small values to demonstrate the process.\nSuppose we have the following parameters:\n\nPublic Key Matrix \\(A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}\\)\nModulus \\(p = 7\\)\nSecret Vector \\(s = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}\\)\nNoise Vector \\(e = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\\)\n\n\n\nCode\nfrom IPython.display import display, Math, Latex\nimport numpy as np\n\n# From KMChris\n# https://gist.github.com/KMChris/8fd878826453c3d55814b3293c7b084c\ndef print_matrix(array):\n    matrix = ''\n    for row in array:\n        try:\n            for number in row:\n                matrix += f'{number}&'\n        except TypeError:\n            matrix += f'{row}&'\n        matrix = matrix[:-1] + r'\\\\'\n    return r'\\begin{bmatrix}'+matrix+r'\\end{bmatrix}'\n\nq = 7\nA=np.array([[1 ,2],[3, 4]])\nsA = np.array([[5],[9]])\neA = np.array([[2],[-1]])\nbA = np.matmul(A,sA)%q\nbA = np.add(bA,eA)%q\n\nmatrix = r\"b = \" + print_matrix(A)\nmatrix += r\" * \" + print_matrix(sA)\nmatrix += r\" + \" + print_matrix(eA)\nmatrix += r\" \\mod{\" + str(q) + r\"}\"\nmatrix += r\" = \" + print_matrix(bA)\n\nmatrix = Math(matrix)\n\ndisplay(matrix)\n\n\n\\(\\displaystyle b = \\begin{bmatrix}1&2\\\\3&4\\\\\\end{bmatrix} * \\begin{bmatrix}5\\\\9\\\\\\end{bmatrix} + \\begin{bmatrix}2\\\\-1\\\\\\end{bmatrix} \\mod{7} = \\begin{bmatrix}4\\\\1\\\\\\end{bmatrix}\\)\nAn example of encryption using LWE\n\n\nTo encrypt the message of length \\(n\\) represented in binary (which has t number of different values), we sample \\(n\\) rows from \\(A\\) and the corresponding values from \\(b\\). We add up all the rows into a single equation and we add \\(\\lfloor\\frac{q}{t}\\rfloor\\) to \\(b\\).\nIn this case we will only use a single row, but the same process still applies.\n\n\\([1 \\quad 2] = 4\\)\n\nIf our message is the bit 1, we add \\(\\lfloor\\frac{q}{2}\\rfloor\\) to \\(b\\):\n\n\\([1 \\quad 2] = 4 + \\lfloor\\frac{q}{2}\\rfloor = 7\\)\n\nIf our message is the big 0, we add \\(0\\) to \\(b\\):\n\n\\([1 \\quad 2] = 4\\)\n\nNext, the person with the secret key multiplies the ciphertext vector \\(b\\) by the secret vector \\(s\\) and takes the result modulo \\(p\\) to obtain the original message. There is a small error, but this is removed by rounding the result to the nearest value representing a bit. In our case it is rounded to either 0 representing 0 or 7 representing 1.\n\n\nCode\nprint(\"A_rows * sA % q = correct\")\nprint(\"b_row - correct = encoded\")\n\n# Encoded 1 bit\nA_row = np.array([1, 2])\nb_row = 7\n\ncorrect = np.matmul(A_row,sA)%q\n\nencoded = b_row - correct\n\nprint(f\"1 bit which should be very close to 7: {encoded}\")\n\n# Encoded 0 bit\nA_row = np.array([1, 2])\nb_row = 4\n\ncorrect = np.matmul(A_row,sA)%q\n\nencoded = b_row - correct\nprint(f\"0 bit which should be very close to 0: {encoded}\")\n\n\nA_rows * sA % q = correct\nb_row - correct = encoded\n1 bit which should be very close to 7: [5]\n0 bit which should be very close to 0: [2]"
  },
  {
    "objectID": "posts/lwe/index.html#example-encryption-using-learning-with-errors-1",
    "href": "posts/lwe/index.html#example-encryption-using-learning-with-errors-1",
    "title": "Learning With Errors",
    "section": "",
    "text": "Let’s walk through a concrete example to illustrate how the Learning With Errors (LWE) problem can be used for encryption. We will use small values to demonstrate the process.\nSuppose we have the following parameters:\n\nPublic Key Matrix \\(A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}\\)\nModulus \\(p = 7\\)\nSecret Vector \\(s = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}\\)\nNoise Vector \\(e = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\\)\n\nTo encrypt a message, we follow these steps:\n\nCompute the ciphertext vector \\(b\\) by performing matrix-vector multiplication: \\(b = A \\cdot s + e \\mod p\\) Plugging in the values: \\(b = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\cdot \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} \\mod 7\\) Solving the matrix-vector multiplication and applying modulo 7: \\(b = \\begin{pmatrix} 3 + 2 \\\\ 9 + 4 \\end{pmatrix} + \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} \\mod 7 = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\\)\n\nThe resulting ciphertext vector \\(b\\) represents the encrypted form of the original message.\nTo decrypt the ciphertext and retrieve the original message, the recipient, who possesses the private key, performs the following steps:\n\nCompute the inner product of the ciphertext vector \\(b\\) and the secret vector \\(s\\): \\(b \\cdot s = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} \\cdot \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix} = (5 \\cdot 3) + (6 \\cdot 1) = 15 + 6 = 21\\)\nSubtract the result from step 2 from the ciphertext vector: \\(b - (b \\cdot s) = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} - 21 = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} - \\begin{pmatrix} 21 \\\\ 21 \\end{pmatrix} = \\begin{pmatrix} 5 - 21 \\\\ 6 - 21 \\end{pmatrix} = \\begin{pmatrix} -16 \\\\ -15 \\end{pmatrix}\\)\n\nThe resulting vector \\(\\begin{pmatrix} -16 \\\\ -15 \\end{pmatrix}\\) represents the decrypted message. In modular arithmetic, we can interpret negative values by adding the modulus to them. In this example, adding 7 to each negative value gives us \\(\\begin{pmatrix} -16 + 7 \\\\ -15 + 7 \\end{pmatrix} = \\begin{pmatrix} -9 \\\\ -8 \\end{pmatrix}\\).\nTherefore, the decrypted message is \\(\\begin{pmatrix} -9 \\\\ -8 \\end{pmatrix}\\)."
  },
  {
    "objectID": "posts/lwe/index.html#conclusion",
    "href": "posts/lwe/index.html#conclusion",
    "title": "Learning With Errors",
    "section": "",
    "text": "In conclusion, the Learning With Errors (LWE) problem is a powerful mathematical framework that has gained significant attention in the field of post-quantum cryptography. Its security is based on the presumed hardness of finding the secret key from the public key, even when given noisy and seemingly random equations. The LWE problem offers a promising approach to building cryptographic schemes that are resilient against attacks from both classical and quantum computers. As researchers continue to explore and develop new algorithms and techniques in this area, the LWE problem holds great potential for providing secure communication and protecting sensitive information in the era of quantum computing."
  },
  {
    "objectID": "posts/lwe/index.html#usage-in-cryptography",
    "href": "posts/lwe/index.html#usage-in-cryptography",
    "title": "Learning With Errors",
    "section": "",
    "text": "Fully Homomorphic Encryption (FHE) is a revolutionary cryptographic scheme that allows computations to be performed directly on encrypted data, without the need for decryption. FHE based on LWE enables secure computation on sensitive data while preserving privacy. It allows for powerful operations like addition and multiplication to be performed on encrypted data, providing a practical solution for secure computation in various applications, such as privacy-preserving data analysis and secure outsourcing of computations.\nKyber is a post-quantum secure key encapsulation mechanism (KEM) based on LWE. It is designed to provide secure key exchange in the presence of powerful quantum computers. Kyber uses the LWE problem to generate cryptographic keys, ensuring that the exchanged keys remain secure even if an adversary has access to quantum computing resources. Kyber is a promising candidate for secure communication in a post-quantum world, offering strong security guarantees and efficient performance.\nBoth TFHE (The Fully Homomorphic Encryption Library) and Kyber highlight the practical applications of the LWE problem in constructing advanced cryptographic algorithms. By leveraging the mathematical hardness of the LWE problem, these algorithms provide secure and efficient solutions for various cryptographic tasks, contributing to the development of post-quantum secure systems."
  },
  {
    "objectID": "posts/lwe/index.html#other-problems",
    "href": "posts/lwe/index.html#other-problems",
    "title": "Learning With Errors",
    "section": "",
    "text": "The Learning With Errors (LWE) problem is closely related to other lattice-based problems, including Ring Learning With Errors (RLWE) and General Learning With Errors (GLWE). These problems share similar mathematical structures and serve as the foundation for various cryptographic schemes.\nRLWE extends the LWE problem by introducing an additional algebraic structure called a ring. It involves working with polynomials instead of vectors, which offers certain advantages in cryptographic constructions. RLWE allows for the development of efficient encryption schemes, such as the NTRUEncrypt scheme, which provides post-quantum security.\nGLWE generalizes the LWE problem by considering a more general form of noise distribution. It allows for more flexibility in the noise generation process and offers enhanced security guarantees. GLWE is utilized in cryptographic constructions such as functional encryption and obfuscation, enabling advanced functionalities like fine-grained access control and program obfuscation."
  },
  {
    "objectID": "posts/zkp/index.html",
    "href": "posts/zkp/index.html",
    "title": "Zero Knowledge Proofs",
    "section": "",
    "text": "Zero knowledge proofs (ZKPs) are a way for a prover to prove that they have knowledge of a secret without revealing the secret itself. This is done by having the prover convince the verifier that they know the secret by providing a proof that the verifier can verify. The verifier can then be sure that the prover knows the secret without actually knowing the secret themselves. These proofs hold immense potential for enhancing privacy and security in various domains, ranging from financial transactions to identity verification. In this blog post, we will delve into the concept of zero knowledge proofs and explore their application through an example known as the Three Coloring Graph Problem.\n\n\nZero Knowledge Proofs were first devised in the paper, “The Knowledge Complexity of Interactive Proof Systems” by Shafi Goldwasser, Silvio Micali, and Charles Rackoff in 1985.\nThe key properties of zero knowledge proofs are:\n\nCompleteness: If the statement is true, an honest prover can convince the verifier of its truth.\nSoundness: If the statement is false, no prover can convince the verifier that it is true, except with some negligible probability.\nZero knowledge: The verifier learns nothing about the statement other than its truthfulness.\n\nZero knowledge proofs are based on cryptographic techniques, such as commitment schemes, digital signatures, and hash functions. They employ clever protocols that enable the prover to convince the verifier while maintaining utmost privacy.\n\n\n\nTo illustrate the concept of zero knowledge proofs, let’s consider two famous examples:\n\nThe Cave: Imagine there is a circular cave with a door around the curve of the cave. Alice claims to know a secret word that will open the door. Bob is skeptical, so Alice wants to convince him that she knows the secret word without revealing the word itself. How can she do this?\n\nAlice can convince Bob that she knows the secret word by having him stand outside the cave while she goes inside. She then opens the door and walks through it, proving that she knows the secret word. Bob can then verify that Alice knows the secret word without learning the word itself.\n\nThe Color Blind Friend: Suppose Alice is not color-blind and Bob is color-blind. Alice claims to know the color of a ball, but Bob is skeptical. Alice wants to convince Bob that she knows the color of the ball without revealing the color itself. How can she do this?\n\nTwo balls are given to Bob, one red and one green. He puts the balls behind his back and randomly chooses to switch them or keep them in the same order. He then brings the balls back out and shows them to Alice. Alice can then tell Bob whether or not he switched the balls. They repeat this process multiple times, and Bob becomes convinced that Alice knows the color of the ball without learning the color itself.\nIn both of these examples, Alice wants to convince Bob that she knows something without revealing the secret itself. This is the essence of zero knowledge proofs.\n\n\n\n\n\n\nAn image of the graph from the MIT website linked below\n\n\nA graph is 3-colorable if the vertices can be colored with three colors such that no two adjacent vertices have the same color. This problem is NP-complete, meaning that it is easy to verify a solution but difficult to find a solution. As a result of it being NP-complete, it means that all NP problems have zero lknowledge proofs.\nHere’s how it works:\n\nThe prover will randomly permute the colors of the vertices and use a commitment scheme to commit to the colors\nThe verifier will choose any edge and ask the prover to reveal the colors of the vertices\nThe prover will reveal the colors of the vertices\nThe verifier will verify that the colors are different\nRepeat until the verifier has a high enough confidence that the graph is 3-colorable\n\nThere is an excellent website from MIT that has an interactive version of the proof. You can find it here.\n\n\n\nZero knowledge proofs have a wide range of applications across various domains, some of which include:\n\nCryptocurrencies and Blockchain: Zero knowledge proofs, such as zk-SNARKs and zk-STARKs, are used to verify transactions and smart contracts without revealing the underlying details, ensuring privacy and confidentiality.\nIdentity Verification: Zero knowledge proofs can enable individuals to prove their identity or possession of certain credentials without exposing sensitive personal information.\nPassword Authentication: Instead of transmitting passwords over a network, zero knowledge proofs can be used to prove knowledge of a password without revealing it, adding an extra layer of security.\n\n\n\n\nZero knowledge proofs provide a remarkable cryptographic tool for establishing the truth of a statement while preserving privacy. Through the examples we’ve seen how zero knowledge proofs allow a prover to convince a verifier without revealing any additional information. These proofs have significant implications for privacy, security, and trust in various domains, paving the way for innovative applications and the protection of sensitive information.\nIn our upcoming blog posts, we will explore specific zero knowledge proof protocols, such as zk-SNARKs and zk-STARKs, and dive deeper into their mechanisms and real-world applications. Stay tuned to learn more about the exciting world of zero knowledge proofs!"
  },
  {
    "objectID": "posts/zkp/index.html#definition-of-zero-knowledge-proofs",
    "href": "posts/zkp/index.html#definition-of-zero-knowledge-proofs",
    "title": "Zero Knowledge Proofs",
    "section": "",
    "text": "Zero Knowledge Proofs were first devised in the paper, “The Knowledge Complexity of Interactive Proof Systems” by Shafi Goldwasser, Silvio Micali, and Charles Rackoff in 1985.\nThe key properties of zero knowledge proofs are:\n\nCompleteness: If the statement is true, an honest prover can convince the verifier of its truth.\nSoundness: If the statement is false, no prover can convince the verifier that it is true, except with some negligible probability.\nZero knowledge: The verifier learns nothing about the statement other than its truthfulness.\n\nZero knowledge proofs are based on cryptographic techniques, such as commitment schemes, digital signatures, and hash functions. They employ clever protocols that enable the prover to convince the verifier while maintaining utmost privacy."
  },
  {
    "objectID": "posts/zkp/index.html#two-abstract-examples",
    "href": "posts/zkp/index.html#two-abstract-examples",
    "title": "Zero Knowledge Proofs",
    "section": "",
    "text": "To illustrate the concept of zero knowledge proofs, let’s consider two famous examples:\n\nThe Cave: Imagine there is a circular cave with a door around the curve of the cave. Alice claims to know a secret word that will open the door. Bob is skeptical, so Alice wants to convince him that she knows the secret word without revealing the word itself. How can she do this?\n\nAlice can convince Bob that she knows the secret word by having him stand outside the cave while she goes inside. She then opens the door and walks through it, proving that she knows the secret word. Bob can then verify that Alice knows the secret word without learning the word itself.\n\nThe Color Blind Friend: Suppose Alice is not color-blind and Bob is color-blind. Alice claims to know the color of a ball, but Bob is skeptical. Alice wants to convince Bob that she knows the color of the ball without revealing the color itself. How can she do this?\n\nTwo balls are given to Bob, one red and one green. He puts the balls behind his back and randomly chooses to switch them or keep them in the same order. He then brings the balls back out and shows them to Alice. Alice can then tell Bob whether or not he switched the balls. They repeat this process multiple times, and Bob becomes convinced that Alice knows the color of the ball without learning the color itself.\nIn both of these examples, Alice wants to convince Bob that she knows something without revealing the secret itself. This is the essence of zero knowledge proofs."
  },
  {
    "objectID": "posts/zkp/index.html#the-3-colorable-graph-problem",
    "href": "posts/zkp/index.html#the-3-colorable-graph-problem",
    "title": "Zero Knowledge Proofs",
    "section": "",
    "text": "An image of the graph from the MIT website linked below\n\n\nA graph is 3-colorable if the vertices can be colored with three colors such that no two adjacent vertices have the same color. This problem is NP-complete, meaning that it is easy to verify a solution but difficult to find a solution. As a result of it being NP-complete, it means that all NP problems have zero lknowledge proofs.\nHere’s how it works:\n\nThe prover will randomly permute the colors of the vertices and use a commitment scheme to commit to the colors\nThe verifier will choose any edge and ask the prover to reveal the colors of the vertices\nThe prover will reveal the colors of the vertices\nThe verifier will verify that the colors are different\nRepeat until the verifier has a high enough confidence that the graph is 3-colorable\n\nThere is an excellent website from MIT that has an interactive version of the proof. You can find it here."
  },
  {
    "objectID": "posts/zkp/index.html#applications-of-zero-knowledge-proofs",
    "href": "posts/zkp/index.html#applications-of-zero-knowledge-proofs",
    "title": "Zero Knowledge Proofs",
    "section": "",
    "text": "Zero knowledge proofs have a wide range of applications across various domains, some of which include:\n\nCryptocurrencies and Blockchain: Zero knowledge proofs, such as zk-SNARKs and zk-STARKs, are used to verify transactions and smart contracts without revealing the underlying details, ensuring privacy and confidentiality.\nIdentity Verification: Zero knowledge proofs can enable individuals to prove their identity or possession of certain credentials without exposing sensitive personal information.\nPassword Authentication: Instead of transmitting passwords over a network, zero knowledge proofs can be used to prove knowledge of a password without revealing it, adding an extra layer of security."
  },
  {
    "objectID": "posts/zkp/index.html#conclusion",
    "href": "posts/zkp/index.html#conclusion",
    "title": "Zero Knowledge Proofs",
    "section": "",
    "text": "Zero knowledge proofs provide a remarkable cryptographic tool for establishing the truth of a statement while preserving privacy. Through the examples we’ve seen how zero knowledge proofs allow a prover to convince a verifier without revealing any additional information. These proofs have significant implications for privacy, security, and trust in various domains, paving the way for innovative applications and the protection of sensitive information.\nIn our upcoming blog posts, we will explore specific zero knowledge proof protocols, such as zk-SNARKs and zk-STARKs, and dive deeper into their mechanisms and real-world applications. Stay tuned to learn more about the exciting world of zero knowledge proofs!"
  },
  {
    "objectID": "posts/sss/index.html",
    "href": "posts/sss/index.html",
    "title": "Shamir’s Secret Sharing",
    "section": "",
    "text": "In the digital age, securing sensitive information is crucial. Shamir’s Secret Sharing (SSS) is a cryptographic technique that provides a way to distribute a secret among multiple parties, ensuring that the secret can only be reconstructed when a sufficient number of parties collaborate. This method, developed by Adi Shamir in 1979, offers a robust solution for protecting sensitive data such as encryption keys, passwords, or private documents.\n\n\nShamir’s Secret Sharing employs polynomial interpolation to split a secret into multiple shares. The secret can be reconstructed only by combining a sufficient number of shares, making it mathematically infeasible to uncover the secret with fewer shares. Here’s a step-by-step breakdown:\n\nSecret Generation: The secret holder generates a secret value.\nPolynomial Generation: A polynomial of degree k-1 is created, where k is the minimum number of shares required to reconstruct the secret. The constant term of the polynomial represents the secret.\nShare Generation: The secret holder calculates n shares by substituting different values of x into the polynomial, where n is the total number of shares to be distributed.\nShare Distribution: Each share is given to a different party. The secret holder doesn’t need to disclose the secret itself, just the shares.\nSecret Reconstruction: When k or more shares are combined, the secret can be reconstructed using Lagrange interpolation, a technique that recovers the polynomial based on the shares. With fewer than k shares, the secret remains secure.\n\nShamir’s secret sharing uses the Lagrange interpolation theorem to reconstruct the secret. This theorem states that a polynomial of degree k-1 can be uniquely determined by k points on the polynomial. In this case, the points are the shares, and the polynomial is the secret.\n\n\n\nShamir’s Secret Sharing has found applications in various domains where secure data distribution and protection are essential:\n\nCryptocurrency: In decentralized cryptocurrencies, private keys can be divided into shares using Shamir’s Secret Sharing. This ensures that multiple parties need to collaborate to authorize transactions or access funds securely.\nData Protection: Sensitive data, such as encryption keys or personal information, can be securely distributed across multiple servers or cloud providers using Shamir’s Secret Sharing. This mitigates the risk of data breaches and unauthorized access.\nDisaster Recovery: Shamir’s Secret Sharing is utilized in disaster recovery scenarios to safeguard critical information. By distributing shares across different locations or individuals, the recovery process becomes resilient against localized failures or data loss.\n\n\n\n\nWe are going to show an example of SSS using integer arithmetic. This is not the most secure way to implement SSS, but it is the easiest to understand. In practice we would use a finite field.\nSay we want to split our secret in a 2-out-of-3 scheme. This means that we need 2 shares to reconstruct the secret, and we have 3 shares in total.\nFirst, we establish the secret we want to share: \\(a_0 = 9702\\).\nThen we generate k-1 random coefficients for our polynomial. In this case, k = 2, so we only need one random coefficient: \\(a_1 = 1337\\).\nThe polynomial is then: \\(f(x) = 9702 + 1337x\\).\nWe can now generate our shares by substituting different values of x into the polynomial. We will use the values 1, 2, and 3.\n\\(S_1 = f(1) = 9702 + 1337(1) = 11039\\) \\(S_2 = f(2) = 9702 + 1337(2) = 12376\\) \\(S_3 = f(3) = 9702 + 1337(3) = 13713\\)\nTo reconstruct the secret we need to use Lagrange Interpolation.\nWolfram Mathworld provides a formula for Lagrange interpolation:\nFor a polynomial \\(P(x)\\) of degree \\(\\le (n-1)\\), that passes through \\(n\\) points \\((x_0, y_0), (x_1, y_1), \\ldots, (x_{n-1}, y_{n-1})\\), the Lagrange interpolation formula is:\n\\(\\quad P(x) = \\Sigma_{i=0}^{n} P_j(x)y_i\\)\nwhere\n\\(\\quad P_j(x) = \\Pi_{k=1, k \\neq j}^{n} \\frac{x - x_k}{x_j - x_k}\\)\nWe can now distribute these shares to different parties. The secret holder does not need to disclose the secret itself, just the shares.\nWhen we want to reconstruct the secret, we need to combine at least 2 shares. Let’s combine shares 1 and 2:\n\ndef lagrange_interpolation(x, points):\n    result = 0\n    for i in range(len(points)):\n        xi, yi = points[i]\n        term = yi\n        for j in range(len(points)):\n            if i != j:\n                xj, _ = points[j]\n                term *= (x - xj) / (xi - xj)\n        result += term\n    return result\n\n# Given points\npoints = [(1, 11039), (2, 12376)]\n\n# Value to interpolate at\nx = 0\n\n# Perform Lagrange interpolation\ninterpolated_value = lagrange_interpolation(x, points)\nprint(f\"The interpolated value at x = {x} is {interpolated_value}\")\n\nThe interpolated value at x = 0 is 9702.0\n\n\nThis is the secret we started with, so we have successfully reconstructed the secret.\n\n\n\nShamir’s Secret Sharing provides a powerful method for distributing and safeguarding secrets among multiple parties. By utilizing polynomial interpolation and Lagrange interpolation, it ensures that sensitive information remains secure unless a sufficient number of shares are combined. This technique finds applications in various areas, including cryptography, key management, data protection, and disaster recovery."
  },
  {
    "objectID": "posts/sss/index.html#how-shamirs-secret-sharing-works",
    "href": "posts/sss/index.html#how-shamirs-secret-sharing-works",
    "title": "Shamir’s Secret Sharing",
    "section": "",
    "text": "Shamir’s Secret Sharing employs polynomial interpolation to split a secret into multiple shares. The secret can be reconstructed only by combining a sufficient number of shares, making it mathematically infeasible to uncover the secret with fewer shares. Here’s a step-by-step breakdown:\n\nSecret Generation: The secret holder generates a secret value.\nPolynomial Generation: A polynomial of degree k-1 is created, where k is the minimum number of shares required to reconstruct the secret. The constant term of the polynomial represents the secret.\nShare Generation: The secret holder calculates n shares by substituting different values of x into the polynomial, where n is the total number of shares to be distributed.\nShare Distribution: Each share is given to a different party. The secret holder doesn’t need to disclose the secret itself, just the shares.\nSecret Reconstruction: When k or more shares are combined, the secret can be reconstructed using Lagrange interpolation, a technique that recovers the polynomial based on the shares. With fewer than k shares, the secret remains secure.\n\nShamir’s secret sharing uses the Lagrange interpolation theorem to reconstruct the secret. This theorem states that a polynomial of degree k-1 can be uniquely determined by k points on the polynomial. In this case, the points are the shares, and the polynomial is the secret."
  },
  {
    "objectID": "posts/sss/index.html#real-world-applications",
    "href": "posts/sss/index.html#real-world-applications",
    "title": "Shamir’s Secret Sharing",
    "section": "",
    "text": "Shamir’s Secret Sharing has found applications in various domains where secure data distribution and protection are essential:\n\nCryptocurrency: In decentralized cryptocurrencies, private keys can be divided into shares using Shamir’s Secret Sharing. This ensures that multiple parties need to collaborate to authorize transactions or access funds securely.\nData Protection: Sensitive data, such as encryption keys or personal information, can be securely distributed across multiple servers or cloud providers using Shamir’s Secret Sharing. This mitigates the risk of data breaches and unauthorized access.\nDisaster Recovery: Shamir’s Secret Sharing is utilized in disaster recovery scenarios to safeguard critical information. By distributing shares across different locations or individuals, the recovery process becomes resilient against localized failures or data loss."
  },
  {
    "objectID": "posts/sss/index.html#example",
    "href": "posts/sss/index.html#example",
    "title": "Shamir’s Secret Sharing",
    "section": "",
    "text": "We are going to show an example of SSS using integer arithmetic. This is not the most secure way to implement SSS, but it is the easiest to understand. In practice we would use a finite field.\nSay we want to split our secret in a 2-out-of-3 scheme. This means that we need 2 shares to reconstruct the secret, and we have 3 shares in total.\nFirst, we establish the secret we want to share: \\(a_0 = 9702\\).\nThen we generate k-1 random coefficients for our polynomial. In this case, k = 2, so we only need one random coefficient: \\(a_1 = 1337\\).\nThe polynomial is then: \\(f(x) = 9702 + 1337x\\).\nWe can now generate our shares by substituting different values of x into the polynomial. We will use the values 1, 2, and 3.\n\\(S_1 = f(1) = 9702 + 1337(1) = 11039\\) \\(S_2 = f(2) = 9702 + 1337(2) = 12376\\) \\(S_3 = f(3) = 9702 + 1337(3) = 13713\\)\nTo reconstruct the secret we need to use Lagrange Interpolation.\nWolfram Mathworld provides a formula for Lagrange interpolation:\nFor a polynomial \\(P(x)\\) of degree \\(\\le (n-1)\\), that passes through \\(n\\) points \\((x_0, y_0), (x_1, y_1), \\ldots, (x_{n-1}, y_{n-1})\\), the Lagrange interpolation formula is:\n\\(\\quad P(x) = \\Sigma_{i=0}^{n} P_j(x)y_i\\)\nwhere\n\\(\\quad P_j(x) = \\Pi_{k=1, k \\neq j}^{n} \\frac{x - x_k}{x_j - x_k}\\)\nWe can now distribute these shares to different parties. The secret holder does not need to disclose the secret itself, just the shares.\nWhen we want to reconstruct the secret, we need to combine at least 2 shares. Let’s combine shares 1 and 2:\n\ndef lagrange_interpolation(x, points):\n    result = 0\n    for i in range(len(points)):\n        xi, yi = points[i]\n        term = yi\n        for j in range(len(points)):\n            if i != j:\n                xj, _ = points[j]\n                term *= (x - xj) / (xi - xj)\n        result += term\n    return result\n\n# Given points\npoints = [(1, 11039), (2, 12376)]\n\n# Value to interpolate at\nx = 0\n\n# Perform Lagrange interpolation\ninterpolated_value = lagrange_interpolation(x, points)\nprint(f\"The interpolated value at x = {x} is {interpolated_value}\")\n\nThe interpolated value at x = 0 is 9702.0\n\n\nThis is the secret we started with, so we have successfully reconstructed the secret."
  },
  {
    "objectID": "posts/sss/index.html#conclusion",
    "href": "posts/sss/index.html#conclusion",
    "title": "Shamir’s Secret Sharing",
    "section": "",
    "text": "Shamir’s Secret Sharing provides a powerful method for distributing and safeguarding secrets among multiple parties. By utilizing polynomial interpolation and Lagrange interpolation, it ensures that sensitive information remains secure unless a sufficient number of shares are combined. This technique finds applications in various areas, including cryptography, key management, data protection, and disaster recovery."
  },
  {
    "objectID": "posts/kdd2023/index.html",
    "href": "posts/kdd2023/index.html",
    "title": "Paper accepted into KDD 2023 Undergraduate Consortium",
    "section": "",
    "text": "KDD 2023 Banner\n\n\nI’m thrilled to share that our paper has been accepted for presentation at the prestigious KDD conference. It’s an honor to have our research recognized by the conference committee, and I want to express my heartfelt gratitude to all my co-authors and professor who contributed their expertise and dedication to this project. Our paper, titled Predicting Time to Pushback of Flights in U.S. Airports, delves into predicting when an airplane leaves the gate by utilizing features such as aircraft type, weather features, and airport activity. We hope that our work will help airlines and airports better understand the factors that contribute to delays and improve their operations. It will be available for viewing on the KDD website soon."
  },
  {
    "objectID": "posts/ot/index.html",
    "href": "posts/ot/index.html",
    "title": "Oblivious Transfer",
    "section": "",
    "text": "Diagram explaining oblivious transfer"
  },
  {
    "objectID": "posts/ot/index.html#rabins-oblivious-transfer",
    "href": "posts/ot/index.html#rabins-oblivious-transfer",
    "title": "Oblivious Transfer",
    "section": "Rabin’s Oblivious Transfer",
    "text": "Rabin’s Oblivious Transfer\nIn 1981, Michael Rabin published a paper titled “How to Exchange Secrets with Oblivious Transfer” in which he described a protocol for 1-out-of-2 oblivious transfer. It is based on the RSA cryptosystem and relies on the difficulty of factoring large integers. There is a 50% chance that the receiver will receive the first message and a 50% chance that the receiver will receive the second message. The sender does not know which message the receiver received and the receiver does not know the contents of the message they did not receive."
  },
  {
    "objectID": "posts/ot/index.html#out-of-2-oblivious-transfer",
    "href": "posts/ot/index.html#out-of-2-oblivious-transfer",
    "title": "Oblivious Transfer",
    "section": "1-out-of-2 oblivious transfer",
    "text": "1-out-of-2 oblivious transfer\n1-out-of-2 oblivious transfer is a more useful form of oblivious transfer than Rabin’s original protocol. It allows the sender to send two messages to the receiver and the receiver to choose which message they receive. The sender does not know which message the receiver received and the receiver does not know the contents of the message they did not receive. It can be generalized to n-out-of-m oblivious transfer, where the sender sends m messages to the receiver and the receiver chooses one of the messages to receive. This is the basis for many protocols underlying secure multiparty computation.\nBelow explains the steps for 1-out-of-2 oblivious transfer:\n\nBob and Alice agree on a generator \\(g\\) and prime number \\(p\\)\nAlice generates a random number \\(a\\) and sends \\(g^a\\) to Bob\nBob generates a random number \\(b\\) and sends \\(B=g^b\\) if he wants the 0th message and \\(B=Ag^b\\) if he wants the 1st message\nAlice computer \\(k_0 = Hash(B^a)\\) and \\(k_1 = Hash((B/A)^a)\\) and sends \\(E_{k_0}(m_0)\\) and \\(E_{k_1}(m_1)\\) to Bob\nBob calculates k_r = Hash((A)^b) and decrypts both messages to get \\(m_r\\)\n\nHere is the protocol implemented in Python where Bob wants the 0th message:\n\nimport random\nfrom Crypto.Cipher import AES\nfrom Crypto.Util.Padding import pad, unpad\nimport struct\nimport hashlib\n\n# Hashes data using SHA3-256\ndef sha3_256_hash(data):\n    sha3_hash = hashlib.sha3_256()\n\n    if not isinstance(data, bytes):\n        data = str(data).encode()\n\n    sha3_hash.update(data)\n\n    hash_result = sha3_hash.digest()\n\n    return hash_result\n\n# Establish shared parameters\ng = 3\np = 17\n\n# Alice generates a random number a and sends g^a to Bob\n# ! This is not secure, but it is just for demonstration purposes !\na = random.randint(0, p)\nA = (g ** a) % p\n\n# Bob generates a random number b and sends B=g^b to Alice\n# Bob wants the 0th message\n# Bob could also send B=Ag^b if he wanted the 1st message\n# ! This is not secure, but it is just for demonstration purposes !\nb = random.randint(0, p)\nB = (g ** b) % p\nkr = sha3_256_hash((A ** b) % p)\n\n# Alice computes k0 = Hash(B^a) and k1 = Hash((B/A)^a) and sends E_{k0}(m0) and E_{k1}(m1) to Bob\nk0 = sha3_256_hash((B ** a) % p)\nk1 = sha3_256_hash(((B / A) ** a) % p)\n\nm0 = pad(b\"Hello\", 16)\nm1 = pad(b\"World\", 16)\n\n# ! This is not secure, but it is just for demonstration purposes !\ncipher0 = AES.new(k0, AES.MODE_ECB)\nc0 = cipher0.encrypt(m0)\n\ncipher1 = AES.new(k1, AES.MODE_ECB)\nc1 = cipher1.encrypt(m1)\n\n# Bob calculates kr = Hash((A)^b) and decrypts both messages to get mr\n# ! This is not secure, but it is just for demonstration purposes !\ncipherb = AES.new(kr, AES.MODE_ECB)\n\nprint(unpad(cipherb.decrypt(c0), 16))\n\ntry:\n    print(\"C0: \" + unpad(cipherb.decrypt(c1), 16))\nexcept ValueError:\n    print(\"Bob did not receive the 1st message\")\n\nb'Hello'\nBob did not receive the 1st message"
  },
  {
    "objectID": "posts/ot/index.html#applications",
    "href": "posts/ot/index.html#applications",
    "title": "Oblivious Transfer",
    "section": "Applications",
    "text": "Applications\n\nSecure Multiparty Computation (MPC):\n\nOblivious Transfer is a fundamental component of secure MPC protocols. It allows multiple parties to jointly compute functions on private inputs without revealing individual inputs. Enables privacy-preserving computations in scenarios such as private auctions and collaborative machine learning.\n\nPrivate Information Retrieval (PIR):\n\nPIR enables retrieving specific information from a database without revealing the queried item or learning about other items. Oblivious Transfer is used to construct PIR protocols, preserving user privacy while retrieving desired data."
  },
  {
    "objectID": "posts/ot/index.html#conclusion",
    "href": "posts/ot/index.html#conclusion",
    "title": "Oblivious Transfer",
    "section": "Conclusion",
    "text": "Conclusion\nOblivious Transfer is a powerful cryptographic protocol that enables secure communication between parties while preserving privacy. It provides a way for senders to transfer private messages to receivers without either party gaining information about the unselected messages. The applications of oblivious transfer extend to various domains where privacy and secure computations are essential. By leveraging the principles of cryptography and secure protocols, oblivious transfer offers a valuable tool for building secure systems and protecting sensitive information."
  },
  {
    "objectID": "posts/ot/index.html#out-of-n-oblivious-transfer",
    "href": "posts/ot/index.html#out-of-n-oblivious-transfer",
    "title": "Oblivious Transfer",
    "section": "1-out-of-n oblivious transfer",
    "text": "1-out-of-n oblivious transfer\nThe protocol shown above can also be generalized to support more than 2 messages by the sender having \\(n\\) messages and the reciever having index \\(i\\) which represents the message they want from the sender.\nThere are also ways to make it \\(k\\) of \\(n\\) where a reciever can request \\(k\\) messages from the sender."
  },
  {
    "objectID": "posts/ygc/index.html",
    "href": "posts/ygc/index.html",
    "title": "Yao’s Garbled Circuits",
    "section": "",
    "text": "Yao’s Garbled Circuits is a cryptographic protocol introduced by Andrew Yao in 1982 that enables secure two-party computation. It allows two parties, let’s call them Alice and Bob, to compute a function on their private inputs without revealing their inputs to each other.\n\n\nYao’s Garbled Circuits is a form of MPC where there are only two parties and each party is assumed to be “honest-but-curious” meaning that they might try and look at things they shouldn’t, but they won’t actively try and break the protocol. The participants are trying to compute the function \\(f(x, y)\\) which is a boolean circuit meaning that all inputs are 0 or 1 and there are nodes like AND, OR, and NOT gates that connect inputs. The function is known to both parties, but they don’t want to reveal their inputs to each other. The protocol works as follows:\n\nAlice and Bob agree on a boolean circuit \\(f(x)\\) that they want to compute\nAlice garbles the circuit and sends it along with her encrypted input \\(x0\\) to Bob\nBob encrypts his input \\(x1\\) by using an Oblivious Transfer protocol with Alice\nBob evaluates the garbled circuit with his encrypted input and sends the result to Alice\n\nLets go through each of these steps in more detail.\nIn this example, we are going to compute the function \\(f(x, y) = x \\oplus y\\), where \\(\\oplus\\) represents the XOR operator. Alice has input \\(x = 1\\), and Bob has input \\(y = 0\\). The first step is to agree on a boolean circuit that computes \\(f(x, y)\\).\n\nThen, Alice generates a key for each wire and each possible value for the wire. In this case, there are two wires, and each wire can be 0 or 1, so there are four keys.\n\nAlice encrypts each output value with the corresponding keys and permutes the table randomly. Then she sends the garbled circuit to Bob along with her encrypted input \\(x_0\\).\n\nBob uses an Oblivious Transfer protocol to select which key he wants from alice. \nSince Bob now has Alice’s key and the key for his own input, he can decrypt the output value and send it to Alice. Bob either has to go through every entry in the table and try to decrypt it or there can be a select bit specified in the protocol so he knows where to look. Bob then sends the output value to Alice.\n\n\n\n\nFor multi-gate circuits, instead of calculating the encryption directly on the function output, the garbler will also generate a key for the output and encrypt that key instead. When Bob decrypts the circuit, he will get the output key, which can be fed into other circuits.\n\n\n\nYao’s Garbled Circuits find applications in various scenarios where privacy and secure computation are paramount. Some of the applications include:\n\nPrivacy-preserving auctions: Garbled circuits can be used to compute auction algorithms securely, allowing bidders to submit their bids without revealing their values until the auction winner is determined.\nSecure machine learning: Yao’s Garbled Circuits can enable privacy-preserving machine learning models by allowing different parties to compute machine learning algorithms on their private data without revealing the data itself.\nPrivate function evaluation: The protocol enables secure computation of functions on private inputs, which is useful in scenarios where mutually distrusting parties need to jointly compute a function without revealing their inputs.\n\n\n\n\nYao’s Garbled Circuits provide a powerful tool for secure two-party computation, enabling privacy-preserving computations between mutually distrusting parties. The protocol ensures that each party’s inputs remain confidential while computing a joint function. By following the steps of garbling and evaluation, Alice and Bob can securely compute a function without exposing their inputs to each other.\nIn this blog post, we explored the concept of Yao’s Garbled Circuits, the underlying mechanisms, and its applications. By understanding and implementing protocols like Yao’s Garbled Circuits, we can achieve privacy-preserving computations in various domains."
  },
  {
    "objectID": "posts/ygc/index.html#how-it-works",
    "href": "posts/ygc/index.html#how-it-works",
    "title": "Yao’s Garbled Circuits",
    "section": "",
    "text": "Yao’s Garbled Circuits is a form of MPC where there are only two parties and each party is assumed to be “honest-but-curious” meaning that they might try and look at things they shouldn’t, but they won’t actively try and break the protocol. The participants are trying to compute the function \\(f(x, y)\\) which is a boolean circuit meaning that all inputs are 0 or 1 and there are nodes like AND, OR, and NOT gates that connect inputs. The function is known to both parties, but they don’t want to reveal their inputs to each other. The protocol works as follows:\n\nAlice and Bob agree on a boolean circuit \\(f(x)\\) that they want to compute\nAlice garbles the circuit and sends it along with her encrypted input \\(x0\\) to Bob\nBob encrypts his input \\(x1\\) by using an Oblivious Transfer protocol with Alice\nBob evaluates the garbled circuit with his encrypted input and sends the result to Alice\n\nLets go through each of these steps in more detail.\nIn this example, we are going to compute the function \\(f(x, y) = x \\oplus y\\), where \\(\\oplus\\) represents the XOR operator. Alice has input \\(x = 1\\), and Bob has input \\(y = 0\\). The first step is to agree on a boolean circuit that computes \\(f(x, y)\\).\n\nThen, Alice generates a key for each wire and each possible value for the wire. In this case, there are two wires, and each wire can be 0 or 1, so there are four keys.\n\nAlice encrypts each output value with the corresponding keys and permutes the table randomly. Then she sends the garbled circuit to Bob along with her encrypted input \\(x_0\\).\n\nBob uses an Oblivious Transfer protocol to select which key he wants from alice. \nSince Bob now has Alice’s key and the key for his own input, he can decrypt the output value and send it to Alice. Bob either has to go through every entry in the table and try to decrypt it or there can be a select bit specified in the protocol so he knows where to look. Bob then sends the output value to Alice."
  },
  {
    "objectID": "posts/ygc/index.html#multi-gate-circuits",
    "href": "posts/ygc/index.html#multi-gate-circuits",
    "title": "Yao’s Garbled Circuits",
    "section": "",
    "text": "For multi-gate circuits, instead of calculating the encryption directly on the function output, the garbler will also generate a key for the output and encrypt that key instead. When Bob decrypts the circuit, he will get the output key, which can be fed into other circuits."
  },
  {
    "objectID": "posts/ygc/index.html#example-code",
    "href": "posts/ygc/index.html#example-code",
    "title": "Yao’s Garbled Circuits",
    "section": "",
    "text": "import os\nfrom Crypto.Cipher import AES\nfrom Crypto.Util.Padding import pad, unpad\n\n# store the xor table in a dictionary\nxor_table = {\n    (0, 0): 0,\n    (0, 1): 1,\n    (1, 0): 1,\n    (1, 1): 0\n}\n\n# generate keys for each wire and each possible value\ndef generate_keys():\n    keys = {}\n    for wire in range(2):\n        for value in range(2):\n            keys[(wire, value)] = os.urandom(16)\n    return keys\n\n# encrypt the output value with the corresponding keys\ndef encrypt_output(keys):\n    encrypted_output = {}\n    for (wire, value), key in keys.items():\n        encrypted_output[(wire, value)] = AES.new(key, AES.MODE_ECB).encrypt(pad(str(xor_table[(wire, value)]).encode(), 16))\n    print(encrypted_output)\n    return encrypted_output\n\n# permute the table randomly\ndef permute_table(encrypted_output):\n    return encrypted_output\n\n# garble the circuit\ndef garble_circuit():\n    keys = generate_keys()\n    encrypted_output = encrypt_output(keys)\n    permuted_table = permute_table(encrypted_output)\n    return permuted_table, keys\n\n# evaluate the circuit\ndef evaluate_circuit(permuted_table, x0, x1):\n    output = None\n    for (wire, value), encrypted_output in permuted_table.items():\n        if wire == 0:\n            if value == x0:\n                output = encrypted_output\n        elif wire == 1:\n            if value == x1:\n                output = encrypted_output\n    return output\n\nprint(\"XOR Table\")\nprint(\"x0\\tx1\\tf(x0, x1)\")\nfor x0 in range(2):\n    for x1 in range(2):\n        print(f\"{x0}\\t{x1}\\t{xor_table[(x0, x1)]}\")\n\nprint(\"-\" * 20)\n\n# Alice garbles the circuit and sends it to Bob\npermuted_table, keys = garble_circuit()\n\nprint(\"Garbled Table\")\nprint(\"x0\\tx1\")\nfor (wire, value), encrypted_output in permuted_table.items():\n    print(f\"{wire}\\t{value}\")\n\nprint(keys)\n\nx0 = 0\n\n# Bob evaluates the circuit\nx1 = 1\n\noutput = evaluate_circuit(permuted_table, x0, x1)\n\nXOR Table\nx0  x1  f(x0, x1)\n0   0   0\n0   1   1\n1   0   1\n1   1   0\n--------------------\n{(0, 0): b'&@d7\\xe7=\\xca\\xca\\x7f3\\xdb\\xbd\\x10\\x1a\\x14#', (0, 1): b'\\xaeN\\x90\\x05\\xe0G\\xf9D\\xe0N0\\x83m\\xcdQj', (1, 0): b'?Hig\\x1d:g\\xe4\\x00\\x95JS\\xc0\\x89\\xd1\\x8a', (1, 1): b\"\\xc7R\\x13'\\xf8?\\xbf\\xad\\xa5\\x9c(w\\x19\\xba\\x17\\xd1\"}\nGarbled Table\nx0  x1\n0   0\n0   1\n1   0\n1   1\n{(0, 0): b'\\xf9\\x01lE\\xe5a\\xb7n\\xdeM\\xe3\\xdag\\x7f\\x80\\xc8', (0, 1): b'h\\x06\\xcb3\\xfa\\xd2\\xd7K\\xfa\\x96\\x01\\xc3\\xc4*?\\xcf', (1, 0): b'\\xfaO\\x88\\xe2\\x94O(\\xef\\x0bA\\xd6K\\xab`_F', (1, 1): b'vS\\xb2q-\\xe2\\xeb\\xb9-W\\xc0( d\\xf2\\xdb'}"
  },
  {
    "objectID": "posts/ygc/index.html#applications",
    "href": "posts/ygc/index.html#applications",
    "title": "Yao’s Garbled Circuits",
    "section": "",
    "text": "Yao’s Garbled Circuits find applications in various scenarios where privacy and secure computation are paramount. Some of the applications include:\n\nPrivacy-preserving auctions: Garbled circuits can be used to compute auction algorithms securely, allowing bidders to submit their bids without revealing their values until the auction winner is determined.\nSecure machine learning: Yao’s Garbled Circuits can enable privacy-preserving machine learning models by allowing different parties to compute machine learning algorithms on their private data without revealing the data itself.\nPrivate function evaluation: The protocol enables secure computation of functions on private inputs, which is useful in scenarios where mutually distrusting parties need to jointly compute a function without revealing their inputs."
  },
  {
    "objectID": "posts/ygc/index.html#conclusion",
    "href": "posts/ygc/index.html#conclusion",
    "title": "Yao’s Garbled Circuits",
    "section": "",
    "text": "Yao’s Garbled Circuits provide a powerful tool for secure two-party computation, enabling privacy-preserving computations between mutually distrusting parties. The protocol ensures that each party’s inputs remain confidential while computing a joint function. By following the steps of garbling and evaluation, Alice and Bob can securely compute a function without exposing their inputs to each other.\nIn this blog post, we explored the concept of Yao’s Garbled Circuits, the underlying mechanisms, and its applications. By understanding and implementing protocols like Yao’s Garbled Circuits, we can achieve privacy-preserving computations in various domains."
  },
  {
    "objectID": "posts/vdf/index.html",
    "href": "posts/vdf/index.html",
    "title": "Verifiable Delay Functions",
    "section": "",
    "text": "A Verifiable Delay Function (VDF) is a computational primitive that introduces a time delay in evaluating a function while providing proof of its correctness. In simple terms, it is a function that takes an input and produces an output after a specific time period, making it computationally expensive to compute the output faster. The key property of VDFs is that they are easy to verify once the output is obtained, but computationally challenging to compute within a shorter time frame. In this blog post, we will delve into the world of VDFs, exploring their applications, properties, and potential impact on the field of cryptography.\n\n\n\nVerifiable: The output of the function can be verified to be correct.\nDelay: The output of the function cannot be computed faster than a specific time period and runs sequentially.\nFunction: The function is deterministic and has a unique output for each input.\n\n\n\n\nWe can hash a value \\(t\\) times to create a naive VDF.\n\\(H^t(x) = H(H(...H(x)))\\)\nWe then use a SNARK to prove that the output is correct. Alternatively, we could recompute the hashes, however, that would be infeasable.\nThis method works because it is sequential and verifiable, but there are far more efficient methods available.\n\n\n\nPietrzak’s VDF found a solution using groups of unknown order. Here’s how it works:\n\n\nWhat is a group of unknown order? A group of unknown order is a group where the parties do not know how many elements are in the group. For instance, in RSA groups, we generate two prime numbers \\(p\\) and \\(q\\) and multiply them together to get the composite modulus \\(n\\). If we know the order of the group, we can solve the problem much easier. To create the order \\(n\\) we have to use a trusted setup by relying on something like multi-party computation.\n\nWe establish a VDF with t steps, a hash function H that maps bytes \\(\\rightarrow\\) elements of \\(G\\), and a finite abelian group of unknown order \\(G\\).\nWe compute the VDF as \\(y = {H(x)^{2}}^{t}\\)\n\nThe squaring of the hash function is what makes this VDF sequential and the fact that \\(G\\) is a group of unknown order makes it difficult to compute the output faster than \\(t\\) steps.\nFor the proof, the verifier wants to prove \\(y = {H(x)^2}^{t}\\) so they first sends \\(\\mu = {H(x)^2}^{\\frac{t}{2}}\\). Then the verifier will send a random value r which is constrained to be less than the security parameter \\(\\lambda\\) (which was chosen during initialization). Then both parties compute \\(x_1 = x^r * \\mu\\) and \\(y = \\mu^r * y\\). If the original statement was correct, then \\(y_1 = {x_1^2}^{\\frac{t}{2}}\\). This is repeated \\(\\log_2(t)\\) times until \\(t=1\\) to get the final proof.\nThis can be made into a non-interactive proof by using the Fiat-Shamir transformation.\n\n\n\nWesolowski’s VDF is similar to Pietrzaks except for the verification step. Instead of halving recursively, the prover gives a point near the end of the sequence and the verifier computers the rest of the sequence to verify the output. The prover only has to store a single point and the the prime number which is a lot less space than Pietrzak’s VDF.\n\n\n\n\n\nAs mentioned above, the most popular option for VDFs is using RSA groups. These groups have been studied extensively and it is known how to create them securely. The downside is that they require a trusted setup to generate the order of the group which could compromise security if the setup is not done correctly.\n\n\n\nClass Groups are a newer area of research that aim to eliminate the trusted setup requirement of RSA groups. One downside of class groups is that their operations are more computationally expensive than RSA groups. However, the fact that they can switch groups often because they do not require a trusted setup makes them a good candidate for VDFs. More research needs to be done on these groups, but they appear to be a promising option.\n\n\n\n\nOne big application of VDFs are randomness beacons. Imagine that there is an lottery on a blockchain and the lottery takes some amount of randomness from the a certain blocks hash to generate the numbers. One visible flaw to this method is that miners could withhold blocks until they find a block that gives them the numbers they want. This is called a block withholding attack. To prevent this, we can use a VDF to generate the randomness. The VDF would take the hash of the block as input and output a random number after a certain amount of time passed. The VDF would be sequential so miners would not be able to withhold blocks to find the right hash. The VDF would also be verifiable so that the miners could not lie about the output. This would prevent block withholding attacks and make the lottery more secure.\n\n\n\nIn conclusion, Verifiable Delay Functions (VDFs) provide a powerful cryptographic tool for achieving time-delayed computations with verifiability. By utilizing sequential and non-parallelizable operations, VDFs introduce a time delay that enhances security and prevents manipulation. The applications of VDFs are vast, with randomness beacons being a notable use case. VDF-based randomness beacons ensure the generation of unbiased and publicly verifiable random numbers, thereby enhancing the fairness and integrity of applications such as lotteries and cryptographic protocols. Ongoing research and development in VDFs aim to improve efficiency, explore new constructions, and expand their applications, making VDFs a promising area in the field of cryptography with significant potential for enhancing security and trust in various domains."
  },
  {
    "objectID": "posts/vdf/index.html#definition-of-vdf",
    "href": "posts/vdf/index.html#definition-of-vdf",
    "title": "Verifiable Delay Functions",
    "section": "",
    "text": "Verifiable: The output of the function can be verified to be correct.\nDelay: The output of the function cannot be computed faster than a specific time period and runs sequentially.\nFunction: The function is deterministic and has a unique output for each input."
  },
  {
    "objectID": "posts/vdf/index.html#naive-vdf",
    "href": "posts/vdf/index.html#naive-vdf",
    "title": "Verifiable Delay Functions",
    "section": "",
    "text": "We can hash a value \\(t\\) times to create a naive VDF.\n\\(H^t(x) = H(H(...H(x)))\\)\nWe then use a SNARK to prove that the output is correct. Alternatively, we could recompute the hashes, however, that would be infeasable.\nThis method works because it is sequential and verifiable, but there are far more efficient methods available."
  },
  {
    "objectID": "posts/vdf/index.html#pietrzaks-vdf",
    "href": "posts/vdf/index.html#pietrzaks-vdf",
    "title": "Verifiable Delay Functions",
    "section": "",
    "text": "Pietrzak’s VDF found a solution using groups of unknown order. Here’s how it works:\n\n\nWhat is a group of unknown order? A group of unknown order is a group where the parties do not know how many elements are in the group. For instance, in RSA groups, we generate two prime numbers \\(p\\) and \\(q\\) and multiply them together to get the composite modulus \\(n\\). If we know the order of the group, we can solve the problem much easier. To create the order \\(n\\) we have to use a trusted setup by relying on something like multi-party computation.\n\nWe establish a VDF with t steps, a hash function H that maps bytes \\(\\rightarrow\\) elements of \\(G\\), and a finite abelian group of unknown order \\(G\\).\nWe compute the VDF as \\(y = {H(x)^{2}}^{t}\\)\n\nThe squaring of the hash function is what makes this VDF sequential and the fact that \\(G\\) is a group of unknown order makes it difficult to compute the output faster than \\(t\\) steps.\nFor the proof, the verifier wants to prove \\(y = {H(x)^2}^{t}\\) so they first sends \\(\\mu = {H(x)^2}^{\\frac{t}{2}}\\). Then the verifier will send a random value r which is constrained to be less than the security parameter \\(\\lambda\\) (which was chosen during initialization). Then both parties compute \\(x_1 = x^r * \\mu\\) and \\(y = \\mu^r * y\\). If the original statement was correct, then \\(y_1 = {x_1^2}^{\\frac{t}{2}}\\). This is repeated \\(\\log_2(t)\\) times until \\(t=1\\) to get the final proof.\nThis can be made into a non-interactive proof by using the Fiat-Shamir transformation."
  },
  {
    "objectID": "posts/vdf/index.html#finite-groups-of-unknown-order",
    "href": "posts/vdf/index.html#finite-groups-of-unknown-order",
    "title": "Verifiable Delay Functions",
    "section": "",
    "text": "As mentioned above, the most popular option for VDFs is using RSA groups. These groups have been studied extensively and it is known how to create them securely. The downside is that they require a trusted setup to generate the order of the group which could compromise security if the setup is not done correctly.\n\n\n\nClass Groups are a newer area of research that aim to eliminate the trusted setup requirement of RSA groups. One downside of class groups is that their operations are more computationally expensive than RSA groups. However, the fact that they can switch groups often because they do not require a trusted setup makes them a good candidate for VDFs. More research needs to be done on these groups, but they appear to be a promising option."
  },
  {
    "objectID": "posts/vdf/index.html#applications",
    "href": "posts/vdf/index.html#applications",
    "title": "Verifiable Delay Functions",
    "section": "",
    "text": "One big application of VDFs are randomness beacons. Imagine that there is an lottery on a blockchain and the lottery takes some amount of randomness from the a certain blocks hash to generate the numbers. One visible flaw to this method is that miners could withhold blocks until they find a block that gives them the numbers they want. This is called a block withholding attack. To prevent this, we can use a VDF to generate the randomness. The VDF would take the hash of the block as input and output a random number after a certain amount of time passed. The VDF would be sequential so miners would not be able to withhold blocks to find the right hash. The VDF would also be verifiable so that the miners could not lie about the output. This would prevent block withholding attacks and make the lottery more secure."
  },
  {
    "objectID": "posts/vdf/index.html#wesolowskis-vdf",
    "href": "posts/vdf/index.html#wesolowskis-vdf",
    "title": "Verifiable Delay Functions",
    "section": "",
    "text": "Wesolowski’s VDF is similar to Pietrzaks except for the verification step. Instead of halving recursively, the prover gives a point near the end of the sequence and the verifier computers the rest of the sequence to verify the output. The prover only has to store a single point and the the prime number which is a lot less space than Pietrzak’s VDF."
  },
  {
    "objectID": "posts/vdf/index.html#conclusion",
    "href": "posts/vdf/index.html#conclusion",
    "title": "Verifiable Delay Functions",
    "section": "",
    "text": "In conclusion, Verifiable Delay Functions (VDFs) provide a powerful cryptographic tool for achieving time-delayed computations with verifiability. By utilizing sequential and non-parallelizable operations, VDFs introduce a time delay that enhances security and prevents manipulation. The applications of VDFs are vast, with randomness beacons being a notable use case. VDF-based randomness beacons ensure the generation of unbiased and publicly verifiable random numbers, thereby enhancing the fairness and integrity of applications such as lotteries and cryptographic protocols. Ongoing research and development in VDFs aim to improve efficiency, explore new constructions, and expand their applications, making VDFs a promising area in the field of cryptography with significant potential for enhancing security and trust in various domains."
  },
  {
    "objectID": "posts/fft/index.html",
    "href": "posts/fft/index.html",
    "title": "Fast Fourier Transform",
    "section": "",
    "text": "The Fast Fourier Transform is a divide and conquer algorithm for computing the discrete Fourier transform of a sequence, or its inverse. Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. The DFT is obtained by decomposing a sequence of values into components of different frequencies. This operation is useful in many fields but computing it directly from the definition is too slow to be practical. The FFT algorithm computes the same result more quickly. The FFT has many use cases in computer science and cryptography that make it a very important algorithm to understand.\n\n\nSay we want to multiply two polynomials \\(p(x) = x^2 + 4x + 1\\) and \\(f(x) = 3x^2 + x + 4\\). We can do this by multiplying each term in \\(p(x)\\) by each term in \\(f(x)\\) and adding the results.\nVideo\nThis gives us \\(f(x) = 3x^4 + 13x^3 + 11x^2 + 17x + 4\\). This is a simple example, but it illustrates the point that multiplying two polynomials of degree \\(n\\) takes \\(O(n^2)\\) time.\nAnother way to do this multiplication is to do it pointwise. We can use a fact that a polynomial of degree \\(n\\) is uniquely determined by its values at \\(n+1\\) points. So we can evaluate \\(p(x)\\) and \\(f(x)\\) at some number points, multiply the values at each point, and then interpolate the resulting polynomial. This is called the point-value representation of a polynomial. Since both polynomials are of degree 2, the resulting polynomial will be of degree 4. In this case we will need 5 points from each polynomial to uniquely determine the resulting polynomial.\nVideo\nImagine we want to reconstruct the simple polynomial \\(f(x) = x^2\\) from a set of points using Lagrange Interpolation. We know that a polynomial of degree 2 requires 3 points to uniquely define it so we will pick the points (0,0), (1, 1), and (-1, 1).\nVideo\nSo another way to multiply polynomials is to first evaluate both polynomials at \\(n+1\\) points, multiply the values at each point, and then interpolate the resulting polynomial. The run time of doing this is also \\(O(n^2)\\) so it is not any faster than the first method. To get a faster algorithm we need to use the Fast Fourier Transform.\nOne fact of polynomials that will be helpful for understanding the Fast Fourier Transform is that any polynomial can be split into two polynomials where one contains the even powers and the other contains the odd powers. For example, \\(f(x) = x^4 + 2x^3 + 3x^2 + 4x + 5\\) can be split into \\(f_1(x) = x^4 + 3x^2 + 5\\) and \\(f_2(x) = 2x^3 + 4x\\). If you remember from high school algebra that polynomials of even degree are symmetric about the y-axis and polynomials of odd degree are anti-symmetric about the y-axis, you might be able to see where we are headed.\nVideo\nA mathematical definition is as follows: \\(P(x) = evens(x^2) + x * odds(x^2)\\) and \\(P(-x) = evens(x^2) - x * odds(x^2)\\). Because of these fact, we dont have to evaluate \\(n+1\\) points, instead we can just evaluate \\(\\lceil \\frac{n}{2} \\rceil + 1\\) points.\nWe need to introduce complex numbers because when we split, we are squaring the numbers which results in them being all positive. We can use what are called the Nth Roots of Unity to get around this. The Nth Roots of Unity are the numbers that are solutions to the equation \\(x^n = 1\\). For example, the 4th roots of unity are 1, -1, i, and -i. We define a term \\(\\omega = e^\\frac{2 \\pi i}{n}\\) which defines the roots of unity. In our previous example, the 4th Roots of Unity using \\(\\omega\\) are 1, \\(\\omega^2\\), \\(\\omega^3\\), and \\(\\omega^4\\). We can use these roots of unity to evaluate the polynomial at the points we need. An important equation we can use is \\(\\omega^{i+n/2} = -\\omega^i\\). When we square the the Nth roots of unity, we get the N/2 roots of unity. We can use these points for our evaluation to make sure that we have positive and negative paired points when we square the points.\nVideo\n\nimport math\nimport numpy as np\n\n\ndef fft(coeffs: list):\n    n = len(coeffs)\n\n    if n == 1:\n        return coeffs\n\n    # n needs to be a power of 2, so we zero pad it if it isn't\n    if n & (n - 1) != 0:\n        n = 2 ** math.ceil(math.log2(n))\n        coeffs += [0 for _ in range(n - len(coeffs))]\n\n    even = fft(coeffs[::2])\n    odd = fft(coeffs[1::2])\n    out = [0 for _ in range(n)]\n\n    omega = math.e ** (2 * math.pi * complex(0, 1) / n)\n\n    for i in range(n // 2):\n        out[i] = even[i] + omega ** i * odd[i]\n        out[i + n // 2] = even[i] - omega ** i * odd[i]\n\n    return out\n        \n\nvals = fft([4, 17, 11, 13, 3])\nprint([np.round(x) for x in vals])\n\n[(48+0j), (4+32j), (-4+4j), (-2+10j), (-12+0j), (-2-10j), (-4-4j), (4-32j)]\n\n\nWe can see that we got a list of points evaluated at the roots of unity of the function. At this point, we could multiply the points like we saw above to get another set of points describing the multiplied polynomial. To perform the Inverse Fast Fourier Transform we need to keep the first point and reverse the rest of the list. After that, we divide by the number of the points we evaluated at.\n\ndef ifft(coeffs: list):\n    vals = fft(coeffs)\n    return [val / len(vals) for val in [vals[0]] + vals[1:][::-1]]\n\nvals = ifft(vals)\nprint([np.round(x) for x in vals])\n\n[(4+0j), (17-0j), (11-0j), (13-0j), (3+0j), 0j, 0j, (-0+0j)]\n\n\nWe see that we got the same polynomial back, plus some extra terms because of the zero padding. The FFT runs in \\(O(n \\log{n})\\) time which makes it much faster than the \\(O(n^2)\\) time of the naive method.\n\n\n\nThe Fast Fourier Transform (FFT) is a powerful algorithm that revolutionized signal processing and data analysis. We have seen how it can be used to convert between the coefficient representation and the value representation of a polynomial quickly. The FFT gets used often in cryptography when dealing with polynomials and many other use cases where its speed is needed.\n\n\n\n\nReducible’s YouTube video\nVitalik Buterin’s blog"
  },
  {
    "objectID": "posts/fft/index.html#why-do-we-need-it",
    "href": "posts/fft/index.html#why-do-we-need-it",
    "title": "Fast Fourier Transform",
    "section": "",
    "text": "Say we want to multiply two polynomials \\(p(x) = x^2 + 4x + 1\\) and \\(f(x) = 3x^2 + x + 4\\). We can do this by multiplying each term in \\(p(x)\\) by each term in \\(f(x)\\) and adding the results.\nVideo\nThis gives us \\(f(x) = 3x^4 + 13x^3 + 11x^2 + 17x + 4\\). This is a simple example, but it illustrates the point that multiplying two polynomials of degree \\(n\\) takes \\(O(n^2)\\) time.\nAnother way to do this multiplication is to do it pointwise. We can use a fact that a polynomial of degree \\(n\\) is uniquely determined by its values at \\(n+1\\) points. So we can evaluate \\(p(x)\\) and \\(f(x)\\) at some number points, multiply the values at each point, and then interpolate the resulting polynomial. This is called the point-value representation of a polynomial. Since both polynomials are of degree 2, the resulting polynomial will be of degree 4. In this case we will need 5 points from each polynomial to uniquely determine the resulting polynomial.\nVideo\nImagine we want to reconstruct the simple polynomial \\(f(x) = x^2\\) from a set of points using Lagrange Interpolation. We know that a polynomial of degree 2 requires 3 points to uniquely define it so we will pick the points (0,0), (1, 1), and (-1, 1).\nVideo\nSo another way to multiply polynomials is to first evaluate both polynomials at \\(n+1\\) points, multiply the values at each point, and then interpolate the resulting polynomial. The run time of doing this is also \\(O(n^2)\\) so it is not any faster than the first method. To get a faster algorithm we need to use the Fast Fourier Transform.\nOne fact of polynomials that will be helpful for understanding the Fast Fourier Transform is that any polynomial can be split into two polynomials where one contains the even powers and the other contains the odd powers. For example, \\(f(x) = x^4 + 2x^3 + 3x^2 + 4x + 5\\) can be split into \\(f_1(x) = x^4 + 3x^2 + 5\\) and \\(f_2(x) = 2x^3 + 4x\\). If you remember from high school algebra that polynomials of even degree are symmetric about the y-axis and polynomials of odd degree are anti-symmetric about the y-axis, you might be able to see where we are headed.\nVideo\nA mathematical definition is as follows: \\(P(x) = evens(x^2) + x * odds(x^2)\\) and \\(P(-x) = evens(x^2) - x * odds(x^2)\\). Because of these fact, we dont have to evaluate \\(n+1\\) points, instead we can just evaluate \\(\\lceil \\frac{n}{2} \\rceil + 1\\) points.\nWe need to introduce complex numbers because when we split, we are squaring the numbers which results in them being all positive. We can use what are called the Nth Roots of Unity to get around this. The Nth Roots of Unity are the numbers that are solutions to the equation \\(x^n = 1\\). For example, the 4th roots of unity are 1, -1, i, and -i. We define a term \\(\\omega = e^\\frac{2 \\pi i}{n}\\) which defines the roots of unity. In our previous example, the 4th Roots of Unity using \\(\\omega\\) are 1, \\(\\omega^2\\), \\(\\omega^3\\), and \\(\\omega^4\\). We can use these roots of unity to evaluate the polynomial at the points we need. An important equation we can use is \\(\\omega^{i+n/2} = -\\omega^i\\). When we square the the Nth roots of unity, we get the N/2 roots of unity. We can use these points for our evaluation to make sure that we have positive and negative paired points when we square the points.\nVideo\n\nimport math\nimport numpy as np\n\n\ndef fft(coeffs: list):\n    n = len(coeffs)\n\n    if n == 1:\n        return coeffs\n\n    # n needs to be a power of 2, so we zero pad it if it isn't\n    if n & (n - 1) != 0:\n        n = 2 ** math.ceil(math.log2(n))\n        coeffs += [0 for _ in range(n - len(coeffs))]\n\n    even = fft(coeffs[::2])\n    odd = fft(coeffs[1::2])\n    out = [0 for _ in range(n)]\n\n    omega = math.e ** (2 * math.pi * complex(0, 1) / n)\n\n    for i in range(n // 2):\n        out[i] = even[i] + omega ** i * odd[i]\n        out[i + n // 2] = even[i] - omega ** i * odd[i]\n\n    return out\n        \n\nvals = fft([4, 17, 11, 13, 3])\nprint([np.round(x) for x in vals])\n\n[(48+0j), (4+32j), (-4+4j), (-2+10j), (-12+0j), (-2-10j), (-4-4j), (4-32j)]\n\n\nWe can see that we got a list of points evaluated at the roots of unity of the function. At this point, we could multiply the points like we saw above to get another set of points describing the multiplied polynomial. To perform the Inverse Fast Fourier Transform we need to keep the first point and reverse the rest of the list. After that, we divide by the number of the points we evaluated at.\n\ndef ifft(coeffs: list):\n    vals = fft(coeffs)\n    return [val / len(vals) for val in [vals[0]] + vals[1:][::-1]]\n\nvals = ifft(vals)\nprint([np.round(x) for x in vals])\n\n[(4+0j), (17-0j), (11-0j), (13-0j), (3+0j), 0j, 0j, (-0+0j)]\n\n\nWe see that we got the same polynomial back, plus some extra terms because of the zero padding. The FFT runs in \\(O(n \\log{n})\\) time which makes it much faster than the \\(O(n^2)\\) time of the naive method."
  },
  {
    "objectID": "topics.html",
    "href": "topics.html",
    "title": "Trevor's Website",
    "section": "",
    "text": "federated learning\nsha-3\ndiscrete logarithm problem\ninteger factorization problem\nsvp & cvp\nbasic modular arithmetic\ngroups, rings, fields\nlearning with errors\nzero knowledge proofs\nshamir secret sharing\noblivious transfer\nyao’s garbled circuits\nverifiable delay functions\nfast fourier transform\nring signatures\ndifferential privacy\nfully homomorphic encryption\nzk-snarks\nzk-starks\nmulti-party computation\nadvanced modular arithmetic\npairing based cryptography\nsiamese networks\nzk-ml\nsmart contracts\nprivate set intersection\nprivate information retrieval\ncrystals kyber\nring learning with errors\nimportance of privacy\nsecure remote password protocol\ninternals of linux\ngraph neural networks\nreinforcement learning"
  },
  {
    "objectID": "posts/fft/index.html#references",
    "href": "posts/fft/index.html#references",
    "title": "Fast Fourier Transform",
    "section": "",
    "text": "Reducible’s YouTube video\nVitalik Buterin’s blog"
  },
  {
    "objectID": "posts/fft/index.html#conclusion",
    "href": "posts/fft/index.html#conclusion",
    "title": "Fast Fourier Transform",
    "section": "",
    "text": "The Fast Fourier Transform (FFT) is a powerful algorithm that revolutionized signal processing and data analysis. We have seen how it can be used to convert between the coefficient representation and the value representation of a polynomial quickly. The FFT gets used often in cryptography when dealing with polynomials and many other use cases where its speed is needed."
  },
  {
    "objectID": "posts/merkletree/index.html",
    "href": "posts/merkletree/index.html",
    "title": "Merkle Trees",
    "section": "",
    "text": "In the world of cryptography and blockchain technology, Merkle trees are a crucial data structure that plays a significant role in ensuring data integrity and security. Named after Ralph Merkle, who first proposed the concept in 1979, Merkle trees have become an essential building block for various applications, including cryptocurrencies, distributed file systems, and more. In this blog post, we will delve into the concept of Merkle trees, their properties, and their applications in modern computing."
  },
  {
    "objectID": "posts/merkletree/index.html#introduction",
    "href": "posts/merkletree/index.html#introduction",
    "title": "Merkle Trees",
    "section": "",
    "text": "In the world of cryptography and blockchain technology, Merkle trees are a crucial data structure that plays a significant role in ensuring data integrity and security. Named after Ralph Merkle, who first proposed the concept in 1979, Merkle trees have become an essential building block for various applications, including cryptocurrencies, distributed file systems, and more. In this blog post, we will delve into the concept of Merkle trees, their properties, and their applications in modern computing."
  },
  {
    "objectID": "posts/merkletree/index.html#what-is-a-merkle-tree",
    "href": "posts/merkletree/index.html#what-is-a-merkle-tree",
    "title": "Merkle Trees",
    "section": "What is a Merkle Tree?",
    "text": "What is a Merkle Tree?\nA Merkle tree, also known as a hash tree, is a hierarchical data structure that represents a large dataset in a compact and verifiable way. It is constructed using hash functions, which are mathematical algorithms that take input data and produce a fixed-size string of characters, known as the hash value or hash digest. Merkle trees are binary trees, meaning that each node in the tree has at most two child nodes."
  },
  {
    "objectID": "posts/merkletree/index.html#how-does-a-merkle-tree-work",
    "href": "posts/merkletree/index.html#how-does-a-merkle-tree-work",
    "title": "Merkle Trees",
    "section": "How Does a Merkle Tree Work?",
    "text": "How Does a Merkle Tree Work?\nLet’s understand the construction of a Merkle tree with a simple example. Consider a dataset with four elements: \\(m_1, m_2, m_3, m_4\\). To create a Merkle tree from this dataset, the following steps are followed:\n\nHashing the Data: Each data element in the dataset is hashed individually. For our example, we apply a hash function (e.g., SHA-256) to get the hash values: \\(h(m_1), h(m_2), h(m_3), h(m_4)\\).\nPairwise Hashing: The hash values are then paired together, and each pair is concatenated and hashed again. In case the number of elements is odd, the last hash value is duplicated to form a pair. Continuing with our example, we get the intermediate hash values: \\(h(h(m_1)+h(m_2)), h(h(m_3)+h(m_4))\\).\nRoot Hash: The process of pairwise hashing continues until a single hash value remains. This final hash value, often called the root hash or the Merkle root, represents the entire dataset. In our example, we obtain the root hash: \\(h(h(h(m_1)+h(m_2)) + h(h(m_3)+h(m_4)))\\).\n\nThe resulting Merkle tree would look like this:"
  },
  {
    "objectID": "posts/merkletree/index.html#properties-of-merkle-trees",
    "href": "posts/merkletree/index.html#properties-of-merkle-trees",
    "title": "Merkle Trees",
    "section": "Properties of Merkle Trees",
    "text": "Properties of Merkle Trees\nMerkle trees offer several important properties that make them valuable in cryptographic applications:\n\nData Integrity: Any change in the original dataset would result in a completely different Merkle root, making it easy to detect alterations or tampering.\nEfficiency: Merkle trees allow for efficient verification of data integrity. Users can compare only a small portion of the tree (logarithmic in size) to ensure the authenticity of the entire dataset.\nParallelism: The structure of Merkle trees allows for parallel computation, making them suitable for distributed systems.\nCompactness: Even for large datasets, Merkle trees require minimal space to store the root hash."
  },
  {
    "objectID": "posts/merkletree/index.html#applications-of-merkle-trees",
    "href": "posts/merkletree/index.html#applications-of-merkle-trees",
    "title": "Merkle Trees",
    "section": "Applications of Merkle Trees",
    "text": "Applications of Merkle Trees\nMerkle trees find extensive use in various fields, including:\n\nBlockchain Technology: In blockchain systems like Bitcoin, Merkle trees are used to summarize transactions within a block, forming the block’s Merkle root. This root is stored in the blockchain’s header, ensuring the integrity of all transactions within the block.\nPeer-to-Peer Networks: In distributed file systems and peer-to-peer networks, Merkle trees are used to verify the integrity of data chunks during file transfers.\nCertificate Revocation: Merkle trees facilitate efficient certificate revocation in Public Key Infrastructures (PKI) by maintaining a compact and updatable list of revoked certificates."
  },
  {
    "objectID": "posts/merkletree/index.html#conclusion",
    "href": "posts/merkletree/index.html#conclusion",
    "title": "Merkle Trees",
    "section": "Conclusion",
    "text": "Conclusion\nMerkle trees are a fundamental data structure in cryptography that enables efficient and secure data verification. Their role in ensuring data integrity and tamper resistance has made them a vital component in various technologies, including blockchain and distributed systems. By understanding the principles behind Merkle trees, we can appreciate the significance of this elegant and versatile data structure in modern computing."
  },
  {
    "objectID": "posts/merkletree/index.html#references",
    "href": "posts/merkletree/index.html#references",
    "title": "Merkle Trees",
    "section": "References:",
    "text": "References:\nMerkle Trees - Wikipedia\nMastering Bitcoin: Unlocking Digital Cryptocurrencies by Andreas M. Antonopoulos"
  },
  {
    "objectID": "posts/cyclotomicpolynomials/index.html",
    "href": "posts/cyclotomicpolynomials/index.html",
    "title": "Cyclotomic Polynomials",
    "section": "",
    "text": "A cyclotomic polynomial is an irreducible polynomial whose roots are defined from the primitive roots of unity. The \\(n\\)th cyclotomic polynomial is denoted as \\(\\Phi_n(x)\\).\n\n\nThe \\(n\\)th roots of unity are the solutions to the equation \\(x^n = 1\\). The \\(n\\)th roots of unity are defined as \\(\\omega_n^k\\) where \\(\\omega_n = e^{\\frac{2\\pi i}{n}}\\) and \\(k \\in \\{0, 1, 2, \\dots, n-1\\}\\).\nFor example, the 4th roots of unity are \\(\\{1, i, -1, -i\\}\\).\n\n\n\nA primitive root of unity is a root of unity whose order is \\(n\\). The order of a root of unity is the smallest positive integer \\(k\\) such that \\(\\omega^k = 1\\). The primitive roots of unity are defined as \\(\\omega_n^k\\) where \\(\\omega_n = e^{\\frac{2\\pi i}{n}}\\) and \\(k \\in \\{0, 1, 2, \\dots, n-1\\}\\) such that \\(\\gcd(k, n) = 1\\).\nFor example, the primitive 4th roots of unity are \\(\\{1, -1\\}\\). This is because only \\(k = 1\\) and \\(k = 3\\) are coprime to \\(n = 4\\).\n\n\n\nThe \\(n\\)th cyclotomic polynomial is defined as \\(\\Phi_n(x) = \\prod_{k=1}^{\\phi(n)} (x - \\omega_n^k)\\) where \\(\\omega_n = e^{\\frac{2\\pi i}{n}}\\) and \\(\\phi(n)\\) is the Euler totient function. This makes sense because we are construction a polynomial in its point value representation using the primitive roots of unity as the points.\n\n\n\nRings that are defined as \\(\\it{t} = \\mathbb{Z}[x]/(\\Phi_n(x))\\) have special properties that make them useful in cryptography. Cyclotomic rings of powers of two are useful in many cryptographic schemes because they are maximally sparse and provide an easy way to compute the modulus operation. Using non power of two cyclomics is also an area being studied because it may be much more efficient, but the tradeoff is that they are more delicate.\n\n\n\nCyclotomic polynomials are useful in cryptography. Fully homomorphic encryption schemes like CKKS can utilize the cyclotomic ring structures because of their nice properties. They are also useful in other areas of mathematics such as number theory and algebraic geometry."
  },
  {
    "objectID": "posts/cyclotomicpolynomials/index.html#nth-roots-of-unity",
    "href": "posts/cyclotomicpolynomials/index.html#nth-roots-of-unity",
    "title": "Cyclotomic Polynomials",
    "section": "",
    "text": "The \\(n\\)th roots of unity are the solutions to the equation \\(x^n = 1\\). The \\(n\\)th roots of unity are defined as \\(\\omega_n^k\\) where \\(\\omega_n = e^{\\frac{2\\pi i}{n}}\\) and \\(k \\in \\{0, 1, 2, \\dots, n-1\\}\\).\nFor example, the 4th roots of unity are \\(\\{1, i, -1, -i\\}\\)."
  },
  {
    "objectID": "posts/cyclotomicpolynomials/index.html#primitive-roots-of-unity",
    "href": "posts/cyclotomicpolynomials/index.html#primitive-roots-of-unity",
    "title": "Cyclotomic Polynomials",
    "section": "",
    "text": "A primitive root of unity is a root of unity whose order is \\(n\\). The order of a root of unity is the smallest positive integer \\(k\\) such that \\(\\omega^k = 1\\). The primitive roots of unity are defined as \\(\\omega_n^k\\) where \\(\\omega_n = e^{\\frac{2\\pi i}{n}}\\) and \\(k \\in \\{0, 1, 2, \\dots, n-1\\}\\) such that \\(\\gcd(k, n) = 1\\).\nFor example, the primitive 4th roots of unity are \\(\\{1, -1\\}\\). This is because only \\(k = 1\\) and \\(k = 3\\) are coprime to \\(n = 4\\)."
  },
  {
    "objectID": "posts/cyclotomicpolynomials/index.html#cyclotomic-rings",
    "href": "posts/cyclotomicpolynomials/index.html#cyclotomic-rings",
    "title": "Cyclotomic Polynomials",
    "section": "",
    "text": "Rings that are defined as \\(\\it{t} = \\mathbb{Z}[x]/(\\Phi_n(x))\\) have special properties that make them useful in cryptography. Cyclotomic rings of powers of two are useful in many cryptographic schemes because they are maximally sparse and provide an easy way to compute the modulus operation. Using non power of two cyclomics is also an area being studied because it may be much more efficient, but the tradeoff is that they are more delicate."
  },
  {
    "objectID": "posts/cyclotomicpolynomials/index.html#conclusion",
    "href": "posts/cyclotomicpolynomials/index.html#conclusion",
    "title": "Cyclotomic Polynomials",
    "section": "",
    "text": "Cyclotomic polynomials are useful in cryptography. Fully homomorphic encryption schemes like CKKS can utilize the cyclotomic ring structures because of their nice properties. They are also useful in other areas of mathematics such as number theory and algebraic geometry."
  },
  {
    "objectID": "posts/cyclotomicpolynomials/index.html#equation-for-cyclotomic-polynomials",
    "href": "posts/cyclotomicpolynomials/index.html#equation-for-cyclotomic-polynomials",
    "title": "Cyclotomic Polynomials",
    "section": "",
    "text": "The \\(n\\)th cyclotomic polynomial is defined as \\(\\Phi_n(x) = \\prod_{k=1}^{\\phi(n)} (x - \\omega_n^k)\\) where \\(\\omega_n = e^{\\frac{2\\pi i}{n}}\\) and \\(\\phi(n)\\) is the Euler totient function. This makes sense because we are construction a polynomial in its point value representation using the primitive roots of unity as the points."
  },
  {
    "objectID": "posts/vandermondematrices/index.html",
    "href": "posts/vandermondematrices/index.html",
    "title": "Vandermonde Matrices",
    "section": "",
    "text": "When studying linear algebra, one often comes across various types of matrices with unique properties and applications. One such matrix is the Vandermonde matrix. Named after the French mathematician Alexandre-Théophile Vandermonde, this matrix holds special significance in fields ranging from polynomial interpolation to signal processing. In this blog post, we will delve into the concept of Vandermonde matrices, their properties, and some of their important applications.\n\n\nA Vandermond matrix is a \\((m + 1)(n + 1)\\) matrix of the form: \\(V(x_0, x_1, \\dots,x_m) = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\dots & x_0^n \\\\ 1 & x_1 & x_1^2 & \\dots & x_1^n \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_m & x_m^2 & \\dots & x_m^n \\end{bmatrix}\\)\nwhere \\(x_0, x_1, \\dots, x_m\\) are distinct real numbers. In other words, a Vandermonde matrix is a matrix whose columns are successive powers of a given vector.\n\n\n\nOne use case of a Vandermond matrix is for polynomial interpolation. These matrices are used often in cryptography in schemes such as CKKS.\nIf you are given the coefficients of a polynomial and want to evaluate it into point-value representation at a set of points you can use the equation \\(Va = y\\). For example, suppose you have a polynomial \\(p(x) = 2x^2 + 3x + 1\\) and you want to evaluate it at the points \\(x_0 = 1, x_1 = 2, x_2 = 3\\). Then, you can use the Vandermonde matrix \\(V = \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 4 \\\\ 1 & 3 & 9 \\end{bmatrix}\\) to evaluate \\(p(x)\\) at the points \\(x_0, x_1, x_2\\) by computing \\(V\\begin{bmatrix} 1 \\\\ 3 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 6 \\\\ 17 \\\\ 38 \\end{bmatrix}\\). This is equivalent to evaluating \\(p(x)\\) at the points \\(x_0, x_1, x_2\\) by hand.\nSuppose you have a set of points \\((x_0, y_0), (x_1, y_1), \\dots, (x_m, y_m)\\) where \\(x_0, x_1, \\dots, x_m\\) are distinct real numbers. We want to find a polynomial \\(p(x)\\) of degree at most \\(m\\) such that \\(p(x_i) = y_i\\) for \\(i = 0, 1, \\dots, m\\). Let \\(V\\) be the Vandermonde matrix with entries \\(V_{ij} = x_i^j\\) for \\(i = 0, 1, \\dots, m\\) and \\(j = 0, 1, \\dots, m\\). Let \\(y = \\begin{bmatrix} y_0 \\\\ y_1 \\\\ \\vdots \\\\ y_m \\end{bmatrix}\\). Then, we can solve for the coefficients of the polynomial \\(p(x)\\) by solving the system of equations \\(Vc = y\\) where \\(c = \\begin{bmatrix} c_0 \\\\ c_1 \\\\ \\vdots \\\\ c_m \\end{bmatrix}\\) is the vector of coefficients of \\(p(x)\\). This system of equations is guaranteed to have a unique solution since the Vandermonde matrix is invertible. Thus, we can find the coefficients of \\(p(x)\\) by solving the system of equations \\(c = V^{-1}y\\).\nThe Discrete Fourier Transform is a specific Vandermonde matrix where the entries are \\(n^{th}\\) roots of unity. By using regular linear algebra methods you can solve the DFT matrix in \\(O(n^2)\\). The Fast Fourier Transform is an algorithm that computes the Discrete Fourier Transform in \\(O(n\\log n)\\) time.\n\n\n\nThe determinant of a square Vandermonde matrix is given by the formula \\(det(V) = \\prod_{0 \\leq i &lt; j \\leq n}(x_j - x_i)\\). This formula might look familiar because it is also the formula for computing the Lagrange bases for polynomial interpolation.\n\n\n\nIn conclusion, Vandermonde matrices are a fascinating and powerful concept in linear algebra with wide-ranging applications. Their distinct properties and versatility make them a valuable tool in various mathematical and engineering disciplines. Whether you’re working on polynomial interpolation, signal processing, or other mathematical problems, understanding Vandermonde matrices can provide you with insights and techniques to solve complex challenges."
  },
  {
    "objectID": "posts/vandermondematrices/index.html#what-is-a-vandermonde-matrix",
    "href": "posts/vandermondematrices/index.html#what-is-a-vandermonde-matrix",
    "title": "Vandermonde Matrices",
    "section": "",
    "text": "A Vandermond matrix is a \\((m + 1)(n + 1)\\) matrix of the form: \\(V(x_0, x_1, \\dots,x_m) = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\dots & x_0^n \\\\ 1 & x_1 & x_1^2 & \\dots & x_1^n \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_m & x_m^2 & \\dots & x_m^n \\end{bmatrix}\\)\nwhere \\(x_0, x_1, \\dots, x_m\\) are distinct real numbers. In other words, a Vandermonde matrix is a matrix whose columns are successive powers of a given vector."
  },
  {
    "objectID": "posts/vandermondematrices/index.html#use-cases",
    "href": "posts/vandermondematrices/index.html#use-cases",
    "title": "Vandermonde Matrices",
    "section": "",
    "text": "One use case of a Vandermond matrix is for polynomial interpolation. These matrices are used often in cryptography in schemes such as CKKS.\nIf you are given the coefficients of a polynomial and want to evaluate it into point-value representation at a set of points you can use the equation \\(Va = y\\). For example, suppose you have a polynomial \\(p(x) = 2x^2 + 3x + 1\\) and you want to evaluate it at the points \\(x_0 = 1, x_1 = 2, x_2 = 3\\). Then, you can use the Vandermonde matrix \\(V = \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 4 \\\\ 1 & 3 & 9 \\end{bmatrix}\\) to evaluate \\(p(x)\\) at the points \\(x_0, x_1, x_2\\) by computing \\(V\\begin{bmatrix} 1 \\\\ 3 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 6 \\\\ 17 \\\\ 38 \\end{bmatrix}\\). This is equivalent to evaluating \\(p(x)\\) at the points \\(x_0, x_1, x_2\\) by hand.\nSuppose you have a set of points \\((x_0, y_0), (x_1, y_1), \\dots, (x_m, y_m)\\) where \\(x_0, x_1, \\dots, x_m\\) are distinct real numbers. We want to find a polynomial \\(p(x)\\) of degree at most \\(m\\) such that \\(p(x_i) = y_i\\) for \\(i = 0, 1, \\dots, m\\). Let \\(V\\) be the Vandermonde matrix with entries \\(V_{ij} = x_i^j\\) for \\(i = 0, 1, \\dots, m\\) and \\(j = 0, 1, \\dots, m\\). Let \\(y = \\begin{bmatrix} y_0 \\\\ y_1 \\\\ \\vdots \\\\ y_m \\end{bmatrix}\\). Then, we can solve for the coefficients of the polynomial \\(p(x)\\) by solving the system of equations \\(Vc = y\\) where \\(c = \\begin{bmatrix} c_0 \\\\ c_1 \\\\ \\vdots \\\\ c_m \\end{bmatrix}\\) is the vector of coefficients of \\(p(x)\\). This system of equations is guaranteed to have a unique solution since the Vandermonde matrix is invertible. Thus, we can find the coefficients of \\(p(x)\\) by solving the system of equations \\(c = V^{-1}y\\).\nThe Discrete Fourier Transform is a specific Vandermonde matrix where the entries are \\(n^{th}\\) roots of unity. By using regular linear algebra methods you can solve the DFT matrix in \\(O(n^2)\\). The Fast Fourier Transform is an algorithm that computes the Discrete Fourier Transform in \\(O(n\\log n)\\) time."
  },
  {
    "objectID": "posts/vandermondematrices/index.html#conclusion",
    "href": "posts/vandermondematrices/index.html#conclusion",
    "title": "Vandermonde Matrices",
    "section": "",
    "text": "In conclusion, Vandermonde matrices are a fascinating and powerful concept in linear algebra with wide-ranging applications. Their distinct properties and versatility make them a valuable tool in various mathematical and engineering disciplines. Whether you’re working on polynomial interpolation, signal processing, or other mathematical problems, understanding Vandermonde matrices can provide you with insights and techniques to solve complex challenges."
  },
  {
    "objectID": "posts/vandermondematrices/index.html#determinant",
    "href": "posts/vandermondematrices/index.html#determinant",
    "title": "Vandermonde Matrices",
    "section": "",
    "text": "The determinant of a square Vandermonde matrix is given by the formula \\(det(V) = \\prod_{0 \\leq i &lt; j \\leq n}(x_j - x_i)\\). This formula might look familiar because it is also the formula for computing the Lagrange bases for polynomial interpolation."
  },
  {
    "objectID": "posts/ckks/index.html",
    "href": "posts/ckks/index.html",
    "title": "Introduction to CKKS",
    "section": "",
    "text": "The HEAAN / CKKS scheme introduced in the paper, Homomorphic Encryption for Arithmetic of Approximate Numbers or named after the authors, Jung Hee Cheon, Andrey Kim, Miran Kim, and Yongsoo Song is a leveled homomorphic scheme based upon the Ring Learning with Errors (RLWE) problem that allows encypted computation on real real numbers. This scheme differs from BGV/BFV schemes because it works on real numbers rather than integers.\n\n\nUnderstanding the following notations will be helpful for reading this blog post:\n\n\\(\\mathcal{R} = \\mathbb{Z}[X]/(X^N +1)\\)\n\\(\\mathbb{Z}_q\\) is in the range \\((−q/2, q/2]\\)\n\\(\\lfloor x \\rceil\\) represents the rounding of the real number x to the closest integer\n\n\n\n\n\\(\\Delta\\) is the scaling factor\n\n\n\nThis scheme operates allows us to encode a vector, \\(\\mathbb{C}^{N/2}\\), into the ciphertext space, \\(\\mathcal{R}_q = (\\mathbb{Z}/q\\mathbb{Z})[X]/(X^N +1)\\) using a ring isomorphism and cannoncial embedding map.\nA cyclotomic polynomial is a polynomial with integer coefficients whose roots are all primitive. An example would be the 4th cyclotomic polynomial or \\(\\phi_4(x) = x^2 + 1\\). One important property of cyclotomic polynomials is that if N is a power of two, then the polynomial is equal to \\(x^{N/2} + 1\\).\n\nA Toolkit for Ring-LWE Cryptography\nMore information about these polynomials can be found here on Wikipedia\nFor any cyclotomic polynomial, \\(a\\), we can say that \\(a(\\xi^j) = a(\\overline{\\xi^{-j}})\\)\n\n\nCode\nimport numpy as np\nimport math\n\ndef primitive_nth_roots_of_unity(n: int) -&gt; np.ndarray:\n    roots = []\n    \n    for i in range(1, n+1):\n        if math.gcd(i, n) == 1:\n            root = np.e ** (2 * np.pi * 1j * i / n)\n            roots.append(root)\n\n    return np.array(roots)\n\neigth_prim_roots = primitive_nth_roots_of_unity(8)\n\nfor i, r in enumerate(eigth_prim_roots):\n    print(f\"Root #{i+1}: {r}\\nConjugate: {np.conjugate(r)}\\n\")\n\n\nRoot #1: (0.7071067811865476+0.7071067811865475j)\nConjugate: (0.7071067811865476-0.7071067811865475j)\n\nRoot #2: (-0.7071067811865475+0.7071067811865476j)\nConjugate: (-0.7071067811865475-0.7071067811865476j)\n\nRoot #3: (-0.7071067811865477-0.7071067811865475j)\nConjugate: (-0.7071067811865477+0.7071067811865475j)\n\nRoot #4: (0.7071067811865474-0.7071067811865477j)\nConjugate: (0.7071067811865474+0.7071067811865477j)\n\n\n\nFrom this week can see that \\(\\xi^1 = \\overline{\\xi^7}\\) and \\(\\xi^3 = \\overline{\\xi^5}\\).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nn = 8\n\nroots = [np.exp(2j * np.pi * k / n) for k in range(n) if np.gcd(k, n) == 1]\n\nreal_parts = [root.real for root in roots]\nimaginary_parts = [root.imag for root in roots]\n\nlabels = ['ξ^1', 'ξ^3', 'ξ^5', 'ξ^7']\n\nfor i, (x, y) in enumerate(zip(real_parts, imaginary_parts)):\n    plt.scatter(x, y, color='red', label=labels[i])\n    plt.text(x + 0.1, y, labels[i], fontsize=12)\n\nfor root in roots:\n    plt.plot([0, root.real], [0, root.imag], linestyle='--', color='blue')\n\nplt.xlabel('Real Part')\nplt.ylabel('Imaginary Part')\nplt.axhline(0, color='black', linewidth=0.5)\nplt.axvline(0, color='black', linewidth=0.5)\nplt.grid(color='gray', linestyle='--', linewidth=0.5)\n\nplt.axis('equal')\n\nplt.xlim(-1.5, 1.5)\nplt.ylim(-1.5, 1.5)\n\nplt.title(f'Primitive 8th Roots of Unity')\n\nplt.show()\n\n\n\n\n\nThis makes intuitive sense if we look at a graph of the roots and see that primitive roots of unity are always symmetric over the x axis.\n\\(\\mathbb{H}\\) of is a subring of \\(\\mathbb{C}^N\\) that contains elements of \\(\\mathbb{C}^N\\) where the conjugate is also in the subring.\nWe define an operation \\(\\pi^{-1}\\) which expands a vector \\(\\mathbb{C}^{N/2}\\) into \\(\\mathbb{H}\\)\n\ndef pi_inverse(z: np.ndarray) -&gt; np.ndarray:\n    return np.concatenate([z, [np.conjugate(x) for x in z[::-1]]])\n\nz = np.array([3+4j,2-1j])\n\nfor i in range(len(z)):\n    print(f\"i: {i}, {z[i]} = i: {(-i-1) % 4}, {np.conjugate(z[-i])}\")\n\nprint()\nprint(list(pi_inverse(z)))\n\ni: 0, (3+4j) = i: 3, (3-4j)\ni: 1, (2-1j) = i: 2, (2+1j)\n\n[(3+4j), (2-1j), (2+1j), (3-4j)]\n\n\n\\(\\sigma(x)\\) is equivalent to the evaluation of a polynomial on the roots of unity for the given cyclotomic polynomial which will produce an element in \\(\\mathbb{C}^N\\).\nImagine \\(\\Delta\\) is 10,000. We can say that \\(\\frac{(\\Delta m * \\Delta n)}{\\Delta^2} = m * n\\). For example let \\(m = 3.14\\) and \\(n = 2.72\\). We expect the result to equal 8.5408.\n\nMultiply \\(m\\) by \\(\\Delta\\), \\(\\Delta * m = 31,400\\)\nMultiply \\(n\\) by \\(\\Delta\\), \\(\\Delta * n = 27,200\\)\nAdd \\(\\Delta m * \\Delta n = 854,080,000\\)\nDivide result by \\(\\Delta^2\\), \\(854,080,000 / \\Delta^2 = 8.5408\\)\n\nThe canonical embedding \\(\\sigma\\) is defined as \\(\\sigma : \\mathbb{R}[X]/(X^N +1) \\rightarrow \\mathbb{C}^N\\) which is equaluating the polynomial on the primitive complex roots of unity to get a vector of points Its inverse would be \\(\\sigma^{-1} : \\mathbb{C}^N \\rightarrow \\mathbb{R}[X]/(X^N +1)\\) which takes a list of points and produces a polynomial.\nAn element in \\(\\mathbb{H}\\) is not necessarily an element in \\(\\sigma(\\mathcal{R})\\) so we have to project each element into \\(\\sigma(\\mathcal{R})\\).\nWe want to project the elements of \\(\\mathbb{H}\\) onto the bases of \\(\\sigma(\\mathcal{R})\\) which are \\(\\beta = (\\sigma(1),\\sigma(X),\\dots,\\sigma(X^{N−1}))\\) and to have integer coefficients rather than complex ones.\nThe first step is to project the elements of our vector \\(z\\) onto the bases of \\(\\sigma(\\mathcal{R})\\).\nThis can be done by using the vector projection equation first learning in a college algebra course. It is defined as \\(proj_\\beta z = \\frac{z * \\beta}{\\left\\| \\beta \\right\\|} * \\beta\\).\nAfter that we will have a polynomial that has the same bases of \\(\\sigma(\\mathcal{R})\\), but we still need to round it so that it has integer coefficients.\nA technique for this discretization is called “coordinate-wise randomized rounding” and is explained in section 2.4.2 of A Toolkit for Ring-LWE Cryptography.\nLet \\(\\Lambda = \\mathcal{L}(B) \\subset \\mathbb{R}\\) represented by the basis \\(B\\) Given a point \\(x \\in \\mathbb{R}\\) and a coset \\(c \\in \\mathbb{R}\\), the goal is to find an element, \\(y\\) on the lattice \\(\\Lambda\\) that minimizes the length of \\(y-x\\).\nWe define a new coset, \\(c' = \\Sigma^{n}_i=1=a_ib_i \\mod \\lambda\\) for the coefficients a which are the decimal parts of our x point between 0 and 1. We choose \\(f_i\\) randomly from \\(\\{a-1, a\\}\\). We then multiply by the basis to complete the prijection.\nIn other words, we first compute \\(randround(\\frac{\\langle z_i b_i \\rangle}{\\langle b_i b_i\\rangle})\\) for every basis vector and then we multiply it by \\(b\\) like the previous projection formula told us.\n\ndef rand_round(x: float) -&gt; int:\n    decimal = x - np.floor(x)\n    f = np.random.choice([decimal-1, decimal])\n    return int(x + f)\n\n\ndef cwrr(coords: np.ndarray) -&gt; np.ndarray:\n    return np.array([rand_round(x) for x in coords])\n\n\ndef discretization(z: np.ndarray) -&gt; np.ndarray:\n    bases = np.vander(primitive_nth_roots_of_unity(2*N), N, increasing=True).T\n    proj = np.array([np.real(np.vdot(z, b) / np.vdot(b,b)) for b in bases])\n\n    return cwrr(proj) @ bases\n\nAfter that we have have to compute \\(\\sigma^{-1}(\\lfloor\\Delta \\pi^{-1}(m)\\rceil_{\\sigma(\\mathcal{R})})\\) to get our final transformation into the ciphertext space \\(\\mathbb{Z}_q[X]/(X^N +1)\\)\nWe have a list of points so we can use the vandermonde matrix to solve for the coefficients by solving \\(Va = y\\) where V is the vandermonde matrix, a are the polynomial coefficients, and y are the points that we have.\n\nfrom numpy.polynomial import Polynomial\n\n\ndef sigma_inverse(b: np.ndarray) -&gt; Polynomial:\n    A = np.vander(primitive_nth_roots_of_unity(2*N), N, increasing=True)\n    coeffs = np.linalg.solve(A, b)\n    return Polynomial(coeffs)\n\nOnce we put it together we have our complete encoding functionality.\n\nDELTA = 64\nN = 4\n\n\ndef pi_inverse(z: np.ndarray) -&gt; np.ndarray:\n    return np.concatenate([z, [np.conjugate(x) for x in z[::-1]]])\n\n\ndef rand_round(x: float) -&gt; int:\n    decimal = x - np.floor(x)\n    f = np.random.choice([decimal-1, decimal])\n    return int(x + f)\n\n\ndef cwrr(coords: np.ndarray) -&gt; np.ndarray:\n    return np.array([rand_round(x) for x in coords])\n\n\ndef discretization(z: np.ndarray) -&gt; np.ndarray:\n    bases = np.vander(primitive_nth_roots_of_unity(2*N), N, increasing=True).T\n    proj = np.array([np.real(np.vdot(z, b) / np.vdot(b,b)) for b in bases])\n\n    return cwrr(proj) @ bases\n\n\ndef sigma_inverse(b: np.ndarray) -&gt; Polynomial:\n    A = np.vander(primitive_nth_roots_of_unity(2*N), N, increasing=True)\n    coeffs = np.linalg.solve(A, b)\n    return Polynomial(coeffs)\n\n\ndef encode(z: np.ndarray) -&gt; Polynomial:\n    out = pi_inverse(z)\n    out *= DELTA\n    out = discretization(out)\n    out = sigma_inverse(out)\n    \n    out = np.round(np.real(out.coef)).astype(int)\n    return Polynomial(out)\n\n\nz = np.array([3+4j, 2-1j])\nencoded_z = encode(z)\nprint(encoded_z)\n\n160.0 + 91.0·x + 159.0·x² + 44.0·x³\n\n\nIf compare with the paper’s example we can see that we got the same polynomial that they did and our scheme worked.\nTo recap how our encoding scheme encodes \\(m \\in \\mathbb{C}^{N/2} \\rightarrow \\mathbb{Z}_q[X]/(X^N +1)\\):\n\n\\(\\pi^{-1}(m)\\) applies \\(\\mathbb{C}^{N/2} \\rightarrow \\mathbb{H}\\)\nScale our element: \\(\\Delta \\pi^{-1}(m)\\)\nProject and randomly round our element into the space of \\(\\sigma(\\mathcal{R})\\)\nApply \\(\\sigma^{-1}(\\lfloor\\Delta \\pi^{-1}(m)\\rceil_{\\sigma(\\mathcal{R})}) \\in \\mathbb{Z}_q[X]/(X^N +1)\\)\n\n\n\n\nDecoding is very easy to understand as it is pretty much the opposite of encoding.\nOur goal is to convert the polynomial in the ring \\(\\mathbb{Z}_q[X]/(X^N +1)\\) to our plaintext in the space \\(\\mathbb{C}^{N/2}\\).\nFirst we have to multiply our polynomial by \\(\\Delta^{-1}\\).\nThen we use the canonical embedding map \\(\\sigma: \\mathbb{R}[X]/(X^N +1) \\rightarrow \\mathbb{C}^{N/2}\\) which is equivalent to evaluating the polynomial, p, at all of our primitive roots of unity and can be calculated with the vandermonde matrix.\n\ndef sigma(p: Polynomial) -&gt; np.ndarray:\n    V = np.vander(primitive_nth_roots_of_unity(2*N), N, increasing=True)\n    a = p.coef\n    y = V @ a\n    return y\n\nNext we have to perform \\(\\pi\\) to take an element \\(\\in \\mathbb{H}\\) and transform it into and element \\(\\in \\mathbb{C}^{N/2}\\)\n\ndef pi(z: np.ndarray) -&gt; np.ndarray:\n    return z[:N//2]\n\nNow we put it all together to get our decoding function.\n\ndef decode(p: Polynomial) -&gt; np.ndarray:\n    p *= 1/DELTA\n    y = sigma(p)\n    return pi(y)\n\nprint(decode(encoded_z))\n\n[3.01928154+3.97592837j 1.98071846-0.99282163j]"
  },
  {
    "objectID": "posts/ckks/index.html#notation",
    "href": "posts/ckks/index.html#notation",
    "title": "Introduction to CKKS",
    "section": "",
    "text": "Understanding the following notations will be helpful for reading this blog post:\n\n\\(\\mathcal{R} = \\mathbb{Z}[X]/(X^N +1)\\)\n\\(\\mathbb{Z}_q\\) is in the range \\((−q/2, q/2]\\)\n\\(\\lfloor x \\rceil\\) represents the rounding of the real number x to the closest integer"
  },
  {
    "objectID": "posts/ckks/index.html#encoding",
    "href": "posts/ckks/index.html#encoding",
    "title": "Introduction to CKKS",
    "section": "",
    "text": "This scheme operates allows us to encode a vector, \\(\\mathbb{C}^{N/2}\\), into the ciphertext space, \\(\\mathcal{R}_q = (\\mathbb{Z}/q\\mathbb{Z})[X]/(X^N +1)\\) using a ring isomorphism and cannoncial embedding map.\nA cyclotomic polynomial is a polynomial with integer coefficients whose roots are all primitive. An example would be the 4th cyclotomic polynomial or \\(\\phi_4(x) = x^2 + 1\\). One important property of cyclotomic polynomials is that if N is a power of two, then the polynomial is equal to \\(x^{N/2} + 1\\).\n\nA Toolkit for Ring-LWE Cryptography\nMore information about these polynomials can be found here on Wikipedia\nFor any cyclotomic polynomial, \\(a\\), we can say that \\(a(\\xi^j) = a(\\overline{\\xi^{-j}})\\)\n\n\nCode\nimport numpy as np\nimport math\n\ndef primitive_nth_roots_of_unity(n: int) -&gt; np.ndarray:\n    roots = []\n    \n    for i in range(1, n+1):\n        if math.gcd(i, n) == 1:\n            root = np.e ** (2 * np.pi * 1j * i / n)\n            roots.append(root)\n\n    return np.array(roots)\n\neigth_prim_roots = primitive_nth_roots_of_unity(8)\n\nfor i, r in enumerate(eigth_prim_roots):\n    print(f\"Root #{i+1}: {r}\\nConjugate: {np.conjugate(r)}\\n\")\n\n\nRoot #1: (0.7071067811865476+0.7071067811865475j)\nConjugate: (0.7071067811865476-0.7071067811865475j)\n\nRoot #2: (-0.7071067811865475+0.7071067811865476j)\nConjugate: (-0.7071067811865475-0.7071067811865476j)\n\nRoot #3: (-0.7071067811865477-0.7071067811865475j)\nConjugate: (-0.7071067811865477+0.7071067811865475j)\n\nRoot #4: (0.7071067811865474-0.7071067811865477j)\nConjugate: (0.7071067811865474+0.7071067811865477j)\n\n\n\nFrom this week can see that \\(\\xi^1 = \\overline{\\xi^7}\\) and \\(\\xi^3 = \\overline{\\xi^5}\\).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nn = 8\n\nroots = [np.exp(2j * np.pi * k / n) for k in range(n) if np.gcd(k, n) == 1]\n\nreal_parts = [root.real for root in roots]\nimaginary_parts = [root.imag for root in roots]\n\nlabels = ['ξ^1', 'ξ^3', 'ξ^5', 'ξ^7']\n\nfor i, (x, y) in enumerate(zip(real_parts, imaginary_parts)):\n    plt.scatter(x, y, color='red', label=labels[i])\n    plt.text(x + 0.1, y, labels[i], fontsize=12)\n\nfor root in roots:\n    plt.plot([0, root.real], [0, root.imag], linestyle='--', color='blue')\n\nplt.xlabel('Real Part')\nplt.ylabel('Imaginary Part')\nplt.axhline(0, color='black', linewidth=0.5)\nplt.axvline(0, color='black', linewidth=0.5)\nplt.grid(color='gray', linestyle='--', linewidth=0.5)\n\nplt.axis('equal')\n\nplt.xlim(-1.5, 1.5)\nplt.ylim(-1.5, 1.5)\n\nplt.title(f'Primitive 8th Roots of Unity')\n\nplt.show()\n\n\n\n\n\nThis makes intuitive sense if we look at a graph of the roots and see that primitive roots of unity are always symmetric over the x axis.\n\\(\\mathbb{H}\\) of is a subring of \\(\\mathbb{C}^N\\) that contains elements of \\(\\mathbb{C}^N\\) where the conjugate is also in the subring.\nWe define an operation \\(\\pi^{-1}\\) which expands a vector \\(\\mathbb{C}^{N/2}\\) into \\(\\mathbb{H}\\)\n\ndef pi_inverse(z: np.ndarray) -&gt; np.ndarray:\n    return np.concatenate([z, [np.conjugate(x) for x in z[::-1]]])\n\nz = np.array([3+4j,2-1j])\n\nfor i in range(len(z)):\n    print(f\"i: {i}, {z[i]} = i: {(-i-1) % 4}, {np.conjugate(z[-i])}\")\n\nprint()\nprint(list(pi_inverse(z)))\n\ni: 0, (3+4j) = i: 3, (3-4j)\ni: 1, (2-1j) = i: 2, (2+1j)\n\n[(3+4j), (2-1j), (2+1j), (3-4j)]\n\n\n\\(\\sigma(x)\\) is equivalent to the evaluation of a polynomial on the roots of unity for the given cyclotomic polynomial which will produce an element in \\(\\mathbb{C}^N\\).\nImagine \\(\\Delta\\) is 10,000. We can say that \\(\\frac{(\\Delta m * \\Delta n)}{\\Delta^2} = m * n\\). For example let \\(m = 3.14\\) and \\(n = 2.72\\). We expect the result to equal 8.5408.\n\nMultiply \\(m\\) by \\(\\Delta\\), \\(\\Delta * m = 31,400\\)\nMultiply \\(n\\) by \\(\\Delta\\), \\(\\Delta * n = 27,200\\)\nAdd \\(\\Delta m * \\Delta n = 854,080,000\\)\nDivide result by \\(\\Delta^2\\), \\(854,080,000 / \\Delta^2 = 8.5408\\)\n\nThe canonical embedding \\(\\sigma\\) is defined as \\(\\sigma : \\mathbb{R}[X]/(X^N +1) \\rightarrow \\mathbb{C}^N\\) which is equaluating the polynomial on the primitive complex roots of unity to get a vector of points Its inverse would be \\(\\sigma^{-1} : \\mathbb{C}^N \\rightarrow \\mathbb{R}[X]/(X^N +1)\\) which takes a list of points and produces a polynomial.\nAn element in \\(\\mathbb{H}\\) is not necessarily an element in \\(\\sigma(\\mathcal{R})\\) so we have to project each element into \\(\\sigma(\\mathcal{R})\\).\nWe want to project the elements of \\(\\mathbb{H}\\) onto the bases of \\(\\sigma(\\mathcal{R})\\) which are \\(\\beta = (\\sigma(1),\\sigma(X),\\dots,\\sigma(X^{N−1}))\\) and to have integer coefficients rather than complex ones.\nThe first step is to project the elements of our vector \\(z\\) onto the bases of \\(\\sigma(\\mathcal{R})\\).\nThis can be done by using the vector projection equation first learning in a college algebra course. It is defined as \\(proj_\\beta z = \\frac{z * \\beta}{\\left\\| \\beta \\right\\|} * \\beta\\).\nAfter that we will have a polynomial that has the same bases of \\(\\sigma(\\mathcal{R})\\), but we still need to round it so that it has integer coefficients.\nA technique for this discretization is called “coordinate-wise randomized rounding” and is explained in section 2.4.2 of A Toolkit for Ring-LWE Cryptography.\nLet \\(\\Lambda = \\mathcal{L}(B) \\subset \\mathbb{R}\\) represented by the basis \\(B\\) Given a point \\(x \\in \\mathbb{R}\\) and a coset \\(c \\in \\mathbb{R}\\), the goal is to find an element, \\(y\\) on the lattice \\(\\Lambda\\) that minimizes the length of \\(y-x\\).\nWe define a new coset, \\(c' = \\Sigma^{n}_i=1=a_ib_i \\mod \\lambda\\) for the coefficients a which are the decimal parts of our x point between 0 and 1. We choose \\(f_i\\) randomly from \\(\\{a-1, a\\}\\). We then multiply by the basis to complete the prijection.\nIn other words, we first compute \\(randround(\\frac{\\langle z_i b_i \\rangle}{\\langle b_i b_i\\rangle})\\) for every basis vector and then we multiply it by \\(b\\) like the previous projection formula told us.\n\ndef rand_round(x: float) -&gt; int:\n    decimal = x - np.floor(x)\n    f = np.random.choice([decimal-1, decimal])\n    return int(x + f)\n\n\ndef cwrr(coords: np.ndarray) -&gt; np.ndarray:\n    return np.array([rand_round(x) for x in coords])\n\n\ndef discretization(z: np.ndarray) -&gt; np.ndarray:\n    bases = np.vander(primitive_nth_roots_of_unity(2*N), N, increasing=True).T\n    proj = np.array([np.real(np.vdot(z, b) / np.vdot(b,b)) for b in bases])\n\n    return cwrr(proj) @ bases\n\nAfter that we have have to compute \\(\\sigma^{-1}(\\lfloor\\Delta \\pi^{-1}(m)\\rceil_{\\sigma(\\mathcal{R})})\\) to get our final transformation into the ciphertext space \\(\\mathbb{Z}_q[X]/(X^N +1)\\)\nWe have a list of points so we can use the vandermonde matrix to solve for the coefficients by solving \\(Va = y\\) where V is the vandermonde matrix, a are the polynomial coefficients, and y are the points that we have.\n\nfrom numpy.polynomial import Polynomial\n\n\ndef sigma_inverse(b: np.ndarray) -&gt; Polynomial:\n    A = np.vander(primitive_nth_roots_of_unity(2*N), N, increasing=True)\n    coeffs = np.linalg.solve(A, b)\n    return Polynomial(coeffs)\n\nOnce we put it together we have our complete encoding functionality.\n\nDELTA = 64\nN = 4\n\n\ndef pi_inverse(z: np.ndarray) -&gt; np.ndarray:\n    return np.concatenate([z, [np.conjugate(x) for x in z[::-1]]])\n\n\ndef rand_round(x: float) -&gt; int:\n    decimal = x - np.floor(x)\n    f = np.random.choice([decimal-1, decimal])\n    return int(x + f)\n\n\ndef cwrr(coords: np.ndarray) -&gt; np.ndarray:\n    return np.array([rand_round(x) for x in coords])\n\n\ndef discretization(z: np.ndarray) -&gt; np.ndarray:\n    bases = np.vander(primitive_nth_roots_of_unity(2*N), N, increasing=True).T\n    proj = np.array([np.real(np.vdot(z, b) / np.vdot(b,b)) for b in bases])\n\n    return cwrr(proj) @ bases\n\n\ndef sigma_inverse(b: np.ndarray) -&gt; Polynomial:\n    A = np.vander(primitive_nth_roots_of_unity(2*N), N, increasing=True)\n    coeffs = np.linalg.solve(A, b)\n    return Polynomial(coeffs)\n\n\ndef encode(z: np.ndarray) -&gt; Polynomial:\n    out = pi_inverse(z)\n    out *= DELTA\n    out = discretization(out)\n    out = sigma_inverse(out)\n    \n    out = np.round(np.real(out.coef)).astype(int)\n    return Polynomial(out)\n\n\nz = np.array([3+4j, 2-1j])\nencoded_z = encode(z)\nprint(encoded_z)\n\n160.0 + 91.0·x + 159.0·x² + 44.0·x³\n\n\nIf compare with the paper’s example we can see that we got the same polynomial that they did and our scheme worked.\nTo recap how our encoding scheme encodes \\(m \\in \\mathbb{C}^{N/2} \\rightarrow \\mathbb{Z}_q[X]/(X^N +1)\\):\n\n\\(\\pi^{-1}(m)\\) applies \\(\\mathbb{C}^{N/2} \\rightarrow \\mathbb{H}\\)\nScale our element: \\(\\Delta \\pi^{-1}(m)\\)\nProject and randomly round our element into the space of \\(\\sigma(\\mathcal{R})\\)\nApply \\(\\sigma^{-1}(\\lfloor\\Delta \\pi^{-1}(m)\\rceil_{\\sigma(\\mathcal{R})}) \\in \\mathbb{Z}_q[X]/(X^N +1)\\)"
  },
  {
    "objectID": "posts/ckks/index.html#parameters",
    "href": "posts/ckks/index.html#parameters",
    "title": "Introduction to CKKS",
    "section": "",
    "text": "\\(\\Delta\\) is the scaling factor"
  },
  {
    "objectID": "posts/ckks/index.html#decoding",
    "href": "posts/ckks/index.html#decoding",
    "title": "Introduction to CKKS",
    "section": "",
    "text": "Decoding is very easy to understand as it is pretty much the opposite of encoding.\nOur goal is to convert the polynomial in the ring \\(\\mathbb{Z}_q[X]/(X^N +1)\\) to our plaintext in the space \\(\\mathbb{C}^{N/2}\\).\nFirst we have to multiply our polynomial by \\(\\Delta^{-1}\\).\nThen we use the canonical embedding map \\(\\sigma: \\mathbb{R}[X]/(X^N +1) \\rightarrow \\mathbb{C}^{N/2}\\) which is equivalent to evaluating the polynomial, p, at all of our primitive roots of unity and can be calculated with the vandermonde matrix.\n\ndef sigma(p: Polynomial) -&gt; np.ndarray:\n    V = np.vander(primitive_nth_roots_of_unity(2*N), N, increasing=True)\n    a = p.coef\n    y = V @ a\n    return y\n\nNext we have to perform \\(\\pi\\) to take an element \\(\\in \\mathbb{H}\\) and transform it into and element \\(\\in \\mathbb{C}^{N/2}\\)\n\ndef pi(z: np.ndarray) -&gt; np.ndarray:\n    return z[:N//2]\n\nNow we put it all together to get our decoding function.\n\ndef decode(p: Polynomial) -&gt; np.ndarray:\n    p *= 1/DELTA\n    y = sigma(p)\n    return pi(y)\n\nprint(decode(encoded_z))\n\n[3.01928154+3.97592837j 1.98071846-0.99282163j]"
  }
]