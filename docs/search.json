[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Trevor's Website",
    "section": "",
    "text": "Learning With Errors\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 16, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nGroups, Rings, and Fields\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 15, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to Modular Arithmetic\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nShortest Vector Problem and Closest Vector Problem\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nInteger Factorization Problem\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nDiscrete Logarithm Problem\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nSimple SHA-3\n\n\n\n\n\n\n\ncryptography\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nFederated Learning From Scratch\n\n\n\n\n\n\n\nmachine learning\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2023\n\n\nTrevor Tomlin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I’m Trevor. I am a motivated and passionate student with a strong interest in computer science and technology. I am currently pursuing a degree in Computer Science at the University of Washington Tacoma. I enjoy exploring new technologies and topics in all branches of computer science including machine learning and cryptography. Recently I have been researching privacy preserving machine learning techniques such as federated learning, differential privacy, and homomorphic encryption. I am excited to continue learning and growing in my field, and I am eager to contribute my skills and knowledge to innovative and impactful projects."
  },
  {
    "objectID": "posts/federatedlearning/index.html",
    "href": "posts/federatedlearning/index.html",
    "title": "Federated Learning From Scratch",
    "section": "",
    "text": "Federated learning is a technique for machine learning that uses decentralized clients to train on local data and send information back to a server without revealing the local data. Federated learning helps models be trained with greater privacy and has many natural applications."
  },
  {
    "objectID": "posts/federatedlearning/index.html#how-does-federated-learning-work",
    "href": "posts/federatedlearning/index.html#how-does-federated-learning-work",
    "title": "Federated Learning From Scratch",
    "section": "How does Federated Learning Work?",
    "text": "How does Federated Learning Work?\n\nAn initial model is established on the server and the weights are sent out to all clients\nEach client trains the model on its own local data and sends the weights or gradients back to the server\nAggregate the weights of each client\nUpdate the server’s model with the aggregated weights and send the new weights to each client\nRepeat steps 2-5 for some number of iterations"
  },
  {
    "objectID": "posts/federatedlearning/index.html#how-do-we-aggregate-the-weights",
    "href": "posts/federatedlearning/index.html#how-do-we-aggregate-the-weights",
    "title": "Federated Learning From Scratch",
    "section": "How do we aggregate the weights?",
    "text": "How do we aggregate the weights?\nThe following two algorithms come from the paper Communication-Efficient Learning of Deep Networks from Decentralized Data by H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas from Google in 2016.\n\nFedSGD\nA simple way to update the server’s model is to update the parameters for every gradient that gets sent from a client. This method is called FedSGD and is defined as follows:\n\\[g_k = \\nabla F_k(w_t)\\] \\[ w_{t+1} \\leftarrow w_t - \\eta \\sum_{k=1}^{K}\\frac{n_k}{n}g_k\\]\nFor each client k, we do one single step of gradient descent and then average the weights together.\n\n\nFedAVG\nFedAVG is a modification of FedSGD that trains each client for multiple epochs and then averages the weights together. This method uses less communication than FedSGD and is one of the most commonly used algorithms. It is defined in the aformentioned paper as follows:\n\n\n\nExample with code\nWe first generate a simple dataset that can be used to classify two classes.We then train a centralized model using sklearn and plot the decision boundary. Next, we train a federated model using FedAVG and plot the decision boundary. Finally, we compare the accuracy of the two models.\n\n# Generate Dataset using sklearn\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nX, y = make_classification(\n    n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=1, random_state=7\n)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Plot the data\nplt.scatter(X[:, 0], X[:, 1], marker=\"o\", c=y, s=25, edgecolor=\"k\")\nplt.show()\n\n\n\n\nFigure 1: A synthetic dataset generated using sklearn\n\n\n\n\n\nimport numpy as np\nfrom sklearn.linear_model import SGDClassifier\n\n# Train sklearn SGDClassifier model\nmodel = SGDClassifier(loss=\"log_loss\")\nmodel.fit(X_train, y_train)\n\n# Plot the decision boundary\nx1 = np.linspace(X_test.min()-3, X_test.max()+3, 100)\nx2 = np.linspace(y_test.min()-3, y_test.max()+3, 100)\nxx1, xx2 = np.meshgrid(x1, x2)\nX_grid = np.c_[xx1.ravel(), xx2.ravel()]\nprobs = model.predict_proba(X_grid)[:, 1].reshape(xx1.shape)\n\nplt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors=\"black\")\nplt.scatter(X_test[:, 0], X_test[:, 1], marker=\"o\", c=y_test, s=25, edgecolor=\"k\")\nplt.show()\n\n# Print the accuracy\naccuracy = model.score(X_test, y_test) * 100.0\nprint(f\"Accuracy: {accuracy:.2f}%\")\n\n\n\n\nFigure 2: Decision boundary after training a centralized model\n\n\n\n\nAccuracy: 85.00%\n\n\n\nimport numpy as np\nfrom sklearn.linear_model import SGDClassifier\n\nn_clients = 3\nn_epochs = 3\nn_rounds = 1\n\nclient_models = [SGDClassifier(loss=\"log_loss\") for _ in range(n_clients)]\nserver_model = SGDClassifier(loss=\"log_loss\")\n\n# Split data into clients\nX_clients = np.array_split(X_train, n_clients)\ny_clients = np.array_split(y_train, n_clients)\n\n# Initialize server coefficients to 0\nserver_model.coef_ = np.zeros((1, 2))\nserver_model.intercept_ = np.zeros(1)\nserver_model.classes_ = np.array([0, 1])\n\nfor _ in range(n_rounds):\n\n    # Set client models to be the same as the server model\n    for client_model in client_models:\n        client_model.coef_ = server_model.coef_\n        client_model.intercept_ = server_model.intercept_\n\n    # Train each client model on its own data\n    for client_model, X, y in zip(client_models, X_clients, y_clients):\n\n        # Split data into batches\n        X_batches = np.array_split(X, n_epochs)\n        y_batches = np.array_split(y, n_epochs)\n\n        for _ in range(n_epochs):\n            for X_batch, y_batch in zip(X_batches, y_batches):\n                client_model.partial_fit(X_batch, y_batch, classes=[0, 1])\n\n    # Aggregate the client models using FedAVG using the number of samples as the weights\n    n_samples = [len(X) for X in X_clients]\n    weights = [n / sum(n_samples) for n in n_samples]\n\n    server_model.coef_ = np.average(\n        [client_model.coef_ for client_model in client_models], axis=0, weights=weights\n    )\n    server_model.intercept_ = np.average(\n        [client_model.intercept_ for client_model in client_models], axis=0, weights=weights\n    )\n\n# Plot the decision boundary\nx1 = np.linspace(X_test.min()-3, X_test.max()+3, 100)\nx2 = np.linspace(y_test.min()-3, y_test.max()+3, 100)\nxx1, xx2 = np.meshgrid(x1, x2)\nX_grid = np.c_[xx1.ravel(), xx2.ravel()]\nprobs = model.predict_proba(X_grid)[:, 1].reshape(xx1.shape)\n\nplt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors=\"black\")\nplt.scatter(X_test[:, 0], X_test[:, 1], marker=\"o\", c=y_test, s=25, edgecolor=\"k\")\nplt.show()\n\n# Print the accuracy\naccuracy = server_model.score(X_test, y_test) * 100.0\nprint(f\"Accuracy: {accuracy:.2f}%\")\n\n\n\n\nFigure 3: Decision boundary after training a federated model\n\n\n\n\nAccuracy: 85.00%\n\n\nNow we can see that the federated model has a similar accuracy to the centralized model. If we look at the weights of the server model, we can see that they are similar to the weights of the centralized model.\n\nprint(f\"Centralized Model Weights: w={model.coef_[0]}, b={model.intercept_[0]}\")\nprint(f\"Federated Model Weights: w={server_model.coef_[0]}, b={server_model.intercept_[0]}\")\n\nCentralized Model Weights: w=[-6.13807248 21.28558495], b=5.731260349455407\nFederated Model Weights: w=[-5.8260368  24.13905334], b=6.432089614040729"
  },
  {
    "objectID": "posts/federatedlearning/index.html#a-high-level-look",
    "href": "posts/federatedlearning/index.html#a-high-level-look",
    "title": "Federated Learning From Scratch",
    "section": "A High-Level Look",
    "text": "A High-Level Look"
  },
  {
    "objectID": "posts/federatedlearning/index.html#further-reading",
    "href": "posts/federatedlearning/index.html#further-reading",
    "title": "Federated Learning From Scratch",
    "section": "Further Reading",
    "text": "Further Reading\nOther algorithms for federated learning include:\n1. FedDyn\n2. Sub-FedAvg\n3. FedAvgM\n4. FedAdam\n\nFrameworks for federated learning include:\n1. TensorFlow Federated\n2. Flower"
  },
  {
    "objectID": "posts/federatedlearning/index.html#issues-with-federated-learning",
    "href": "posts/federatedlearning/index.html#issues-with-federated-learning",
    "title": "Federated Learning From Scratch",
    "section": "Issues with Federated Learning",
    "text": "Issues with Federated Learning\nFederated Learning is a promising approach to training machine learning models on decentralized data. There are situations where Federated Learning is naturally the best solution given how the data is split up. However, there are still many issues that need to be considered before using it.  While Federated Learning helps increase privacy, it does not guarantee privacy. There are many attacks that use either malicious models or gradients to extract information about the data. To have privacy Federated Learning must be combined with something such as differential privacy or fully homomorphic encryption.  Another issue is that clients typically have different amounts of data and with different usage patterns that might not be representative of the entire dataset. This is defined as Unbalanced data and Non-IID data in the Federated Learning literature.  Finally, Federated Learning has to deal with the issue of limited communication and a large number of clients. Some clients have limited bandwidth and are offline for long periods of time. This means that the server model has to be able to handle clients that are not always available."
  },
  {
    "objectID": "posts/keccak/index.html",
    "href": "posts/keccak/index.html",
    "title": "Simple SHA-3",
    "section": "",
    "text": "Cryptographic algorithms such as Keccak play a crucial role in securing sensitive information, but they can often seem daunting and complex to understand. The National Institute of Standards and Technology (NIST) standard for Keccak, in particular, has become a widely used cryptographic algorithm due to its high security and efficiency. However, the technical jargon and complex mathematical concepts surrounding Keccak can be intimidating for those unfamiliar with the field of cryptography. In this blog post, I aim to provide a comprehensive yet accessible guide to the NIST standard for Keccak, breaking down the technical terms and explaining them in an easier to understand way."
  },
  {
    "objectID": "posts/keccak/index.html#what-is-the-nist-standard-for-keccak",
    "href": "posts/keccak/index.html#what-is-the-nist-standard-for-keccak",
    "title": "Simple SHA-3",
    "section": "What is the NIST standard for Keccak?",
    "text": "What is the NIST standard for Keccak?\nThe NIST standard for Keccak is a set of specifications for the Keccak cryptographic algorithm developed by Guido Bertoni, Joan Daemen, Michaël Peeters, and Gilles Van Assche. The NIST standard, officially known as FIPS 202, was published in 2015 as a part of a competition that NIST organized. Keccak is a family of hash functions, with different versions that provide varying levels of security and performance. The NIST standard specifies the requirements for the use of Keccak in a variety of applications, including digital signatures, key derivation, and password hashing."
  },
  {
    "objectID": "posts/keccak/index.html#understanding-keccaks-hash-function",
    "href": "posts/keccak/index.html#understanding-keccaks-hash-function",
    "title": "Simple SHA-3",
    "section": "Understanding Keccak’s Hash Function",
    "text": "Understanding Keccak’s Hash Function\nThe state of the hash function is represented as a 5x5 matrix of 64-bit words. The state is initialized to all zeros. The input is then XORed with the state. The state is then passed through the Keccak-p permutation function. This process is repeated until all of the input has been processed. The output is the state of the hash function.\nTo convert from a bit string to the state array we use the following function:\nprivate static long[][] stringToStateArray(String s) {\n    long[][] A = new long[5][5];\n    int i = 0;\n\n    for (int y = 0; y &lt; 5; y++) {\n        for (int x = 0; x &lt; 5; x++) {\n            String blockString = s.substring(i * 64, (i + 1) * 64);\n            A[x][y] = Long.reverse(Long.parseUnsignedLong(blockString, 2));\n            i++;\n            // 9 is the number of longs to store 576 (rate) / 64 (size of long) = 9 longs\n            if (i&gt;=8) {\n                return A;\n            }\n        }\n    }\n\n    return A;\n}\nMore information about this can be found in section 3.1.2 of FIPS 202.\nThe 5-step mappings in the Keccak cryptographic algorithm are the core components that transform input data into a fixed-length hash output.\nSome of the step mappings require this function, which rotates the bits of a 64-bit integer to the left by a specified number of bits:\nprivate static long rotateLeft(long x, int n) {\n    return (x &lt;&lt; n) | (x &gt;&gt;&gt; (64 - n));\n}\n\nTheta: In this step, the input data is transformed by applying a linear function to each row of the state matrix. This step helps to increase the security of the algorithm by increasing the diffusion of the input data.\n\n\n\n\nFigure 3 From FIPS 202\n\n\npublic static long[][] theta(long[][] A) {\n    long[] C = new long[5];\n    for (int x = 0; x &lt; 5; x++) {\n        C[x] = A[x][0] ^ A[x][1] ^ A[x][2] ^ A[x][3] ^ A[x][4];\n    }\n\n    long[] D = new long[5];\n    for (int x = 0; x &lt; 5; x++) {\n        D[x] = (C[(x+4)%5]) ^ rotateLeft(C[(x+1)%5], 1);\n    }\n\n    for (int x = 0; x &lt; 5; x++) {\n        for (int y = 0; y &lt; 5; y++) {\n            A[x][y] ^= D[x];\n        }\n    }\n    return A;\n}\n\nRho: The state matrix is rotated by a certain number of positions in this step. The amount of rotation is determined by a pre-defined pattern, which varies depending on the version of Keccak being used.\n\n\n\n\nFigure 4 From FIPS 202\n\n\n\nPi: In this step, the columns and rows of the state matrix are rearranged according to a pre-defined permutation. This helps to further increase the diffusion of the input data.\n\n\n\n\nFigure 5 From FIPS 202\n\n\n\nChi: The state matrix is transformed by applying a non-linear function to each row. This helps to introduce non-linearity into the algorithm and make it more resistant to attacks.\n\nIn practice, the Pi and Rho steps are combined into a single step mapping. The combined step mapping is defined as:\npublic static long[][] pi_rho(long[][] A) {\n\n    final int[][] offsets = new int[][] {\n        {0, 1, 62, 28, 27},\n        {36, 44, 6, 55, 20},\n        {3, 10, 43, 25, 39},\n        {41, 45, 15, 21, 8},\n        {18, 2, 61, 56, 14}\n    };\n\n    long[][] B = new long[5][5];\n    for (int y = 0; y &lt; 5; y++) {\n        for (int x = 0; x &lt; 5; x++) {\n            int newX = 2 * x + 3 * y;\n            newX %= 5;\n            int newY = y;\n\n            long rotatedValue = rotateLeft(A[x][y], offsets[y][x]);\n\n            B[newY][newX] = rotatedValue;\n        }\n    }\n\n    return B;\n\n}\n\n\n\nFigure 6 From FIPS 202\n\n\npublic static long[][] chi(long[][] A) {\n    long[][] C = new long[5][5];\n    for (int i = 0; i &lt; 5; i++) {\n        for (int j = 0; j &lt; 5; j++) {\n            C[i][j] = A[i][j] ^ ((~A[(i+1)%5][j]) & A[(i+2)%5][j]);\n        }\n    }\n    return C;\n}\n\nIota: The final step involves XORing a pre-defined round constant with a specific location in the state matrix. This helps to add additional randomness to the output and increase the security of the algorithm.\n\npublic static long[][] iota(long[][] A, int round) {\n    long RC = rc[round];\n    A[0][0] ^= RC;\n    return A;\n}\nIn this case the round constants are retrieved from a lookup table, however the round constants can also be calculated using Algorithm 5 from the NIST standard. Below is the lookup table for the round constants:\nprivate static final long[] rc = {\n    0x0000000000000001L,\n    0x0000000000008082L,\n    0x800000000000808AL,\n    0x8000000080008000L,\n    0x000000000000808BL,\n    0x0000000080000001L,\n    0x8000000080008081L,\n    0x8000000000008009L,\n    0x000000000000008AL,\n    0x0000000000000088L,\n    0x0000000080008009L,\n    0x000000008000000AL,\n    0x000000008000808BL,\n    0x800000000000008BL,\n    0x8000000000008089L,\n    0x8000000000008003L,\n    0x8000000000008002L,\n    0x8000000000000080L,\n    0x000000000000800AL,\n    0x800000008000000AL,\n    0x8000000080008081L,\n    0x8000000000008080L,\n    0x0000000080000001L,\n    0x8000000080008008L\n};\nBy repeating these 5-step mappings multiple times, the input data is progressively transformed into a fixed-length hash output. The number of rounds performed depends on the version of Keccak being used and the desired level of security. The output produced by Keccak is considered to be highly secure and is resistant to various attacks such as collision, preimage, and second preimage attacks.\nA single round is defined as:\npublic static long[][] keccakRound(long[][] A, int round) {\n    A = theta(A);\n    A = pi_rho(A);\n    A = chi(A);\n    A = iota(A, round);\n    return A;\n}\nAnd gets repeated for the number of rounds:\npublic static long[][] keccakf(long[][] A, int n) {\n    for (int i = 0; i &lt; n; i++) {\n        A = keccakRound(A, i);\n    }\n    return A;\n}\nTo put this all together, here is psuedo code for the Keccak algorithm:\nfunction keccak-f(A)\n    for i from 0 to 24\n        A = θ(A)\n        A = π(A)\n        A = ρ(A)\n        A = χ(A)\n        A = ι(A, i)\n    return A\n\nfunction SHA-3(M)\n    P = M || 0x06 || 0x00 || … || 0x80 so that len(P) * constant == rate\n    n = len(P)/rate\n    c = list of blocks with a length of rate bits\n\n    Initialize all state values to 0\n\n    for i from 0 to n-1\n        S = S xor c[i]\n        S = keccak_round(S)\n\n    Z = empty string\n    for i from 0 to n-1\n        Z = Z || S[i*b..(i+1)*b-1]\n    return Z"
  },
  {
    "objectID": "posts/keccak/index.html#applications-of-keccak",
    "href": "posts/keccak/index.html#applications-of-keccak",
    "title": "Simple SHA-3",
    "section": "Applications of Keccak",
    "text": "Applications of Keccak\nKeccak has several applications in the field of cryptography due to its high security and efficiency. Some of the common applications of Keccak include:\n\nHash Functions: Keccak is commonly used as a hash function to securely store and transmit sensitive data. Its resistance to various attacks makes it suitable for applications such as password storage, digital signatures, and message authentication.\nEncryption: Keccak can be used for encryption, especially in applications where data needs to be transmitted securely over a network. The algorithm’s high security makes it a reliable choice for encryption.\nKey Derivation: Keccak can be used to derive keys for cryptographic protocols such as TLS (Transport Layer Security) and SSL (Secure Sockets Layer). It is also used to generate keys for secure communication between different systems.\nBlockchain: Keccak is used as a hashing function in many blockchain systems such as Ethereum and CryptoNote. The algorithm provides high security, which is necessary for protecting the integrity of the blockchain.\nRandom Number Generation: Keccak is used in random number generators for secure applications such as gambling, lottery, and cryptography."
  },
  {
    "objectID": "posts/keccak/index.html#conclusion",
    "href": "posts/keccak/index.html#conclusion",
    "title": "Simple SHA-3",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, Keccak is a powerful cryptographic algorithm that has become a popular choice for secure applications such as password storage, digital signatures, and blockchain. Its high security and efficiency make it a reliable choice for various cryptographic operations, including hashing, encryption, key derivation, and random number generation. The 5-step mappings of Keccak, also known as the Keccak-p permutation, provide a robust framework for transforming input data into a fixed-length hash output. While Keccak may seem complex and intimidating to those unfamiliar with cryptography, this blog post has provided a comprehensive yet accessible guide to the NIST standard for Keccak. By breaking down the technical terms and explaining them in an easy-to-understand way, we hope to have demystified Keccak and made it accessible to anyone interested in cryptography."
  },
  {
    "objectID": "posts/keccak/index.html#parameter-specifications",
    "href": "posts/keccak/index.html#parameter-specifications",
    "title": "Simple SHA-3",
    "section": "Parameter Specifications",
    "text": "Parameter Specifications\nKeccak is described in the format Keccak-p[b,n] where b is the rate + capacity and n is the number of rounds. Additionally, the parameter \\(w\\) is defined as \\(\\frac{b}{25}\\) and \\(l\\) is \\(log_2(w)\\). Keccak-f[b] is a subset of Keccak-p[b,n] where \\(n\\) is fixed to \\(12 + 2l\\).\n\nFIPS 202 Table 1: KECCAK-p permutation widths and related quantities\n\n\nb\n25\n50\n100\n200\n400\n800\n1600\n\n\n\n\nw\n1\n2\n4\n8\n16\n32\n64\n\n\nl\n0\n1\n2\n3\n4\n5\n6\n\n\n\n\nFIPS 202 Table 3: Input block sizes for HMAC\n\n\nHash Function\nSHA3-224\nSHA3-256\nSHA3-384\nSHA3-512\n\n\n\n\nBlock Size (bytes)\n144\n136\n104\n72\n\n\n\n\nKeccak Team Table 3: the parameters of the standard FIPS 202 and SP 800-185 instances\n\n\n\n\n\n\n\n\n\nName\nr\nc\nOutput length (bits)\nSecurity level (bits)\n\n\n\n\nSHA3-224\n1152\n448\n224\n112\n\n\nSHA3-256\n1088\n512\n256\n128\n\n\nSHA3-384\n832\n768\n384\n192\n\n\nSHA3-512\n576\n1024\n512\n256\n\n\n\nIn this blog we are using Keccak-f[1600] which is the SHA-3 standard. This means that the rate is 576, the capacity is 1024, and the output length is 512. \\(w\\) is 64 and \\(l\\) is 6."
  },
  {
    "objectID": "posts/keccak/index.html#padding",
    "href": "posts/keccak/index.html#padding",
    "title": "Simple SHA-3",
    "section": "Padding",
    "text": "Padding\nKeccak pads the end of the input with the byte 0x06 followed by as many 0x00 bytes as necessary to make the input a multiple of the rate of the hash function. The last byte of the last block is set to 0x80."
  },
  {
    "objectID": "posts/keccak/index.html#input",
    "href": "posts/keccak/index.html#input",
    "title": "Simple SHA-3",
    "section": "Input",
    "text": "Input\nKeccak recieves a strings of bits stored in little-endian format. Keccak pads the end of the input with the byte 0x06 followed by as many 0x00 bytes as necessary to make the input a multiple of the rate of the hash function. The last byte of the last block is set to 0x80."
  },
  {
    "objectID": "posts/keccak/index.html#understanding-sha-3s-hash-function",
    "href": "posts/keccak/index.html#understanding-sha-3s-hash-function",
    "title": "Simple SHA-3",
    "section": "Understanding SHA-3’s Hash Function",
    "text": "Understanding SHA-3’s Hash Function\nThe state of the hash function is represented as a 5x5 matrix of 64-bit words. The state is initialized to all zeros. The input is then XORed with the state. The state is then passed through the Keccak-p permutation function. This process is repeated until all of the input has been processed. The output is the state of the hash function.\nTo convert from a bit string to the state array we use the following function:\nprivate static long[][] stringToStateArray(String s) {\n    long[][] A = new long[5][5];\n    int i = 0;\n\n    for (int y = 0; y &lt; 5; y++) {\n        for (int x = 0; x &lt; 5; x++) {\n            String blockString = s.substring(i * 64, (i + 1) * 64);\n            A[x][y] = Long.reverse(Long.parseUnsignedLong(blockString, 2));\n            i++;\n            // 9 is the number of longs to store 576 (rate) / 64 (size of long) = 9 longs\n            if (i&gt;=8) {\n                return A;\n            }\n        }\n    }\n\n    return A;\n}\nMore information about this can be found in section 3.1.2 of FIPS 202.\nThe 5-step mappings in the Keccak cryptographic algorithm are the core components that transform input data into a fixed-length hash output.\nSome of the step mappings require this function, which rotates the bits of a 64-bit integer to the left by a specified number of bits:\nprivate static long rotateLeft(long x, int n) {\n    return (x &lt;&lt; n) | (x &gt;&gt;&gt; (64 - n));\n}\n\nTheta: In this step, the input data is transformed by applying a linear function to each row of the state matrix. This step helps to increase the security of the algorithm by increasing the diffusion of the input data.\n\n\n\n\nFigure 3 From FIPS 202\n\n\npublic static long[][] theta(long[][] A) {\n    long[] C = new long[5];\n    for (int x = 0; x &lt; 5; x++) {\n        C[x] = A[x][0] ^ A[x][1] ^ A[x][2] ^ A[x][3] ^ A[x][4];\n    }\n\n    long[] D = new long[5];\n    for (int x = 0; x &lt; 5; x++) {\n        D[x] = (C[(x+4)%5]) ^ rotateLeft(C[(x+1)%5], 1);\n    }\n\n    for (int x = 0; x &lt; 5; x++) {\n        for (int y = 0; y &lt; 5; y++) {\n            A[x][y] ^= D[x];\n        }\n    }\n    return A;\n}\n\nRho: The state matrix is rotated by a certain number of positions in this step. The amount of rotation is determined by a pre-defined pattern, which varies depending on the version of Keccak being used.\n\n\n\n\nFigure 4 From FIPS 202\n\n\n\nPi: In this step, the columns and rows of the state matrix are rearranged according to a pre-defined permutation. This helps to further increase the diffusion of the input data.\n\n\n\n\nFigure 5 From FIPS 202\n\n\n\nChi: The state matrix is transformed by applying a non-linear function to each row. This helps to introduce non-linearity into the algorithm and make it more resistant to attacks.\n\nIn practice, the Pi and Rho steps are combined into a single step mapping. The combined step mapping is defined as:\npublic static long[][] pi_rho(long[][] A) {\n\n    final int[][] offsets = new int[][] {\n        {0, 1, 62, 28, 27},\n        {36, 44, 6, 55, 20},\n        {3, 10, 43, 25, 39},\n        {41, 45, 15, 21, 8},\n        {18, 2, 61, 56, 14}\n    };\n\n    long[][] B = new long[5][5];\n    for (int y = 0; y &lt; 5; y++) {\n        for (int x = 0; x &lt; 5; x++) {\n            int newX = 2 * x + 3 * y;\n            newX %= 5;\n            int newY = y;\n\n            long rotatedValue = rotateLeft(A[x][y], offsets[y][x]);\n\n            B[newY][newX] = rotatedValue;\n        }\n    }\n\n    return B;\n\n}\n\n\n\nFigure 6 From FIPS 202\n\n\npublic static long[][] chi(long[][] A) {\n    long[][] C = new long[5][5];\n    for (int i = 0; i &lt; 5; i++) {\n        for (int j = 0; j &lt; 5; j++) {\n            C[i][j] = A[i][j] ^ ((~A[(i+1)%5][j]) & A[(i+2)%5][j]);\n        }\n    }\n    return C;\n}\n\nIota: The final step involves XORing a pre-defined round constant with a specific location in the state matrix. This helps to add additional randomness to the output and increase the security of the algorithm.\n\npublic static long[][] iota(long[][] A, int round) {\n    long RC = rc[round];\n    A[0][0] ^= RC;\n    return A;\n}\nIn this case the round constants are retrieved from a lookup table, however the round constants can also be calculated using Algorithm 5 from the NIST standard. Below is the lookup table for the round constants:\nprivate static final long[] rc = {\n    0x0000000000000001L,\n    0x0000000000008082L,\n    0x800000000000808AL,\n    0x8000000080008000L,\n    0x000000000000808BL,\n    0x0000000080000001L,\n    0x8000000080008081L,\n    0x8000000000008009L,\n    0x000000000000008AL,\n    0x0000000000000088L,\n    0x0000000080008009L,\n    0x000000008000000AL,\n    0x000000008000808BL,\n    0x800000000000008BL,\n    0x8000000000008089L,\n    0x8000000000008003L,\n    0x8000000000008002L,\n    0x8000000000000080L,\n    0x000000000000800AL,\n    0x800000008000000AL,\n    0x8000000080008081L,\n    0x8000000000008080L,\n    0x0000000080000001L,\n    0x8000000080008008L\n};\nBy repeating these 5-step mappings multiple times, the input data is progressively transformed into a fixed-length hash output. The number of rounds performed depends on the version of Keccak being used and the desired level of security. The output produced by Keccak is considered to be highly secure and is resistant to various attacks such as collision, preimage, and second preimage attacks.\nA single round is defined as:\npublic static long[][] keccakRound(long[][] A, int round) {\n    A = theta(A);\n    A = pi_rho(A);\n    A = chi(A);\n    A = iota(A, round);\n    return A;\n}\nAnd gets repeated for the number of rounds:\npublic static long[][] keccakf(long[][] A, int n) {\n    for (int i = 0; i &lt; n; i++) {\n        A = keccakRound(A, i);\n    }\n    return A;\n}\nTo put this all together, here is psuedo code for the Keccak algorithm:\nfunction keccak-f(A)\n    for i from 0 to 24\n        A = θ(A)\n        A = π(A)\n        A = ρ(A)\n        A = χ(A)\n        A = ι(A, i)\n    return A\n\nfunction SHA-3(M)\n    P = M || 0x06 || 0x00 || … || 0x80 so that len(P) * constant == rate\n    n = len(P)/rate\n    c = list of blocks with a length of rate bits\n\n    Initialize all state values to 0\n\n    for i from 0 to n-1\n        S = S xor c[i]\n        S = keccak_round(S)\n\n    Z = empty string\n    for i from 0 to n-1\n        Z = Z || S[i*b..(i+1)*b-1]\n    return Z"
  },
  {
    "objectID": "posts/keccak/index.html#references",
    "href": "posts/keccak/index.html#references",
    "title": "Simple SHA-3",
    "section": "References",
    "text": "References\n\nKeccak Team - Keccak Specifications Summary\nFIPS 202"
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html",
    "href": "posts/discretelogarithmproblem/index.html",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "The discrete logarithm problem is a fundamental concept in the field of cryptography. It plays a crucial role in many encryption algorithms and serves as the basis for various security protocols. In this blog post, we will explore what the discrete logarithm problem is and why it is significant.\n\n\nBefore delving into the discrete logarithm problem, let’s quickly recap logarithms. A logarithm is an operation that calculates the exponent to which a particular base must be raised to obtain a given number. In simpler terms, it answers the question: “What power do I need to raise this base to get this number?”\nFor example, in the equation \\(2^x = 8\\), the logarithm base 2 of 8 is 3, denoted as \\(log_2(8) = 3\\). It tells us that 2 raised to the power of 3 equals 8.\n\n\n\nNow, let’s move on to the discrete logarithm problem. In cryptography, we often deal with mathematical structures known as finite fields. These fields have a finite number of elements and exhibit certain properties that make them suitable for cryptographic operations.\nThe discrete logarithm problem is defined within a finite field. Given a base element g and a target element h, the problem involves finding an exponent x such that \\(g^x = h.\\) Mathematically, it can be represented as \\(x = log_g(h).\\)\nThe challenge lies in finding the value of x efficiently, especially when the field is very large and calculations become computationally expensive. In other words, the problem is to determine the unknown exponent x based on the known values of g and h.\n\nimport matplotlib.pyplot as plt\n\n# Define the finite field parameters\nprime_modulus = 17  # Modulus value for the finite field\n\n# Generate the base and target elements\n# All integers from 1 to (prime_modulus - 1)\nbase_elements = range(1, prime_modulus)  \n\n# Calculate the target elements using exponentiation\ntarget_elements = [pow(2, x, prime_modulus) for x in base_elements]  \n\nplt.scatter(base_elements, target_elements, color='red', marker='o')\n\nplt.xlabel('Base Elements')\nplt.ylabel('Target Elements')\nplt.title('Discrete Logarithm Problem')\n\nplt.show()\n\n\n\n\nNow, if we consider the plotted graph, with the x-axis representing the base elements and the y-axis representing the target elements, finding the discrete logarithm involves determining the x-coordinate (base element) corresponding to a given y-coordinate (target element).\nThe challenge arises because, in a finite field, as the field size (p) grows larger, the number of possible base and target elements increases exponentially.\n\n\n\nThe discrete logarithm problem forms the foundation of various cryptographic algorithms, particularly those based on public-key cryptography. These algorithms rely on the difficulty of solving the discrete logarithm problem to ensure the security of encrypted data.\nOne such algorithm is Diffie-Hellman key exchange, which allows two parties to establish a shared secret key over an insecure channel.\nOther algorithms, such as DSA (Digital Signature Algorithm) and ElGamal encryption, also depend on the discrete logarithm problem for their security.\n\n\n\nThe emergence of quantum computing has significant implications for cryptographic algorithms, including those based on the discrete logarithm problem. Classical computers employ the index calculus algorithm to solve this problem, but it becomes time-consuming as the field size increases. Quantum computers, however, leverage algorithms like Shor’s algorithm, which can efficiently solve the discrete logarithm problem in polynomial time. This poses a challenge to the security of classical cryptographic schemes when faced with a powerful quantum computer.\nWhile there are no quantum computers large enough to break the discrete logarithm problem at the time of writing, it is important to consider the implications of quantum computing on the security of cryptographic algorithms. This is especially true for those that rely on the discrete logarithm problem, such as Diffie-Hellman key exchange and DSA.\n\n\n\nIn summary, the discrete logarithm problem is a mathematical challenge of finding an unknown exponent within a finite field. Its significance in cryptography cannot be overstated, as it underpins the security of various encryption algorithms and protocols. However, the emergence of quantum computing poses a threat to the security of these algorithms, as quantum computers can efficiently solve the discrete logarithm problem. We should look to develop quantum-resistant cryptographic schemes to ensure the security of our data in the future such as lattice-based cryptography."
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html#understanding-logarithms",
    "href": "posts/discretelogarithmproblem/index.html#understanding-logarithms",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "Before delving into the discrete logarithm problem, let’s quickly recap logarithms. A logarithm is an operation that calculates the exponent to which a particular base must be raised to obtain a given number. In simpler terms, it answers the question: “What power do I need to raise this base to get this number?”\nFor example, in the equation \\(2^x = 8\\), the logarithm base 2 of 8 is 3, denoted as \\(log_2(8) = 3\\). It tells us that 2 raised to the power of 3 equals 8."
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html#the-discrete-logarithm-problem",
    "href": "posts/discretelogarithmproblem/index.html#the-discrete-logarithm-problem",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "Now, let’s move on to the discrete logarithm problem. In cryptography, we often deal with mathematical structures known as finite fields. These fields have a finite number of elements and exhibit certain properties that make them suitable for cryptographic operations.\nThe discrete logarithm problem is defined within a finite field. Given a base element g and a target element h, the problem involves finding an exponent x such that \\(g^x = h.\\) Mathematically, it can be represented as \\(x = log_g(h).\\)\nThe challenge lies in finding the value of x efficiently, especially when the field is very large and calculations become computationally expensive. In other words, the problem is to determine the unknown exponent x based on the known values of g and h.\n\nimport matplotlib.pyplot as plt\n\n# Define the finite field parameters\nprime_modulus = 17  # Modulus value for the finite field\n\n# Generate the base and target elements\n# All integers from 1 to (prime_modulus - 1)\nbase_elements = range(1, prime_modulus)  \n\n# Calculate the target elements using exponentiation\ntarget_elements = [pow(2, x, prime_modulus) for x in base_elements]  \n\nplt.scatter(base_elements, target_elements, color='red', marker='o')\n\nplt.xlabel('Base Elements')\nplt.ylabel('Target Elements')\nplt.title('Discrete Logarithm Problem')\n\nplt.show()\n\n\n\n\nNow, if we consider the plotted graph, with the x-axis representing the base elements and the y-axis representing the target elements, finding the discrete logarithm involves determining the x-coordinate (base element) corresponding to a given y-coordinate (target element).\nThe challenge arises because, in a finite field, as the field size (p) grows larger, the number of possible base and target elements increases exponentially."
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html#significance-in-cryptography",
    "href": "posts/discretelogarithmproblem/index.html#significance-in-cryptography",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "The discrete logarithm problem forms the foundation of various cryptographic algorithms, particularly those based on public-key cryptography. These algorithms rely on the difficulty of solving the discrete logarithm problem to ensure the security of encrypted data.\nOne such algorithm is Diffie-Hellman key exchange, which allows two parties to establish a shared secret key over an insecure channel.\nOther algorithms, such as DSA (Digital Signature Algorithm) and ElGamal encryption, also depend on the discrete logarithm problem for their security."
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html#conclusion",
    "href": "posts/discretelogarithmproblem/index.html#conclusion",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "In summary, the discrete logarithm problem is a mathematical challenge of finding an unknown exponent within a finite field. Its significance in cryptography cannot be overstated, as it underpins the security of various encryption algorithms and protocols. However, the emergence of quantum computing poses a threat to the security of these algorithms, as quantum computers can efficiently solve the discrete logarithm problem. We should look to develop quantum-resistant cryptographic schemes to ensure the security of our data in the future such as lattice-based cryptography."
  },
  {
    "objectID": "posts/discretelogarithmproblem/index.html#quantum-security",
    "href": "posts/discretelogarithmproblem/index.html#quantum-security",
    "title": "Discrete Logarithm Problem",
    "section": "",
    "text": "The emergence of quantum computing has significant implications for cryptographic algorithms, including those based on the discrete logarithm problem. Classical computers employ the index calculus algorithm to solve this problem, but it becomes time-consuming as the field size increases. Quantum computers, however, leverage algorithms like Shor’s algorithm, which can efficiently solve the discrete logarithm problem in polynomial time. This poses a challenge to the security of classical cryptographic schemes when faced with a powerful quantum computer.\nWhile there are no quantum computers large enough to break the discrete logarithm problem at the time of writing, it is important to consider the implications of quantum computing on the security of cryptographic algorithms. This is especially true for those that rely on the discrete logarithm problem, such as Diffie-Hellman key exchange and DSA."
  },
  {
    "objectID": "posts/integerfactorization/index.html",
    "href": "posts/integerfactorization/index.html",
    "title": "Integer Factorization Problem",
    "section": "",
    "text": "The integer factorization problem is a fundamental challenge in cryptography, with significant implications for the widely used RSA encryption scheme. Understanding this problem and its computational complexity provides insights into the security of RSA and the potential impact of quantum computing advancements.\nIn essence, the integer factorization problem involves breaking down a composite integer into its prime factors. While this task may seem simple for small numbers, it becomes exponentially more difficult as the size of the number increases. This property forms the basis of RSA encryption, where the security relies on the difficulty of factoring the product of two large prime numbers.\nClassical computers employ various algorithms, such as the General Number Field Sieve (GNFS) or the Quadratic Sieve (QS), to factorize composite integers. The time complexity of these algorithms grows significantly with the size of the number, making it increasingly time-consuming to factorize larger integers.\nLet’s see an example of how we can factorize the product of two small prime numbers using a Python code snippet:\n\ndef factorize_product(p, q):\n    n = p * q\n    factors = []\n    i = 2\n\n    while i * i &lt;= n:\n        if n % i:\n            i += 1\n        else:\n            n //= i\n            factors.append(i)\n\n    if n &gt; 1:\n        factors.append(n)\n\n    return factors\n\np = 7\nq = 11\nproduct = p * q\nprime_factors = factorize_product(p, q)\nprint(f\"The prime factors of {product} are: {prime_factors}\")\n\nThe prime factors of 77 are: [7, 11]\n\n\nIn the example, we factorize the product of two primes 7 and 11, which is 77. The code will output the prime factors: [7, 11], indicating that 77 can be factored into the primes 7 and 11.\nIn the code snippet above, we demonstrated the factorization of a product of two small prime numbers. However, it’s important to note that the security of RSA encryption relies on the difficulty of factoring much larger composite numbers. Typical RSA primes used in modern cryptographic systems can have lengths of 2048 bits to make a security level of 4096 bits. Factoring such large numbers using classical computers is an incredibly demanding computational task that is not reasonable to compute.\nTo put this into perspective, consider that breaking a 4096-bit RSA key by factoring the modulus is estimated to require trillions of years on current classical computing technology. This emphasizes the level of security provided by RSA encryption when implemented with sufficiently large prime numbers.\nIt’s worth noting that while this code snippet demonstrates factoring a product of small prime numbers, for larger composite numbers, more efficient factoring algorithms are required. Nonetheless, the underlying principle remains the same: factoring the product of two large prime numbers is extremely challenging, forming the basis of the security behind RSA encryption.\nThe existence of a powerful quantum computer with the capability to execute Shor’s algorithm poses a significant threat to the security of RSA and other cryptographic systems that rely on the hardness of integer factorization. With a quantum computer, the time required to factorize large composite numbers would be reduced from exponential to polynomial, rendering RSA vulnerable to attacks.\nTo address these concerns, researchers are actively exploring post-quantum cryptography. The goal is to develop new encryption schemes that can resist attacks from both classical and quantum computers. These schemes rely on alternative mathematical problems that have no known efficient algorithms for quantum computers, providing a potential avenue for future secure communication."
  },
  {
    "objectID": "posts/integerfactorization/index.html#the-integer-factorization-problem-and-its-impact-on-rsa",
    "href": "posts/integerfactorization/index.html#the-integer-factorization-problem-and-its-impact-on-rsa",
    "title": "Integer Factorization Problem",
    "section": "",
    "text": "The integer factorization problem is a fundamental challenge in cryptography, with significant implications for the widely used RSA encryption scheme. Understanding this problem and its computational complexity provides insights into the security of RSA and the potential impact of quantum computing advancements.\nIn essence, the integer factorization problem involves breaking down a composite integer into its prime factors. While this task may seem simple for small numbers, it becomes exponentially more difficult as the size of the number increases. This property forms the basis of RSA encryption, where the security relies on the difficulty of factoring the product of two large prime numbers.\nClassical computers employ various algorithms, such as the General Number Field Sieve (GNFS) or the Quadratic Sieve (QS), to factorize composite integers. The time complexity of these algorithms grows significantly with the size of the number, making it increasingly time-consuming to factorize larger integers.\nLet’s see an example of how we can factorize the product of two small prime numbers using a Python code snippet:\n\ndef factorize_product(p, q):\n    n = p * q\n    factors = []\n    i = 2\n\n    while i * i &lt;= n:\n        if n % i:\n            i += 1\n        else:\n            n //= i\n            factors.append(i)\n\n    if n &gt; 1:\n        factors.append(n)\n\n    return factors\n\np = 7\nq = 11\nproduct = p * q\nprime_factors = factorize_product(p, q)\nprint(f\"The prime factors of {product} are: {prime_factors}\")\n\nThe prime factors of 77 are: [7, 11]\n\n\nIn the example, we factorize the product of two primes 7 and 11, which is 77. The code will output the prime factors: [7, 11], indicating that 77 can be factored into the primes 7 and 11.\nIn the code snippet above, we demonstrated the factorization of a product of two small prime numbers. However, it’s important to note that the security of RSA encryption relies on the difficulty of factoring much larger composite numbers. Typical RSA primes used in modern cryptographic systems can have lengths of 2048 bits to make a security level of 4096 bits. Factoring such large numbers using classical computers is an incredibly demanding computational task that is not reasonable to compute.\nTo put this into perspective, consider that breaking a 4096-bit RSA key by factoring the modulus is estimated to require trillions of years on current classical computing technology. This emphasizes the level of security provided by RSA encryption when implemented with sufficiently large prime numbers.\nIt’s worth noting that while this code snippet demonstrates factoring a product of small prime numbers, for larger composite numbers, more efficient factoring algorithms are required. Nonetheless, the underlying principle remains the same: factoring the product of two large prime numbers is extremely challenging, forming the basis of the security behind RSA encryption.\nThe existence of a powerful quantum computer with the capability to execute Shor’s algorithm poses a significant threat to the security of RSA and other cryptographic systems that rely on the hardness of integer factorization. With a quantum computer, the time required to factorize large composite numbers would be reduced from exponential to polynomial, rendering RSA vulnerable to attacks.\nTo address these concerns, researchers are actively exploring post-quantum cryptography. The goal is to develop new encryption schemes that can resist attacks from both classical and quantum computers. These schemes rely on alternative mathematical problems that have no known efficient algorithms for quantum computers, providing a potential avenue for future secure communication."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html",
    "href": "posts/shortestvectorproblem/index.html",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "Lattice-based cryptography has emerged as a powerful tool in modern cryptography, offering security guarantees and resilience against attacks from both classical and quantum computers. At the heart of lattice-based cryptography lies the Shortest Vector Problem (SVP) and a related problem the Closest Vector Problem, a fundamental computational problem with wide-ranging implications. In this blog post, we will delve into them both, their impact on cryptographic systems, and their practical applications.\n\n\n\nGiven a set of basis vectors which make up a lattice, the goal of the Shortest Vector Problem is to find the shortest non-zero vector in the lattice. The shortest vector is the vector with the smallest Euclidean norm. The Shortest Vector Problem is a hard problem to solve, and it is believed that there is no efficient algorithm to solve it. The Shortest Vector Problem is a NP-hard problem, meaning that it is at least as hard as any other problem in the class of NP problems.\n\n\n\nThe Closest Vector Problem is a related problem to the Shortest Vector Problem. Given a lattice and a target vector, the goal of the Closest Vector Problem is to find the closest vector in the lattice to the target vector. The Closest Vector Problem is also a hard problem to solve, and it is believed that there is no efficient algorithm to solve it. The Closest Vector Problem is also a NP-hard problem.\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Good Basis\nbasis_1_pair1 = np.array([2, 0])\nbasis_2_pair1 = np.array([0, 2])\n\n# Bad Basis\nbasis_1_pair2 = np.array([2, -6])\nbasis_2_pair2 = np.array([2, -8])\n\ngrid_size = 10\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_pair1 = np.array([(x, y) for x in x_values for y in y_values])\n\nlattice_transformed_pair1 = lattice_pair1[:, 0][:, None] * basis_1_pair1 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair1\n\nlattice_transformed_pair2 = lattice_pair1[:, 0][:, None] * basis_1_pair2 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair2\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_transformed_pair1[:, 0], lattice_transformed_pair1[:, 1], color='blue', label='Lattice')\nax.arrow(0, 0, basis_1_pair1[0], basis_1_pair1[1], color='red', width=0.1, label='Good Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair1[0], basis_2_pair1[1], color='red', width=0.1, length_includes_head=True)\n\nax.arrow(0, 0, basis_1_pair2[0], basis_1_pair2[1], color='green', width=0.1, label='Bad Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair2[0], basis_2_pair2[1], color='green', width=0.1, length_includes_head=True)\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn example of two different basis pairs. The red basis pair is a good basis pair, while the green basis pair is a bad basis pair.\n\n\n\n\nTo illustrate the concept of good and bad basis vectors, let’s consider an example. We can visualize a lattice and its basis vectors using two pairs. The first pair consists of basis vectors that are nearly perpendicular, while the second pair comprises basis vectors that are nearly parallel. By examining the resulting lattices, we can observe the impact of the choice of basis vectors on the lattice structure and its security properties.\nBob gives Alice the bad basis. Alice picks a point on the lattice (2, 2) that represents her message. She then adds a small error to the point and sends that point to Bob. Bob then uses the good basis to decode the message.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Basis vectors\nbasis_1 = np.array([2, 0])\nbasis_2 = np.array([0, 2])\n\ngrid_size = 3\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_points = np.array([(x, y) for x in x_values for y in y_values])\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_points[:, 0], lattice_points[:, 1], color='blue', label='Lattice')\n\npoint_1 = np.array([2, 2])  # Point on lattice representing message\npoint_2 = np.array([2.3, 2])  # Message with error added\n\nax.arrow(0, 0, point_1[0], point_1[1], color='green', width=0.1, length_includes_head=True)\n\nax.scatter(point_2[0], point_2[1], color='orange')\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn example of the encoded message and error added to point\n\n\n\n\nThis is very similar to how the Goldreich–Goldwasser–Halevi (GGH) lattice-based cryptosystem works.\n\n\n\nIn practice, lattice-based cryptosystems operate in high-dimensional spaces, which greatly enhances their security. The dimensionality of the lattice significantly increases the computational complexity of finding the shortest vector without access to the private key. As the dimensions increase, the search space for potential shortest vectors expands exponentially, making exhaustive search and other classical techniques infeasible. Quantum computers, despite their potential advantages, still face formidable challenges in solving the shortest vector problem for high-dimensional lattices. Their limited performance and the exponential growth of the problem’s complexity ensure that lattice-based cryptosystems remain secure against both classical and quantum attacks. Therefore, the use of high-dimensional lattices strengthens the security of lattice-based cryptosystems and solidifies their position as robust post-quantum cryptographic solutions.\n\n\n\nKyber, based on the pq-crystals framework, is a lattice-based post-quantum cryptosystem that offers secure communication through its Key Encapsulation Mechanism (KEM) and digital signature schemes. It provides robust security against attacks from classical and quantum adversaries by leveraging the hardness of lattice problems. Kyber strikes a balance between security and efficiency, allowing users to choose parameters based on their specific requirements. With its promising security properties and competitive performance, Kyber has emerged as a strong contender in the field of post-quantum cryptography.\nLattice-based cryptography finds applications in various domains. One notable application is Fully Homomorphic Encryption (FHE), which enables computations on encrypted data without the need for decryption. FHE has applications in privacy-preserving computations, secure outsourcing of computations, and secure machine learning.\n\n\n\nIn summary, the use of high-dimensional lattices in lattice-based cryptosystems provides a robust defense against attacks. The exponential growth of the search space, coupled with the limitations of classical and quantum computers, ensures that finding the shortest vector without the private key remains a nearly impossible task. This characteristic reinforces the post-quantum security offered by lattice-based cryptography and solidifies its position as a promising and resilient approach in the realm of modern cryptographic systems."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#introduction",
    "href": "posts/shortestvectorproblem/index.html#introduction",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "Lattice-based cryptography has emerged as a powerful tool in modern cryptography, offering security guarantees and resilience against attacks from both classical and quantum computers. At the heart of lattice-based cryptography lies the Shortest Vector Problem (SVP) and a related problem the Closest Vector Problem, a fundamental computational problem with wide-ranging implications. In this blog post, we will delve into them both, their impact on cryptographic systems, and their practical applications."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#example",
    "href": "posts/shortestvectorproblem/index.html#example",
    "title": "Shortest Vector Problem",
    "section": "",
    "text": "Code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Good Basis\nbasis_1_pair1 = np.array([2, 0])\nbasis_2_pair1 = np.array([0, 2])\n\n# Bad Basis\nbasis_1_pair2 = np.array([2, -6])\nbasis_2_pair2 = np.array([2, -8])\n\ngrid_size = 10\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_pair1 = np.array([(x, y) for x in x_values for y in y_values])\n\nlattice_transformed_pair1 = lattice_pair1[:, 0][:, None] * basis_1_pair1 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair1\n\nlattice_transformed_pair2 = lattice_pair1[:, 0][:, None] * basis_1_pair2 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair2\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_transformed_pair1[:, 0], lattice_transformed_pair1[:, 1], color='blue', label='Lattice')\nax.arrow(0, 0, basis_1_pair1[0], basis_1_pair1[1], color='red', width=0.1, label='Good Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair1[0], basis_2_pair1[1], color='red', width=0.1, length_includes_head=True)\n\nax.arrow(0, 0, basis_1_pair2[0], basis_1_pair2[1], color='green', width=0.1, label='Bad Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair2[0], basis_2_pair2[1], color='green', width=0.1, length_includes_head=True)\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn example of two different basis pairs. The red basis pair is a good basis pair, while the green basis pair is a bad basis pair.\n\n\n\n\nTo illustrate the concept of good and bad basis vectors, let’s consider an example. We can visualize a lattice and its basis vectors using two pairs. The first pair consists of basis vectors that are nearly perpendicular, while the second pair comprises basis vectors that are nearly parallel. By examining the resulting lattices, we can observe the impact of the choice of basis vectors on the lattice structure and its security properties.\nBob gives Alice the bad basis. Alice picks a point on the lattice (2, 2) that represents her message. She then adds a small error to the point and sends that point to Bob. Bob then uses the good basis to decode the message.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Basis vectors\nbasis_1 = np.array([2, 0])\nbasis_2 = np.array([0, 2])\n\ngrid_size = 5\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_points = np.array([(x, y) for x in x_values for y in y_values])\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_points[:, 0], lattice_points[:, 1], color='blue')\n\nax.arrow(0, 0, basis_1[0], basis_1[1], color='red', width=0.1, length_includes_head=True)\nax.arrow(0, 0, basis_2[0], basis_2[1], color='red', width=0.1, length_includes_head=True)\n\npoint_1 = np.array([2, 2])  # Point on lattice representing message\npoint_2 = np.array([2.3, 2])  # Message with error added\n\nax.arrow(0, 0, point_1[0], point_1[1], color='green', width=0.1, length_includes_head=True)\n\nax.scatter(point_2[0], point_2[1], color='orange')\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n\n\n\n\n\nAn example of the encoded message and error added to point\n\n\n\n\nThis is very similar to how the Goldreich–Goldwasser–Halevi (GGH) lattice-based cryptosystem works."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#dimensionality-in-practice",
    "href": "posts/shortestvectorproblem/index.html#dimensionality-in-practice",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "In practice, lattice-based cryptosystems operate in high-dimensional spaces, which greatly enhances their security. The dimensionality of the lattice significantly increases the computational complexity of finding the shortest vector without access to the private key. As the dimensions increase, the search space for potential shortest vectors expands exponentially, making exhaustive search and other classical techniques infeasible. Quantum computers, despite their potential advantages, still face formidable challenges in solving the shortest vector problem for high-dimensional lattices. Their limited performance and the exponential growth of the problem’s complexity ensure that lattice-based cryptosystems remain secure against both classical and quantum attacks. Therefore, the use of high-dimensional lattices strengthens the security of lattice-based cryptosystems and solidifies their position as robust post-quantum cryptographic solutions."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#applications",
    "href": "posts/shortestvectorproblem/index.html#applications",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "Kyber, based on the pq-crystals framework, is a lattice-based post-quantum cryptosystem that offers secure communication through its Key Encapsulation Mechanism (KEM) and digital signature schemes. It provides robust security against attacks from classical and quantum adversaries by leveraging the hardness of lattice problems. Kyber strikes a balance between security and efficiency, allowing users to choose parameters based on their specific requirements. With its promising security properties and competitive performance, Kyber has emerged as a strong contender in the field of post-quantum cryptography.\nLattice-based cryptography finds applications in various domains. One notable application is Fully Homomorphic Encryption (FHE), which enables computations on encrypted data without the need for decryption. FHE has applications in privacy-preserving computations, secure outsourcing of computations, and secure machine learning."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#conclusion",
    "href": "posts/shortestvectorproblem/index.html#conclusion",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "In summary, the use of high-dimensional lattices in lattice-based cryptosystems provides a robust defense against attacks. The exponential growth of the search space, coupled with the limitations of classical and quantum computers, ensures that finding the shortest vector without the private key remains a nearly impossible task. This characteristic reinforces the post-quantum security offered by lattice-based cryptography and solidifies its position as a promising and resilient approach in the realm of modern cryptographic systems."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#shortest-vector-problem",
    "href": "posts/shortestvectorproblem/index.html#shortest-vector-problem",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "Given a set of basis vectors which make up a lattice, the goal of the Shortest Vector Problem is to find the shortest non-zero vector in the lattice. The shortest vector is the vector with the smallest Euclidean norm. The Shortest Vector Problem is a hard problem to solve, and it is believed that there is no efficient algorithm to solve it. The Shortest Vector Problem is a NP-hard problem, meaning that it is at least as hard as any other problem in the class of NP problems."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#closest-vector-problem",
    "href": "posts/shortestvectorproblem/index.html#closest-vector-problem",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "The Closest Vector Problem is a related problem to the Shortest Vector Problem. Given a lattice and a target vector, the goal of the Closest Vector Problem is to find the closest vector in the lattice to the target vector. The Closest Vector Problem is also a hard problem to solve, and it is believed that there is no efficient algorithm to solve it. The Closest Vector Problem is also a NP-hard problem."
  },
  {
    "objectID": "posts/shortestvectorproblem/index.html#example-of-closest-vector-problem",
    "href": "posts/shortestvectorproblem/index.html#example-of-closest-vector-problem",
    "title": "Shortest Vector Problem and Closest Vector Problem",
    "section": "",
    "text": "Code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Good Basis\nbasis_1_pair1 = np.array([2, 0])\nbasis_2_pair1 = np.array([0, 2])\n\n# Bad Basis\nbasis_1_pair2 = np.array([2, -6])\nbasis_2_pair2 = np.array([2, -8])\n\ngrid_size = 10\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_pair1 = np.array([(x, y) for x in x_values for y in y_values])\n\nlattice_transformed_pair1 = lattice_pair1[:, 0][:, None] * basis_1_pair1 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair1\n\nlattice_transformed_pair2 = lattice_pair1[:, 0][:, None] * basis_1_pair2 + \\\n                            lattice_pair1[:, 1][:, None] * basis_2_pair2\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_transformed_pair1[:, 0], lattice_transformed_pair1[:, 1], color='blue', label='Lattice')\nax.arrow(0, 0, basis_1_pair1[0], basis_1_pair1[1], color='red', width=0.1, label='Good Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair1[0], basis_2_pair1[1], color='red', width=0.1, length_includes_head=True)\n\nax.arrow(0, 0, basis_1_pair2[0], basis_1_pair2[1], color='green', width=0.1, label='Bad Basis', length_includes_head=True)\nax.arrow(0, 0, basis_2_pair2[0], basis_2_pair2[1], color='green', width=0.1, length_includes_head=True)\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn example of two different basis pairs. The red basis pair is a good basis pair, while the green basis pair is a bad basis pair.\n\n\n\n\nTo illustrate the concept of good and bad basis vectors, let’s consider an example. We can visualize a lattice and its basis vectors using two pairs. The first pair consists of basis vectors that are nearly perpendicular, while the second pair comprises basis vectors that are nearly parallel. By examining the resulting lattices, we can observe the impact of the choice of basis vectors on the lattice structure and its security properties.\nBob gives Alice the bad basis. Alice picks a point on the lattice (2, 2) that represents her message. She then adds a small error to the point and sends that point to Bob. Bob then uses the good basis to decode the message.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Basis vectors\nbasis_1 = np.array([2, 0])\nbasis_2 = np.array([0, 2])\n\ngrid_size = 3\nx_values = np.arange(-grid_size, grid_size + 1)\ny_values = np.arange(-grid_size, grid_size + 1)\nlattice_points = np.array([(x, y) for x in x_values for y in y_values])\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(lattice_points[:, 0], lattice_points[:, 1], color='blue', label='Lattice')\n\npoint_1 = np.array([2, 2])  # Point on lattice representing message\npoint_2 = np.array([2.3, 2])  # Message with error added\n\nax.arrow(0, 0, point_1[0], point_1[1], color='green', width=0.1, length_includes_head=True)\n\nax.scatter(point_2[0], point_2[1], color='orange')\n\nax.set_xlim([-grid_size - 1, grid_size + 1])\nax.set_ylim([-grid_size - 1, grid_size + 1])\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Lattice with Basis Vectors')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn example of the encoded message and error added to point\n\n\n\n\nThis is very similar to how the Goldreich–Goldwasser–Halevi (GGH) lattice-based cryptosystem works."
  },
  {
    "objectID": "posts/modulararithmetic/index.html",
    "href": "posts/modulararithmetic/index.html",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Modular arithmetic is a fascinating branch of mathematics that deals with integers and their remainders. It has various applications in fields like cryptography, computer science, and number theory. In this blog post, we’ll dive into the basics of modular arithmetic and explore different operations using interactive Manim animations.\n\n\nModular arithmetic involves performing operations on numbers within a fixed range, called a modulus. The modulus acts as a wrapping point, where numbers “wrap around” when they exceed the modulus. This wrapping behavior provides interesting properties and patterns.\n\n\n\nLet’s explore modular addition using an example. Suppose we want to add 4 and 4 modulo 5.\nHere are the steps for the equation \\(4 + 4 = 3 \\mod{5 }\\) using modular arithmetic:\nStep 1: Start with the addition of 4 and 4: \\(4 + 4 = 8\\).\nStep 2: Apply the modulus operation with a modulus of 5. Divide the result (8) by the modulus (5) and find the remainder: \\(8 = 3 \\mod{5}\\).\nStep 3: The final result is 3, indicating that when we add 4 and 4 within the modulus of 5, the remainder is 3.\n\n\n\nSubtraction works similarly in modular arithmetic. Let’s work through the equation \\(4 - 8 \\mod{3}\\) using modular arithmetic:\nStep 1: Start with the subtraction of 8 from 4: \\(4 - 8 = -4\\).\nStep 2: Since the result is negative, we need to add the modulus to make it positive. In this case, the modulus is 3, so we add 3 to -4: \\(-4 + 3 = -1\\).\nStep 3: Take the result modulo 3: \\(-1 = 2 \\mod{3}\\).\nStep 4: The final result is 2, indicating that when we subtract 8 from 4 within the modulus of 3, the remainder is 2.\n\n\n\nLet’s work through the equation \\(3 * 4 \\mod{7}\\) using modular arithmetic:\nStep 1: Start with the multiplication of 3 and 4: \\(3 * 4 = 12\\).\nStep 2: Take the result modulo 7: \\(12 = 5 \\mod{7}\\).\nStep 3: The final result is 5, indicating that when we multiply 3 by 4 within the modulus of 7, the remainder is 5.\nIn modular arithmetic, the result of multiplication is obtained by taking the modulo of the product, ensuring that the final result falls within the defined range determined by the modulus.\n\n\n\nThe modular inverse is another essential operation in modular arithmetic. It involves finding the number that, when multiplied by a given number modulo a specified modulus, yields a result of 1. Let’s compute the modular inverse of 3 modulo 10. Here’s an animation showcasing modular inverse on a number line:\nLet’s go through the steps to find the modular inverse:\nStep 1: Try different values for the inverse starting from 1 and going up. Multiply each value by 3 and take the result modulo 10.\n\n\\(1 * 3 = 3 \\mod{10}\\)\n\\(2 * 3 = 6 \\mod{10}\\)\n\\(3 * 3 = 9 \\mod{10}\\)\n\\(4 * 3 = 2 \\mod{10}\\)\n\\(5 * 3 = 5 \\mod{10}\\)\n\\(6 * 3 = 8 \\mod{10}\\)\n\\(7 * 3 = 1 \\mod{10}\\)\n\nStep 2: We found that when we multiply 7 by 3 and take the result modulo 10, we get 1. Therefore, the modular inverse of 3 mod 10 is 7.\nAfter finding the modular inverse of 3 mod 10 as 7 using a naive method, let’s discuss a more efficient approach to find modular inverses using the extended Euclidean algorithm.\nThe extended Euclidean algorithm is a well-known algorithm for finding the greatest common divisor (GCD) of two numbers and obtaining their Bézout coefficients, which can be used to find the modular inverse.\nIn the case of finding the modular inverse of 3 mod 10, we can apply the extended Euclidean algorithm as follows:\nStep 1: Start with the original numbers 3 and 10.\nStep 2: Apply the extended Euclidean algorithm to find the GCD and Bézout coefficients. The algorithm provides us with the values of x and y, such that:\n\\(GCD(3, 10) = 3 * x + 10 * y\\)\nStep 3: If the GCD is equal to 1, then the modular inverse exists. In this case, it means that there is a number, let’s call it “m”, such that:\n\\(3 * m = 1 \\mod{10}\\)\nStep 4: The value of “m” obtained from the extended Euclidean algorithm is the modular inverse of \\(3 \\mod{10}\\).\nUsing the extended Euclidean algorithm provides a more efficient way to find modular inverses compared to the naive method of trying different values. This algorithm has a time complexity of O(log N), where N is the larger of the two numbers involved.\nIf you want to learn more about the extended Euclidean algorithm and how to implement it, check out this post on Brilliant.\n\n\n\nFinding the square root in modular arithmetic involves finding a number that, when squared, gives a result equivalent to a given value modulo a specified modulus. Let’s go through an example to illustrate the steps involved.\nExample: Find the square root of 5 modulo 11.\nStep 1: Begin with the given value, which is 5.\nStep 2: Try different numbers from 0 to 10 as potential square roots. Square each number and take the result modulo 11.\n\n\\(0^2 = 0 \\mod{11}\\)\n\\(1^2 = 1 \\mod{11}\\)\n\\(2^2 = 4 \\mod{11}\\)\n\\(3^2 = 9 \\mod{11}\\)\n\\(4^2 = 5 \\mod{11}\\)\n\\(5^2 = 3 \\mod{11}\\)\n\\(6^2 = 3 \\mod{11}\\)\n\\(7^2 = 5 \\mod{11}\\)\n\\(8^2 = 9 \\mod{11}\\)\n\\(9^2 = 4 \\mod{11}\\)\n\\(10^2 = 1 \\mod{11}\\)\n\nStep 3: We found that when we square 4 and 7, we obtain a result of 5 modulo 11. Therefore, the square roots of 5 modulo 11 are 4 and 7.\nIt’s important to note that in modular arithmetic, a number can have multiple square roots or no square roots at all, depending on the value and modulus involved.\nTo find square roots in modular arithmetic, a more efficient approach is to use Euler’s criterion along with the properties of quadratic residues. Euler’s criterion states that for an odd prime modulus p and an integer a, if \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is congruent to 1, then a has a square root modulo p.\nHere’s a more efficient method to find square roots modulo a prime modulus:\n\nGiven a value a and a prime modulus p, check if a is a quadratic residue modulo p. This can be done by calculating \\(a^{\\frac{p-1}{2}} \\mod{p}\\).\nIf \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is not congruent to 1, then a has no square root modulo p.\nIf \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is congruent to 1, we can proceed to calculate the square root using the Tonelli-Shanks algorithm or other square root algorithms specifically designed for modular arithmetic. These algorithms involve solving modular equations and finding the appropriate values.\n\nThe Tonelli-Shanks algorithm is a popular algorithm for finding square roots in modular arithmetic, especially for large prime moduli.\nIt’s important to note that finding square roots in modular arithmetic can be complex, especially for non-prime moduli. The methods described above are specific to prime moduli and may not directly apply to composite moduli.\n\n\n\nModular arithmetic provides a unique perspective on numbers and operations within a fixed range. It exhibits interesting patterns and behaviors that have practical applications in various fields. We explored modular addition, subtraction, multiplication, square root, and modular inverses. I hope you enjoyed this introduction to modular arithmetic! In a future post I’ll explore more advanced topics in modular arithmetic, so stay tuned!"
  },
  {
    "objectID": "posts/modulararithmetic/index.html#what-is-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#what-is-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Modular arithmetic involves performing operations on numbers within a fixed range, called a modulus. The modulus acts as a wrapping point, where numbers “wrap around” when they exceed the modulus. This wrapping behavior provides interesting properties and patterns."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#addition-in-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#addition-in-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Let’s explore modular addition using an example. Suppose we want to add 4 and 4 modulo 5.\nHere are the steps for the equation \\(4 + 4 = 3 \\mod{5 }\\) using modular arithmetic:\nStep 1: Start with the addition of 4 and 4: \\(4 + 4 = 8\\).\nStep 2: Apply the modulus operation with a modulus of 5. Divide the result (8) by the modulus (5) and find the remainder: \\(8 = 3 \\mod{5}\\).\nStep 3: The final result is 3, indicating that when we add 4 and 4 within the modulus of 5, the remainder is 3."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#subtraction-in-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#subtraction-in-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Subtraction works similarly in modular arithmetic. Let’s work through the equation \\(4 - 8 \\mod{3}\\) using modular arithmetic:\nStep 1: Start with the subtraction of 8 from 4: \\(4 - 8 = -4\\).\nStep 2: Since the result is negative, we need to add the modulus to make it positive. In this case, the modulus is 3, so we add 3 to -4: \\(-4 + 3 = -1\\).\nStep 3: Take the result modulo 3: \\(-1 = 2 \\mod{3}\\).\nStep 4: The final result is 2, indicating that when we subtract 8 from 4 within the modulus of 3, the remainder is 2."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#multiplication-in-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#multiplication-in-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Let’s work through the equation \\(3 * 4 \\mod{7}\\) using modular arithmetic:\nStep 1: Start with the multiplication of 3 and 4: \\(3 * 4 = 12\\).\nStep 2: Take the result modulo 7: \\(12 = 5 \\mod{7}\\).\nStep 3: The final result is 5, indicating that when we multiply 3 by 4 within the modulus of 7, the remainder is 5.\nIn modular arithmetic, the result of multiplication is obtained by taking the modulo of the product, ensuring that the final result falls within the defined range determined by the modulus."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#square-root-in-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#square-root-in-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Finding the square root in modular arithmetic involves finding a number that, when squared, gives a result equivalent to a given value modulo a specified modulus. Let’s go through an example to illustrate the steps involved.\nExample: Find the square root of 5 modulo 11.\nStep 1: Begin with the given value, which is 5.\nStep 2: Try different numbers from 0 to 10 as potential square roots. Square each number and take the result modulo 11.\n\n\\(0^2 = 0 \\mod{11}\\)\n\\(1^2 = 1 \\mod{11}\\)\n\\(2^2 = 4 \\mod{11}\\)\n\\(3^2 = 9 \\mod{11}\\)\n\\(4^2 = 5 \\mod{11}\\)\n\\(5^2 = 3 \\mod{11}\\)\n\\(6^2 = 3 \\mod{11}\\)\n\\(7^2 = 5 \\mod{11}\\)\n\\(8^2 = 9 \\mod{11}\\)\n\\(9^2 = 4 \\mod{11}\\)\n\\(10^2 = 1 \\mod{11}\\)\n\nStep 3: We found that when we square 4 and 7, we obtain a result of 5 modulo 11. Therefore, the square roots of 5 modulo 11 are 4 and 7.\nIt’s important to note that in modular arithmetic, a number can have multiple square roots or no square roots at all, depending on the value and modulus involved.\nTo find square roots in modular arithmetic, a more efficient approach is to use Euler’s criterion along with the properties of quadratic residues. Euler’s criterion states that for an odd prime modulus p and an integer a, if \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is congruent to 1, then a has a square root modulo p.\nHere’s a more efficient method to find square roots modulo a prime modulus:\n\nGiven a value a and a prime modulus p, check if a is a quadratic residue modulo p. This can be done by calculating \\(a^{\\frac{p-1}{2}} \\mod{p}\\).\nIf \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is not congruent to 1, then a has no square root modulo p.\nIf \\(a^{\\frac{p-1}{2}} \\mod{p}\\) is congruent to 1, we can proceed to calculate the square root using the Tonelli-Shanks algorithm or other square root algorithms specifically designed for modular arithmetic. These algorithms involve solving modular equations and finding the appropriate values.\n\nThe Tonelli-Shanks algorithm is a popular algorithm for finding square roots in modular arithmetic, especially for large prime moduli.\nIt’s important to note that finding square roots in modular arithmetic can be complex, especially for non-prime moduli. The methods described above are specific to prime moduli and may not directly apply to composite moduli."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#modular-inverse-in-modular-arithmetic",
    "href": "posts/modulararithmetic/index.html#modular-inverse-in-modular-arithmetic",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "The modular inverse is another essential operation in modular arithmetic. It involves finding the number that, when multiplied by a given number modulo a specified modulus, yields a result of 1. Let’s compute the modular inverse of 3 modulo 10. Here’s an animation showcasing modular inverse on a number line:\nLet’s go through the steps to find the modular inverse:\nStep 1: Try different values for the inverse starting from 1 and going up. Multiply each value by 3 and take the result modulo 10.\n\n\\(1 * 3 = 3 \\mod{10}\\)\n\\(2 * 3 = 6 \\mod{10}\\)\n\\(3 * 3 = 9 \\mod{10}\\)\n\\(4 * 3 = 2 \\mod{10}\\)\n\\(5 * 3 = 5 \\mod{10}\\)\n\\(6 * 3 = 8 \\mod{10}\\)\n\\(7 * 3 = 1 \\mod{10}\\)\n\nStep 2: We found that when we multiply 7 by 3 and take the result modulo 10, we get 1. Therefore, the modular inverse of 3 mod 10 is 7.\nAfter finding the modular inverse of 3 mod 10 as 7 using a naive method, let’s discuss a more efficient approach to find modular inverses using the extended Euclidean algorithm.\nThe extended Euclidean algorithm is a well-known algorithm for finding the greatest common divisor (GCD) of two numbers and obtaining their Bézout coefficients, which can be used to find the modular inverse.\nIn the case of finding the modular inverse of 3 mod 10, we can apply the extended Euclidean algorithm as follows:\nStep 1: Start with the original numbers 3 and 10.\nStep 2: Apply the extended Euclidean algorithm to find the GCD and Bézout coefficients. The algorithm provides us with the values of x and y, such that:\n\\(GCD(3, 10) = 3 * x + 10 * y\\)\nStep 3: If the GCD is equal to 1, then the modular inverse exists. In this case, it means that there is a number, let’s call it “m”, such that:\n\\(3 * m = 1 \\mod{10}\\)\nStep 4: The value of “m” obtained from the extended Euclidean algorithm is the modular inverse of \\(3 \\mod{10}\\).\nUsing the extended Euclidean algorithm provides a more efficient way to find modular inverses compared to the naive method of trying different values. This algorithm has a time complexity of O(log N), where N is the larger of the two numbers involved.\nIf you want to learn more about the extended Euclidean algorithm and how to implement it, check out this post on Brilliant."
  },
  {
    "objectID": "posts/modulararithmetic/index.html#conclusion",
    "href": "posts/modulararithmetic/index.html#conclusion",
    "title": "Introduction to Modular Arithmetic",
    "section": "",
    "text": "Modular arithmetic provides a unique perspective on numbers and operations within a fixed range. It exhibits interesting patterns and behaviors that have practical applications in various fields. We explored modular addition, subtraction, multiplication, square root, and modular inverses. I hope you enjoyed this introduction to modular arithmetic! In a future post I’ll explore more advanced topics in modular arithmetic, so stay tuned!"
  },
  {
    "objectID": "posts/groupsfieldsrings/index.html",
    "href": "posts/groupsfieldsrings/index.html",
    "title": "Groups, Rings, and Fields",
    "section": "",
    "text": "Groups, fields, and rings are fundamental mathematical structures that play a crucial role in various cryptographic algorithms. Let’s explore the definitions of these structures and their applications in cryptography.\n\n\nA group is a mathematical structure that consists of a set G along with a binary operation * defined on G. For G to be a group, the following conditions must hold:\n\nClosure: For any elements a and b in G, the result of the operation a * b is also in G.\nAssociativity: The operation * is associative, meaning that for any- elements a, b, and c in G, the expression (a * b) * c is equal to a * (b * c).\nIdentity element: There exists an identity element e in G such that for any element a in G, the equation a * e = e * a = a holds.\nInverses: For every element a in G, there exists an inverse element a⁻¹ in G such that a * a⁻¹ = a⁻¹ * a = e.\n\nAn Abelian group, also known as a commutative group, is a specific type of group where the operation is commutative. In other words, the order in which elements are combined does not affect the result. This property allows for a more simplified structure and often leads to interesting mathematical properties.\nGroups find extensive use in cryptography, particularly in symmetric key algorithms and elliptic curve cryptography. The properties of groups, such as associativity and inverses, are leveraged to achieve secure cryptographic operations.\n\n\n\nA ring is a mathematical structure that combines the operations of addition (+) and multiplication (×). A ring R consists of a set along with two operations: addition and multiplication. For R to be a ring, the following conditions must hold:\n\nR, under addition, forms an Abelian group.\nR, under multiplication, is closed, associative, and has a multiplicative identity element.\nMultiplication distributes over addition.\n\nRings find applications in various areas of mathematics and cryptography, such as error-correcting codes and digital signatures.\n\n\n\nA field is an algebraic structure that extends the concept of a group by introducing a second binary operation, typically denoted as + and ×. A field F consists of a set along with two operations: addition (+) and multiplication (×). For F to be a field, the following conditions must hold:\n\nF, under addition, forms an Abelian group with an identity element 0 and additive inverses.\nF, excluding the additive identity, under multiplication, forms an Abelian group with an identity element 1 and multiplicative inverses.\nDistributivity: For any elements a, b, and c in F, the equation a × (b + c) = (a × b) + (a × c) holds.\n\nFields are essential in cryptography, particularly in public key algorithms. They provide the mathematical framework for operations like modular arithmetic, which forms the basis for secure encryption and digital signatures.\n\n\n\nGroups, fields, and rings are essential mathematical structures that provide a foundation for many cryptographic algorithms. They enable the design and implementation of cryptographic primitives that offer security properties such as confidentiality, integrity, and authenticity.\nFor example, in public key cryptography, the discrete logarithm problem and elliptic curve discrete logarithm problem are formulated within groups or fields. The hardness of these problems forms the basis of cryptographic schemes like the Diffie-Hellman key exchange, Digital Signature Algorithm (DSA), and Elliptic Curve Cryptography (ECC).\nFields and rings also play a crucial role in error-correcting codes used in data transmission and storage. These codes rely on algebraic structures to encode and decode data, ensuring reliable and accurate transmission.\nIn conclusion, groups, fields, and rings provide mathematical frameworks that underpin cryptography and other areas of mathematics. Understanding these structures and their properties is essential for developing secure cryptographic algorithms and systems. By leveraging the properties of these structures, we can design encryption schemes, digital signatures, and other cryptographic primitives that protect sensitive information in various applications."
  },
  {
    "objectID": "posts/groupsfieldsrings/index.html#groups",
    "href": "posts/groupsfieldsrings/index.html#groups",
    "title": "Groups, Rings, and Fields",
    "section": "",
    "text": "A group is a mathematical structure that consists of a set G along with a binary operation * defined on G. For G to be a group, the following conditions must hold:\n\nClosure: For any elements a and b in G, the result of the operation a * b is also in G.\nAssociativity: The operation * is associative, meaning that for any- elements a, b, and c in G, the expression (a * b) * c is equal to a * (b * c).\nIdentity element: There exists an identity element e in G such that for any element a in G, the equation a * e = e * a = a holds.\nInverses: For every element a in G, there exists an inverse element a⁻¹ in G such that a * a⁻¹ = a⁻¹ * a = e.\n\nAn Abelian group, also known as a commutative group, is a specific type of group where the operation is commutative. In other words, the order in which elements are combined does not affect the result. This property allows for a more simplified structure and often leads to interesting mathematical properties.\nGroups find extensive use in cryptography, particularly in symmetric key algorithms and elliptic curve cryptography. The properties of groups, such as associativity and inverses, are leveraged to achieve secure cryptographic operations."
  },
  {
    "objectID": "posts/groupsfieldsrings/index.html#fields",
    "href": "posts/groupsfieldsrings/index.html#fields",
    "title": "Groups, Rings, and Fields",
    "section": "",
    "text": "A field is an algebraic structure that extends the concept of a group by introducing a second binary operation, typically denoted as + and ×. A field F consists of a set along with two operations: addition (+) and multiplication (×). For F to be a field, the following conditions must hold:\n\nF, under addition, forms an Abelian group with an identity element 0 and additive inverses.\nF, excluding the additive identity, under multiplication, forms an Abelian group with an identity element 1 and multiplicative inverses.\nDistributivity: For any elements a, b, and c in F, the equation a × (b + c) = (a × b) + (a × c) holds.\n\nFields are essential in cryptography, particularly in public key algorithms. They provide the mathematical framework for operations like modular arithmetic, which forms the basis for secure encryption and digital signatures."
  },
  {
    "objectID": "posts/groupsfieldsrings/index.html#rings",
    "href": "posts/groupsfieldsrings/index.html#rings",
    "title": "Groups, Rings, and Fields",
    "section": "",
    "text": "A ring is a mathematical structure that combines the operations of addition (+) and multiplication (×). A ring R consists of a set along with two operations: addition and multiplication. For R to be a ring, the following conditions must hold:\n\nR, under addition, forms an Abelian group.\nR, under multiplication, is closed, associative, and has a multiplicative identity element.\nMultiplication distributes over addition.\n\nRings find applications in various areas of mathematics and cryptography, such as error-correcting codes and digital signatures."
  },
  {
    "objectID": "posts/groupsfieldsrings/index.html#cryptographic-applications",
    "href": "posts/groupsfieldsrings/index.html#cryptographic-applications",
    "title": "Groups, Rings, and Fields",
    "section": "",
    "text": "Groups, fields, and rings are essential mathematical structures that provide a foundation for many cryptographic algorithms. They enable the design and implementation of cryptographic primitives that offer security properties such as confidentiality, integrity, and authenticity.\nFor example, in public key cryptography, the discrete logarithm problem and elliptic curve discrete logarithm problem are formulated within groups or fields. The hardness of these problems forms the basis of cryptographic schemes like the Diffie-Hellman key exchange, Digital Signature Algorithm (DSA), and Elliptic Curve Cryptography (ECC).\nFields and rings also play a crucial role in error-correcting codes used in data transmission and storage. These codes rely on algebraic structures to encode and decode data, ensuring reliable and accurate transmission.\nIn conclusion, groups, fields, and rings provide mathematical frameworks that underpin cryptography and other areas of mathematics. Understanding these structures and their properties is essential for developing secure cryptographic algorithms and systems. By leveraging the properties of these structures, we can design encryption schemes, digital signatures, and other cryptographic primitives that protect sensitive information in various applications."
  },
  {
    "objectID": "posts/lwe/index.html",
    "href": "posts/lwe/index.html",
    "title": "Learning With Errors",
    "section": "",
    "text": "The Learning With Errors (LWE) problem is a mathematical problem that plays a significant role in modern cryptographic schemes. It is based on the concept of finding a solution to a system of linear equations with errors. Let’s explore the LWE problem and its applications in cryptography. Problem Statement\nThis problem is incredibly similar to the shortest vector problem (SVP) and the closest vector problem (CVP). I suggest you read that article first if you haven’t already.\n\n\nThe LWE problem can be formulated as the equation \\(A⋅s+e=b\\mod{p}\\), where:\n\n\\(A\\) is the public key matrix,\n\\(s\\) is the secret vector,\n\\(e\\) is the noise vector,\n\\(b\\) is the resulting ciphertext vector, and\n\\(p\\) is a modulus.\n\nLet’s walk through a concrete example to illustrate how the Learning With Errors (LWE) problem can be used for encryption. We will use small values to demonstrate the process.\nSuppose we have the following parameters:\n\nPublic Key Matrix \\(A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}\\)\nModulus \\(p = 7\\)\nSecret Vector \\(s = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}\\)\nNoise Vector \\(e = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\\)\n\n\n\nCode\nfrom IPython.display import display, Math, Latex\nimport numpy as np\n\n# From KMChris\n# https://gist.github.com/KMChris/8fd878826453c3d55814b3293c7b084c\ndef print_matrix(array):\n    matrix = ''\n    for row in array:\n        try:\n            for number in row:\n                matrix += f'{number}&'\n        except TypeError:\n            matrix += f'{row}&'\n        matrix = matrix[:-1] + r'\\\\'\n    return r'\\begin{bmatrix}'+matrix+r'\\end{bmatrix}'\n\nq = 7\nA=np.array([[1 ,2],[3, 4]])\nsA = np.array([[5],[9]])\neA = np.array([[2],[-1]])\nbA = np.matmul(A,sA)%q\nbA = np.add(bA,eA)%q\n\nmatrix = r\"b = \" + print_matrix(A)\nmatrix += r\" * \" + print_matrix(sA)\nmatrix += r\" + \" + print_matrix(eA)\nmatrix += r\" \\mod{\" + str(q) + r\"}\"\nmatrix += r\" = \" + print_matrix(bA)\n\nmatrix = Math(matrix)\n\ndisplay(matrix)\n\n\n\\(\\displaystyle b = \\begin{bmatrix}1&2\\\\3&4\\\\\\end{bmatrix} * \\begin{bmatrix}5\\\\9\\\\\\end{bmatrix} + \\begin{bmatrix}2\\\\-1\\\\\\end{bmatrix} \\mod{7} = \\begin{bmatrix}4\\\\1\\\\\\end{bmatrix}\\)\nAn example of encryption using LWE\n\n\nTo encrypt the message of length \\(n\\) represented in binary (which has t number of different values), we sample \\(n\\) rows from \\(A\\) and the corresponding values from \\(b\\). We add up all the rows into a single equation and we add \\(\\lfloor\\frac{q}{t}\\rfloor\\) to \\(b\\).\nIn this case we will only use a single row, but the same process still applies.\n\n\\([1 \\quad 2] = 4\\)\n\nIf our message is the bit 1, we add \\(\\lfloor\\frac{q}{2}\\rfloor\\) to \\(b\\):\n\n\\([1 \\quad 2] = 4 + \\lfloor\\frac{q}{2}\\rfloor = 7\\)\n\nIf our message is the big 0, we add \\(0\\) to \\(b\\):\n\n\\([1 \\quad 2] = 4\\)\n\nNext, the person with the secret key multiplies the ciphertext vector \\(b\\) by the secret vector \\(s\\) and takes the result modulo \\(p\\) to obtain the original message. There is a small error, but this is removed by rounding the result to the nearest value representing a bit. In our case it is rounded to either 0 representing 0 or 7 representing 1.\n\n\nCode\nprint(\"A_rows * sA % q = correct\")\nprint(\"b_row - correct = encoded\")\n\n# Encoded 1 bit\nA_row = np.array([1, 2])\nb_row = 7\n\ncorrect = np.matmul(A_row,sA)%q\n\nencoded = b_row - correct\n\nprint(f\"1 bit which should be very close to 7: {encoded}\")\n\n# Encoded 0 bit\nA_row = np.array([1, 2])\nb_row = 4\n\ncorrect = np.matmul(A_row,sA)%q\n\nencoded = b_row - correct\nprint(f\"0 bit which should be very close to 0: {encoded}\")\n\n\nA_rows * sA % q = correct\nb_row - correct = encoded\n1 bit which should be very close to 7: [5]\n0 bit which should be very close to 0: [2]\n\n\n\n\n\nFully Homomorphic Encryption (FHE) is a revolutionary cryptographic scheme that allows computations to be performed directly on encrypted data, without the need for decryption. FHE based on LWE enables secure computation on sensitive data while preserving privacy. It allows for powerful operations like addition and multiplication to be performed on encrypted data, providing a practical solution for secure computation in various applications, such as privacy-preserving data analysis and secure outsourcing of computations.\nKyber is a post-quantum secure key encapsulation mechanism (KEM) based on LWE. It is designed to provide secure key exchange in the presence of powerful quantum computers. Kyber uses the LWE problem to generate cryptographic keys, ensuring that the exchanged keys remain secure even if an adversary has access to quantum computing resources. Kyber is a promising candidate for secure communication in a post-quantum world, offering strong security guarantees and efficient performance.\nBoth TFHE (The Fully Homomorphic Encryption Library) and Kyber highlight the practical applications of the LWE problem in constructing advanced cryptographic algorithms. By leveraging the mathematical hardness of the LWE problem, these algorithms provide secure and efficient solutions for various cryptographic tasks, contributing to the development of post-quantum secure systems.\n\n\n\nThe Learning With Errors (LWE) problem is closely related to other lattice-based problems, including Ring Learning With Errors (RLWE) and General Learning With Errors (GLWE). These problems share similar mathematical structures and serve as the foundation for various cryptographic schemes.\nRLWE extends the LWE problem by introducing an additional algebraic structure called a ring. It involves working with polynomials instead of vectors, which offers certain advantages in cryptographic constructions. RLWE allows for the development of efficient encryption schemes, such as the NTRUEncrypt scheme, which provides post-quantum security.\nGLWE generalizes the LWE problem by considering a more general form of noise distribution. It allows for more flexibility in the noise generation process and offers enhanced security guarantees. GLWE is utilized in cryptographic constructions such as functional encryption and obfuscation, enabling advanced functionalities like fine-grained access control and program obfuscation.\n\n\n\nIn conclusion, the Learning With Errors (LWE) problem is a powerful mathematical framework that has gained significant attention in the field of post-quantum cryptography. Its security is based on the presumed hardness of finding the secret key from the public key, even when given noisy and seemingly random equations. The LWE problem offers a promising approach to building cryptographic schemes that are resilient against attacks from both classical and quantum computers. As researchers continue to explore and develop new algorithms and techniques in this area, the LWE problem holds great potential for providing secure communication and protecting sensitive information in the era of quantum computing."
  },
  {
    "objectID": "posts/lwe/index.html#example-encryption-using-learning-with-errors",
    "href": "posts/lwe/index.html#example-encryption-using-learning-with-errors",
    "title": "Learning With Errors",
    "section": "",
    "text": "The LWE problem can be formulated as the equation \\(A⋅s+e=b\\mod{p}\\), where:\n\n\\(A\\) is the public key matrix,\n\\(s\\) is the secret vector,\n\\(e\\) is the noise vector,\n\\(b\\) is the resulting ciphertext vector, and\n\\(p\\) is a modulus.\n\nLet’s walk through a concrete example to illustrate how the Learning With Errors (LWE) problem can be used for encryption. We will use small values to demonstrate the process.\nSuppose we have the following parameters:\n\nPublic Key Matrix \\(A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}\\)\nModulus \\(p = 7\\)\nSecret Vector \\(s = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}\\)\nNoise Vector \\(e = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\\)\n\n\n\nCode\nfrom IPython.display import display, Math, Latex\nimport numpy as np\n\n# From KMChris\n# https://gist.github.com/KMChris/8fd878826453c3d55814b3293c7b084c\ndef print_matrix(array):\n    matrix = ''\n    for row in array:\n        try:\n            for number in row:\n                matrix += f'{number}&'\n        except TypeError:\n            matrix += f'{row}&'\n        matrix = matrix[:-1] + r'\\\\'\n    return r'\\begin{bmatrix}'+matrix+r'\\end{bmatrix}'\n\nq = 7\nA=np.array([[1 ,2],[3, 4]])\nsA = np.array([[5],[9]])\neA = np.array([[2],[-1]])\nbA = np.matmul(A,sA)%q\nbA = np.add(bA,eA)%q\n\nmatrix = r\"b = \" + print_matrix(A)\nmatrix += r\" * \" + print_matrix(sA)\nmatrix += r\" + \" + print_matrix(eA)\nmatrix += r\" \\mod{\" + str(q) + r\"}\"\nmatrix += r\" = \" + print_matrix(bA)\n\nmatrix = Math(matrix)\n\ndisplay(matrix)\n\n\n\\(\\displaystyle b = \\begin{bmatrix}1&2\\\\3&4\\\\\\end{bmatrix} * \\begin{bmatrix}5\\\\9\\\\\\end{bmatrix} + \\begin{bmatrix}2\\\\-1\\\\\\end{bmatrix} \\mod{7} = \\begin{bmatrix}4\\\\1\\\\\\end{bmatrix}\\)\nAn example of encryption using LWE\n\n\nTo encrypt the message of length \\(n\\) represented in binary (which has t number of different values), we sample \\(n\\) rows from \\(A\\) and the corresponding values from \\(b\\). We add up all the rows into a single equation and we add \\(\\lfloor\\frac{q}{t}\\rfloor\\) to \\(b\\).\nIn this case we will only use a single row, but the same process still applies.\n\n\\([1 \\quad 2] = 4\\)\n\nIf our message is the bit 1, we add \\(\\lfloor\\frac{q}{2}\\rfloor\\) to \\(b\\):\n\n\\([1 \\quad 2] = 4 + \\lfloor\\frac{q}{2}\\rfloor = 7\\)\n\nIf our message is the big 0, we add \\(0\\) to \\(b\\):\n\n\\([1 \\quad 2] = 4\\)\n\nNext, the person with the secret key multiplies the ciphertext vector \\(b\\) by the secret vector \\(s\\) and takes the result modulo \\(p\\) to obtain the original message. There is a small error, but this is removed by rounding the result to the nearest value representing a bit. In our case it is rounded to either 0 representing 0 or 7 representing 1.\n\n\nCode\nprint(\"A_rows * sA % q = correct\")\nprint(\"b_row - correct = encoded\")\n\n# Encoded 1 bit\nA_row = np.array([1, 2])\nb_row = 7\n\ncorrect = np.matmul(A_row,sA)%q\n\nencoded = b_row - correct\n\nprint(f\"1 bit which should be very close to 7: {encoded}\")\n\n# Encoded 0 bit\nA_row = np.array([1, 2])\nb_row = 4\n\ncorrect = np.matmul(A_row,sA)%q\n\nencoded = b_row - correct\nprint(f\"0 bit which should be very close to 0: {encoded}\")\n\n\nA_rows * sA % q = correct\nb_row - correct = encoded\n1 bit which should be very close to 7: [5]\n0 bit which should be very close to 0: [2]"
  },
  {
    "objectID": "posts/lwe/index.html#example-encryption-using-learning-with-errors-1",
    "href": "posts/lwe/index.html#example-encryption-using-learning-with-errors-1",
    "title": "Learning With Errors",
    "section": "",
    "text": "Let’s walk through a concrete example to illustrate how the Learning With Errors (LWE) problem can be used for encryption. We will use small values to demonstrate the process.\nSuppose we have the following parameters:\n\nPublic Key Matrix \\(A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}\\)\nModulus \\(p = 7\\)\nSecret Vector \\(s = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}\\)\nNoise Vector \\(e = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\\)\n\nTo encrypt a message, we follow these steps:\n\nCompute the ciphertext vector \\(b\\) by performing matrix-vector multiplication: \\(b = A \\cdot s + e \\mod p\\) Plugging in the values: \\(b = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\cdot \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} \\mod 7\\) Solving the matrix-vector multiplication and applying modulo 7: \\(b = \\begin{pmatrix} 3 + 2 \\\\ 9 + 4 \\end{pmatrix} + \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} \\mod 7 = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\\)\n\nThe resulting ciphertext vector \\(b\\) represents the encrypted form of the original message.\nTo decrypt the ciphertext and retrieve the original message, the recipient, who possesses the private key, performs the following steps:\n\nCompute the inner product of the ciphertext vector \\(b\\) and the secret vector \\(s\\): \\(b \\cdot s = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} \\cdot \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix} = (5 \\cdot 3) + (6 \\cdot 1) = 15 + 6 = 21\\)\nSubtract the result from step 2 from the ciphertext vector: \\(b - (b \\cdot s) = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} - 21 = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} - \\begin{pmatrix} 21 \\\\ 21 \\end{pmatrix} = \\begin{pmatrix} 5 - 21 \\\\ 6 - 21 \\end{pmatrix} = \\begin{pmatrix} -16 \\\\ -15 \\end{pmatrix}\\)\n\nThe resulting vector \\(\\begin{pmatrix} -16 \\\\ -15 \\end{pmatrix}\\) represents the decrypted message. In modular arithmetic, we can interpret negative values by adding the modulus to them. In this example, adding 7 to each negative value gives us \\(\\begin{pmatrix} -16 + 7 \\\\ -15 + 7 \\end{pmatrix} = \\begin{pmatrix} -9 \\\\ -8 \\end{pmatrix}\\).\nTherefore, the decrypted message is \\(\\begin{pmatrix} -9 \\\\ -8 \\end{pmatrix}\\)."
  },
  {
    "objectID": "posts/lwe/index.html#conclusion",
    "href": "posts/lwe/index.html#conclusion",
    "title": "Learning With Errors",
    "section": "",
    "text": "In conclusion, the Learning With Errors (LWE) problem is a powerful mathematical framework that has gained significant attention in the field of post-quantum cryptography. Its security is based on the presumed hardness of finding the secret key from the public key, even when given noisy and seemingly random equations. The LWE problem offers a promising approach to building cryptographic schemes that are resilient against attacks from both classical and quantum computers. As researchers continue to explore and develop new algorithms and techniques in this area, the LWE problem holds great potential for providing secure communication and protecting sensitive information in the era of quantum computing."
  },
  {
    "objectID": "posts/lwe/index.html#usage-in-cryptography",
    "href": "posts/lwe/index.html#usage-in-cryptography",
    "title": "Learning With Errors",
    "section": "",
    "text": "Fully Homomorphic Encryption (FHE) is a revolutionary cryptographic scheme that allows computations to be performed directly on encrypted data, without the need for decryption. FHE based on LWE enables secure computation on sensitive data while preserving privacy. It allows for powerful operations like addition and multiplication to be performed on encrypted data, providing a practical solution for secure computation in various applications, such as privacy-preserving data analysis and secure outsourcing of computations.\nKyber is a post-quantum secure key encapsulation mechanism (KEM) based on LWE. It is designed to provide secure key exchange in the presence of powerful quantum computers. Kyber uses the LWE problem to generate cryptographic keys, ensuring that the exchanged keys remain secure even if an adversary has access to quantum computing resources. Kyber is a promising candidate for secure communication in a post-quantum world, offering strong security guarantees and efficient performance.\nBoth TFHE (The Fully Homomorphic Encryption Library) and Kyber highlight the practical applications of the LWE problem in constructing advanced cryptographic algorithms. By leveraging the mathematical hardness of the LWE problem, these algorithms provide secure and efficient solutions for various cryptographic tasks, contributing to the development of post-quantum secure systems."
  },
  {
    "objectID": "posts/lwe/index.html#other-problems",
    "href": "posts/lwe/index.html#other-problems",
    "title": "Learning With Errors",
    "section": "",
    "text": "The Learning With Errors (LWE) problem is closely related to other lattice-based problems, including Ring Learning With Errors (RLWE) and General Learning With Errors (GLWE). These problems share similar mathematical structures and serve as the foundation for various cryptographic schemes.\nRLWE extends the LWE problem by introducing an additional algebraic structure called a ring. It involves working with polynomials instead of vectors, which offers certain advantages in cryptographic constructions. RLWE allows for the development of efficient encryption schemes, such as the NTRUEncrypt scheme, which provides post-quantum security.\nGLWE generalizes the LWE problem by considering a more general form of noise distribution. It allows for more flexibility in the noise generation process and offers enhanced security guarantees. GLWE is utilized in cryptographic constructions such as functional encryption and obfuscation, enabling advanced functionalities like fine-grained access control and program obfuscation."
  }
]